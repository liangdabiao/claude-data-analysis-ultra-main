#!/usr/bin/env python3
"""
æ¨¡å‹ä¼˜åŒ–å™¨
æä¾›æ¨¡å‹æ€§èƒ½ä¼˜åŒ–å’Œè¶…å‚æ•°è°ƒä¼˜åŠŸèƒ½
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import warnings
warnings.filterwarnings('ignore')

class ModelOptimizer:
    """æ¨¡å‹ä¼˜åŒ–å™¨ç±»"""

    def __init__(self):
        self.best_params = {}
        self.optimization_history = {}

    def optimize_random_forest(self, X_train, y_train, X_test=None, y_test=None,
                             optimization_method='grid', cv_folds=5, n_iter=50):
        """
        ä¼˜åŒ–éšæœºæ£®æ—æ¨¡å‹

        Args:
            X_train, y_train: è®­ç»ƒæ•°æ®
            X_test, y_test: æµ‹è¯•æ•°æ®ï¼ˆå¯é€‰ï¼‰
            optimization_method: ä¼˜åŒ–æ–¹æ³• ('grid', 'random', 'bayesian')
            cv_folds: äº¤å‰éªŒè¯æŠ˜æ•°
            n_iter: éšæœºæœç´¢è¿­ä»£æ¬¡æ•°

        Returns:
            ä¼˜åŒ–åçš„æ¨¡å‹å’Œå‚æ•°
        """
        print("ğŸ”§ å¼€å§‹éšæœºæ£®æ—æ¨¡å‹ä¼˜åŒ–...")

        # åŸºç¡€æ¨¡å‹
        rf = RandomForestRegressor(random_state=42, n_jobs=-1)

        # å‚æ•°æœç´¢ç©ºé—´
        param_grid = {
            'n_estimators': [50, 100, 200, 300],
            'max_depth': [None, 10, 20, 30],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4],
            'max_features': ['sqrt', 'log2', None]
        }

        # é€‰æ‹©ä¼˜åŒ–æ–¹æ³•
        if optimization_method == 'grid':
            print("  ä½¿ç”¨ç½‘æ ¼æœç´¢...")
            search = GridSearchCV(
                rf, param_grid, cv=cv_folds,
                scoring='r2', n_jobs=-1, verbose=1
            )
        elif optimization_method == 'random':
            print("  ä½¿ç”¨éšæœºæœç´¢...")
            search = RandomizedSearchCV(
                rf, param_grid, n_iter=n_iter, cv=cv_folds,
                scoring='r2', n_jobs=-1, verbose=1, random_state=42
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ä¼˜åŒ–æ–¹æ³•: {optimization_method}")

        # æ‰§è¡Œæœç´¢
        search.fit(X_train, y_train)

        # è·å–æœ€ä½³æ¨¡å‹
        best_model = search.best_estimator_
        best_params = search.best_params_
        best_score = search.best_score_

        print(f"âœ… ä¼˜åŒ–å®Œæˆ!")
        print(f"  æœ€ä½³å‚æ•°: {best_params}")
        print(f"  äº¤å‰éªŒè¯RÂ²: {best_score:.4f}")

        # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
        if X_test is not None and y_test is not None:
            test_score = best_model.score(X_test, y_test)
            print(f"  æµ‹è¯•é›†RÂ²: {test_score:.4f}")

        # ä¿å­˜ç»“æœ
        self.best_params['random_forest'] = best_params
        self.optimization_history['random_forest'] = {
            'best_params': best_params,
            'best_cv_score': best_score,
            'test_score': test_score if X_test is not None else None
        }

        return best_model, best_params, best_score

    def optimize_linear_regression(self, X_train, y_train, X_test=None, y_test=None):
        """
        ä¼˜åŒ–çº¿æ€§å›å½’æ¨¡å‹ï¼ˆç‰¹å¾é€‰æ‹©å’Œæ­£åˆ™åŒ–ï¼‰

        Args:
            X_train, y_train: è®­ç»ƒæ•°æ®
            X_test, y_test: æµ‹è¯•æ•°æ®ï¼ˆå¯é€‰ï¼‰

        Returns:
            ä¼˜åŒ–åçš„æ¨¡å‹å’Œç‰¹å¾ä¿¡æ¯
        """
        print("ğŸ”§ å¼€å§‹çº¿æ€§å›å½’æ¨¡å‹ä¼˜åŒ–...")

        # åŸºç¡€æ¨¡å‹
        lr = LinearRegression()

        # äº¤å‰éªŒè¯è¯„ä¼°
        cv_scores = cross_val_score(lr, X_train, y_train, cv=5, scoring='r2')

        print(f"  äº¤å‰éªŒè¯RÂ²: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")

        # è®­ç»ƒæ¨¡å‹
        lr.fit(X_train, y_train)

        # ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆç³»æ•°ç»å¯¹å€¼ï¼‰
        feature_importance = np.abs(lr.coef_)
        feature_ranking = np.argsort(feature_importance)[::-1]

        print("  ç‰¹å¾é‡è¦æ€§æ’å:")
        for i, idx in enumerate(feature_ranking):
            if i < len(feature_importance):
                print(f"    {i+1}. ç‰¹å¾{idx}: {feature_importance[idx]:.4f}")

        # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
        test_score = None
        if X_test is not None and y_test is not None:
            test_score = lr.score(X_test, y_test)
            print(f"  æµ‹è¯•é›†RÂ²: {test_score:.4f}")

        # ä¿å­˜ç»“æœ
        self.optimization_history['linear_regression'] = {
            'feature_importance': feature_importance.tolist(),
            'feature_ranking': feature_ranking.tolist(),
            'cv_scores': cv_scores.tolist(),
            'test_score': test_score
        }

        return lr, feature_importance, cv_scores.mean()

    def ensemble_models(self, models, X_test, y_test, weights=None):
        """
        æ¨¡å‹é›†æˆ

        Args:
            models: æ¨¡å‹åˆ—è¡¨
            X_test, y_test: æµ‹è¯•æ•°æ®
            weights: æ¨¡å‹æƒé‡ï¼ˆå¯é€‰ï¼‰

        Returns:
            é›†æˆé¢„æµ‹ç»“æœå’Œæ€§èƒ½
        """
        print("ğŸ”— å¼€å§‹æ¨¡å‹é›†æˆ...")

        if weights is None:
            # ç®€å•å¹³å‡
            weights = [1.0 / len(models)] * len(models)

        # è·å–å„æ¨¡å‹é¢„æµ‹
        predictions = []
        model_scores = []

        for i, model in enumerate(models):
            pred = model.predict(X_test)
            predictions.append(pred)
            score = model.score(X_test, y_test)
            model_scores.append(score)
            print(f"  æ¨¡å‹{i+1} RÂ²: {score:.4f} (æƒé‡: {weights[i]:.3f})")

        # åŠ æƒå¹³å‡é¢„æµ‹
        ensemble_pred = np.zeros_like(predictions[0])
        for pred, weight in zip(predictions, weights):
            ensemble_pred += pred * weight

        # è®¡ç®—é›†æˆæ€§èƒ½
        ensemble_r2 = r2_score(y_test, ensemble_pred)
        ensemble_mae = mean_absolute_error(y_test, ensemble_pred)
        ensemble_rmse = np.sqrt(mean_squared_error(y_test, ensemble_pred))

        print(f"âœ… é›†æˆæ¨¡å‹æ€§èƒ½:")
        print(f"  RÂ² åˆ†æ•°: {ensemble_r2:.4f}")
        print(f"  MAE: {ensemble_mae:.4f}")
        print(f"  RMSE: {ensemble_rmse:.4f}")

        return ensemble_pred, {
            'r2_score': ensemble_r2,
            'mae': ensemble_mae,
            'rmse': ensemble_rmse,
            'individual_scores': model_scores,
            'weights': weights
        }

    def feature_selection(self, X_train, y_train, X_test=None, y_test=None,
                        method='correlation', threshold=0.1):
        """
        ç‰¹å¾é€‰æ‹©

        Args:
            X_train, y_train: è®­ç»ƒæ•°æ®
            X_test, y_test: æµ‹è¯•æ•°æ®ï¼ˆå¯é€‰ï¼‰
            method: é€‰æ‹©æ–¹æ³• ('correlation', 'mutual_info', 'rfe')
            threshold: é€‰æ‹©é˜ˆå€¼

        Returns:
            é€‰æ‹©çš„ç‰¹å¾ç´¢å¼•å’Œé‡è¦æ€§
        """
        print(f"ğŸ¯ å¼€å§‹ç‰¹å¾é€‰æ‹© (æ–¹æ³•: {method})...")

        if method == 'correlation':
            # ç›¸å…³æ€§åˆ†æ
            correlations = []
            for i in range(X_train.shape[1]):
                corr = np.corrcoef(X_train[:, i], y_train)[0, 1]
                correlations.append(abs(corr))

            selected_features = [i for i, corr in enumerate(correlations) if corr > threshold]
            feature_importance = correlations

        elif method == 'mutual_info':
            from sklearn.feature_selection import mutual_info_regression
            mi_scores = mutual_info_regression(X_train, y_train)
            selected_features = [i for i, score in enumerate(mi_scores) if score > threshold]
            feature_importance = mi_scores

        elif method == 'rfe':
            from sklearn.feature_selection import RFE
            from sklearn.linear_model import LinearRegression

            estimator = LinearRegression()
            selector = RFE(estimator, n_features_to_select=max(1, int(threshold * X_train.shape[1])))
            selector.fit(X_train, y_train)

            selected_features = [i for i, selected in enumerate(selector.support_) if selected]
            feature_importance = selector.ranking_

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ç‰¹å¾é€‰æ‹©æ–¹æ³•: {method}")

        print(f"  åŸå§‹ç‰¹å¾æ•°: {X_train.shape[1]}")
        print(f"  é€‰æ‹©ç‰¹å¾æ•°: {len(selected_features)}")
        print(f"  é€‰æ‹©ç‰¹å¾ç´¢å¼•: {selected_features}")

        # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°ç‰¹å¾é€‰æ‹©æ•ˆæœ
        if X_test is not None and y_test is not None and len(selected_features) > 0:
            X_train_selected = X_train[:, selected_features]
            X_test_selected = X_test[:, selected_features]

            lr = LinearRegression()
            lr.fit(X_train_selected, y_train)
            test_score = lr.score(X_test_selected, y_test)

            # ä¸åŸå§‹ç‰¹å¾å¯¹æ¯”
            lr_full = LinearRegression()
            lr_full.fit(X_train, y_train)
            full_score = lr_full.score(X_test, y_test)

            print(f"  é€‰æ‹©åæ¨¡å‹RÂ²: {test_score:.4f}")
            print(f"  åŸå§‹æ¨¡å‹RÂ²: {full_score:.4f}")
            print(f"  æ€§èƒ½å˜åŒ–: {((test_score - full_score) / full_score * 100):+.2f}%")

        return selected_features, feature_importance

    def automated_hyperparameter_tuning(self, X_train, y_train, X_test, y_test,
                                      model_types=['random_forest'], time_limit=300):
        """
        è‡ªåŠ¨åŒ–è¶…å‚æ•°è°ƒä¼˜

        Args:
            X_train, y_train: è®­ç»ƒæ•°æ®
            X_test, y_test: æµ‹è¯•æ•°æ®
            model_types: è¦è°ƒä¼˜çš„æ¨¡å‹ç±»å‹
            time_limit: æ—¶é—´é™åˆ¶ï¼ˆç§’ï¼‰

        Returns:
            è°ƒä¼˜ç»“æœæ‘˜è¦
        """
        print("ğŸ¤– å¼€å§‹è‡ªåŠ¨åŒ–è¶…å‚æ•°è°ƒä¼˜...")
        print(f"  æ—¶é—´é™åˆ¶: {time_limit}ç§’")
        print(f"  è°ƒä¼˜æ¨¡å‹: {model_types}")

        import time
        start_time = time.time()
        results = {}

        for model_type in model_types:
            if time.time() - start_time > time_limit:
                print(f"â° æ—¶é—´é™åˆ¶è¾¾åˆ°ï¼Œåœæ­¢è°ƒä¼˜")
                break

            print(f"\n  è°ƒä¼˜ {model_type}...")

            try:
                if model_type == 'random_forest':
                    # å¿«é€Ÿéšæœºæœç´¢
                    model, params, score = self.optimize_random_forest(
                        X_train, y_train, X_test, y_test,
                        optimization_method='random', n_iter=20, cv_folds=3
                    )
                    results[model_type] = {
                        'model': model,
                        'best_params': params,
                        'best_score': score
                    }

                elif model_type == 'linear_regression':
                    model, importance, score = self.optimize_linear_regression(
                        X_train, y_train, X_test, y_test
                    )
                    results[model_type] = {
                        'model': model,
                        'feature_importance': importance,
                        'score': score
                    }

            except Exception as e:
                print(f"    âŒ è°ƒä¼˜å¤±è´¥: {str(e)}")
                continue

        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        best_model_type = None
        best_score = -np.inf

        for model_type, result in results.items():
            score = result.get('best_score', result.get('score', 0))
            if score > best_score:
                best_score = score
                best_model_type = model_type

        elapsed_time = time.time() - start_time

        print(f"\nâœ… è‡ªåŠ¨è°ƒä¼˜å®Œæˆ (è€—æ—¶: {elapsed_time:.1f}ç§’)")
        if best_model_type:
            print(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model_type} (RÂ²: {best_score:.4f})")

        return results, best_model_type, elapsed_time

    def generate_optimization_report(self, output_path='optimization_report.md'):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        print("ğŸ“‹ ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š...")

        report = "# æ¨¡å‹ä¼˜åŒ–æŠ¥å‘Š\n\n"
        report += f"ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now()}\n\n"

        # éšæœºæ£®æ—ä¼˜åŒ–ç»“æœ
        if 'random_forest' in self.optimization_history:
            rf_result = self.optimization_history['random_forest']
            report += "## éšæœºæ£®æ—ä¼˜åŒ–\n\n"
            report += f"æœ€ä½³å‚æ•°: {rf_result['best_params']}\n\n"
            report += f"äº¤å‰éªŒè¯RÂ²: {rf_result['best_cv_score']:.4f}\n\n"
            if rf_result.get('test_score'):
                report += f"æµ‹è¯•é›†RÂ²: {rf_result['test_score']:.4f}\n\n"

        # çº¿æ€§å›å½’ä¼˜åŒ–ç»“æœ
        if 'linear_regression' in self.optimization_history:
            lr_result = self.optimization_history['linear_regression']
            report += "## çº¿æ€§å›å½’ä¼˜åŒ–\n\n"
            cv_scores = lr_result['cv_scores']
            report += f"äº¤å‰éªŒè¯RÂ²: {np.mean(cv_scores):.4f} (Â±{np.std(cv_scores):.4f})\n\n"
            if lr_result.get('test_score'):
                report += f"æµ‹è¯•é›†RÂ²: {lr_result['test_score']:.4f}\n\n"

        # ä¿å­˜æŠ¥å‘Š
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"âœ… ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
        return output_path