#!/usr/bin/env python3
"""
éƒ¨ç½²ç®¡ç†å™¨
æä¾›LTVé¢„æµ‹æŠ€èƒ½çš„éƒ¨ç½²ã€é›†æˆå’Œç®¡ç†åŠŸèƒ½
"""

import os
import json
import pickle
import joblib
import pandas as pd
from pathlib import Path
from typing import Dict, Any, List, Optional
import shutil
import zipfile
from datetime import datetime

class DeploymentManager:
    """éƒ¨ç½²ç®¡ç†å™¨ç±»"""

    def __init__(self, skill_dir: str = None):
        """
        åˆå§‹åŒ–éƒ¨ç½²ç®¡ç†å™¨

        Args:
            skill_dir: æŠ€èƒ½æ ¹ç›®å½•
        """
        if skill_dir is None:
            # é»˜è®¤ä¸ºå½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•çš„ä¸Šçº§ç›®å½•
            self.skill_dir = Path(__file__).parent.parent
        else:
            self.skill_dir = Path(skill_dir)

        self.config_dir = self.skill_dir / 'config'
        self.models_dir = self.skill_dir / 'models'
        self.data_dir = self.skill_dir / 'data'
        self.docs_dir = self.skill_dir / 'docs'

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        for dir_path in [self.config_dir, self.models_dir, self.data_dir, self.docs_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)

    def create_deployment_package(self, output_path: str = None,
                                include_models: bool = True,
                                include_data: bool = False,
                                include_docs: bool = True) -> str:
        """
        åˆ›å»ºéƒ¨ç½²åŒ…

        Args:
            output_path: è¾“å‡ºè·¯å¾„
            include_models: æ˜¯å¦åŒ…å«æ¨¡å‹æ–‡ä»¶
            include_data: æ˜¯å¦åŒ…å«æ•°æ®æ–‡ä»¶
            include_docs: æ˜¯å¦åŒ…å«æ–‡æ¡£

        Returns:
            éƒ¨ç½²åŒ…è·¯å¾„
        """
        print("ğŸ“¦ åˆ›å»ºéƒ¨ç½²åŒ…...")

        if output_path is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_path = f"ltv_predictor_deployment_{timestamp}.zip"

        output_path = Path(output_path)

        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = self.skill_dir / 'temp_deployment'
        if temp_dir.exists():
            shutil.rmtree(temp_dir)
        temp_dir.mkdir()

        try:
            # å¤åˆ¶æ ¸å¿ƒæ–‡ä»¶
            self._copy_core_files(temp_dir)

            # å¤åˆ¶æ¨¡å‹æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if include_models:
                self._copy_models(temp_dir)

            # å¤åˆ¶æ•°æ®æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if include_data:
                self._copy_data(temp_dir)

            # å¤åˆ¶æ–‡æ¡£ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if include_docs:
                self._copy_docs(temp_dir)

            # åˆ›å»ºéƒ¨ç½²é…ç½®
            self._create_deployment_config(temp_dir)

            # åˆ›å»ºå¯åŠ¨è„šæœ¬
            self._create_startup_scripts(temp_dir)

            # åˆ›å»ºZIPåŒ…
            with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file_path in temp_dir.rglob('*'):
                    if file_path.is_file():
                        arcname = file_path.relative_to(temp_dir)
                        zipf.write(file_path, arcname)

            print(f"âœ… éƒ¨ç½²åŒ…å·²åˆ›å»º: {output_path}")
            print(f"   åŒ…å¤§å°: {output_path.stat().st_size / 1024 / 1024:.1f} MB")

        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            if temp_dir.exists():
                shutil.rmtree(temp_dir)

        return str(output_path)

    def _copy_core_files(self, temp_dir: Path):
        """å¤åˆ¶æ ¸å¿ƒæ–‡ä»¶"""
        print("  å¤åˆ¶æ ¸å¿ƒæ–‡ä»¶...")

        core_files = [
            'scripts/data_processor.py',
            'scripts/regression_models.py',
            'scripts/ltv_predictor.py',
            'scripts/visualizer.py',
            'scripts/report_generator.py',
            'scripts/quick_analysis.py',
            'scripts/model_optimizer.py',
            'scripts/advanced_analytics.py',
            'scripts/deployment_manager.py',
            'SKILL.md',
            'README.md'
        ]

        for file_path in core_files:
            src = self.skill_dir / file_path
            if src.exists():
                dst = temp_dir / file_path
                dst.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(src, dst)
                print(f"    âœ“ {file_path}")

    def _copy_models(self, temp_dir: Path):
        """å¤åˆ¶æ¨¡å‹æ–‡ä»¶"""
        print("  å¤åˆ¶æ¨¡å‹æ–‡ä»¶...")

        models_src = self.skill_dir / 'models'
        if models_src.exists():
            models_dst = temp_dir / 'models'
            shutil.copytree(models_src, models_dst, dirs_exist_ok=True)
            print(f"    âœ“ æ¨¡å‹æ–‡ä»¶å·²å¤åˆ¶")

    def _copy_data(self, temp_dir: Path):
        """å¤åˆ¶æ•°æ®æ–‡ä»¶"""
        print("  å¤åˆ¶æ•°æ®æ–‡ä»¶...")

        data_src = self.skill_dir / 'data'
        if data_src.exists():
            data_dst = temp_dir / 'data'
            shutil.copytree(data_src, data_dst, dirs_exist_ok=True)
            print(f"    âœ“ æ•°æ®æ–‡ä»¶å·²å¤åˆ¶")

    def _copy_docs(self, temp_dir: Path):
        """å¤åˆ¶æ–‡æ¡£æ–‡ä»¶"""
        print("  å¤åˆ¶æ–‡æ¡£æ–‡ä»¶...")

        docs_src = self.skill_dir / 'docs'
        if docs_src.exists():
            docs_dst = temp_dir / 'docs'
            shutil.copytree(docs_src, docs_dst, dirs_exist_ok=True)
            print(f"    âœ“ æ–‡æ¡£æ–‡ä»¶å·²å¤åˆ¶")

        examples_src = self.skill_dir / 'examples'
        if examples_src.exists():
            examples_dst = temp_dir / 'examples'
            shutil.copytree(examples_src, examples_dst, dirs_exist_ok=True)
            print(f"    âœ“ ç¤ºä¾‹æ–‡ä»¶å·²å¤åˆ¶")

    def _create_deployment_config(self, temp_dir: Path):
        """åˆ›å»ºéƒ¨ç½²é…ç½®"""
        config = {
            'skill_info': {
                'name': 'ltv-predictor',
                'version': '1.0.0',
                'description': 'å®¢æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼é¢„æµ‹æŠ€èƒ½',
                'author': 'Claude Code',
                'created_at': datetime.now().isoformat()
            },
            'dependencies': [
                'pandas>=1.3.0',
                'numpy>=1.21.0',
                'scikit-learn>=1.0.0',
                'matplotlib>=3.5.0',
                'seaborn>=0.11.0',
                'openpyxl>=3.0.0'
            ],
            'default_config': {
                'feature_period_months': 3,
                'prediction_period_months': 12,
                'models_to_train': ['linear_regression', 'random_forest'],
                'enable_visualization': True,
                'enable_reports': True
            },
            'api_endpoints': {
                'analyze': '/api/v1/analyze',
                'predict': '/api/v1/predict',
                'batch_predict': '/api/v1/batch_predict',
                'model_info': '/api/v1/model_info'
            }
        }

        config_path = temp_dir / 'deployment_config.json'
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)

        print(f"    âœ“ éƒ¨ç½²é…ç½®å·²åˆ›å»º")

    def _create_startup_scripts(self, temp_dir: Path):
        """åˆ›å»ºå¯åŠ¨è„šæœ¬"""
        # åˆ›å»ºWindowsæ‰¹å¤„ç†æ–‡ä»¶
        windows_script = '''@echo off
echo å¯åŠ¨LTVé¢„æµ‹æŠ€èƒ½æœåŠ¡...
python scripts/deployment_manager.py start_server
pause
'''
        with open(temp_dir / 'start.bat', 'w', encoding='utf-8') as f:
            f.write(windows_script)

        # åˆ›å»ºLinux/Mac shellè„šæœ¬
        linux_script = '''#!/bin/bash
echo "å¯åŠ¨LTVé¢„æµ‹æŠ€èƒ½æœåŠ¡..."
python scripts/deployment_manager.py start_server
'''
        with open(temp_dir / 'start.sh', 'w', encoding='utf-8') as f:
            f.write(linux_script)

        # ä½¿shellè„šæœ¬å¯æ‰§è¡Œ
        os.chmod(temp_dir / 'start.sh', 0o755)

        print(f"    âœ“ å¯åŠ¨è„šæœ¬å·²åˆ›å»º")

    def validate_deployment(self, deployment_path: str) -> Dict[str, Any]:
        """
        éªŒè¯éƒ¨ç½²åŒ…

        Args:
            deployment_path: éƒ¨ç½²åŒ…è·¯å¾„

        Returns:
            éªŒè¯ç»“æœ
        """
        print("ğŸ” éªŒè¯éƒ¨ç½²åŒ…...")

        deployment_path = Path(deployment_path)
        validation_result = {
            'is_valid': True,
            'errors': [],
            'warnings': [],
            'file_count': 0,
            'total_size': 0
        }

        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not deployment_path.exists():
                validation_result['is_valid'] = False
                validation_result['errors'].append("éƒ¨ç½²åŒ…æ–‡ä»¶ä¸å­˜åœ¨")
                return validation_result

            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            size_mb = deployment_path.stat().st_size / 1024 / 1024
            validation_result['total_size'] = size_mb

            if size_mb > 100:
                validation_result['warnings'].append("éƒ¨ç½²åŒ…è¾ƒå¤§ï¼Œå»ºè®®ä¼˜åŒ–å¤§å°")

            # æ£€æŸ¥ZIPæ–‡ä»¶å®Œæ•´æ€§
            with zipfile.ZipFile(deployment_path, 'r') as zipf:
                validation_result['file_count'] = len(zipf.namelist())

                # æ£€æŸ¥å¿…è¦æ–‡ä»¶
                required_files = [
                    'scripts/ltv_predictor.py',
                    'scripts/quick_analysis.py',
                    'deployment_config.json'
                ]

                for required_file in required_files:
                    if required_file not in zipf.namelist():
                        validation_result['is_valid'] = False
                        validation_result['errors'].append(f"ç¼ºå°‘å¿…è¦æ–‡ä»¶: {required_file}")

            print(f"âœ… éƒ¨ç½²åŒ…éªŒè¯å®Œæˆ")
            print(f"   æ–‡ä»¶æ•°é‡: {validation_result['file_count']}")
            print(f"   åŒ…å¤§å°: {size_mb:.1f} MB")
            print(f"   éªŒè¯çŠ¶æ€: {'é€šè¿‡' if validation_result['is_valid'] else 'å¤±è´¥'}")

            if validation_result['warnings']:
                print(f"   è­¦å‘Š: {len(validation_result['warnings'])}ä¸ª")

        except Exception as e:
            validation_result['is_valid'] = False
            validation_result['errors'].append(f"éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")

        return validation_result

    def install_dependencies(self) -> bool:
        """
        å®‰è£…ä¾èµ–åŒ…

        Returns:
            æ˜¯å¦å®‰è£…æˆåŠŸ
        """
        print("ğŸ“¦ å®‰è£…ä¾èµ–åŒ…...")

        dependencies = [
            'pandas>=1.3.0',
            'numpy>=1.21.0',
            'scikit-learn>=1.0.0',
            'matplotlib>=3.5.0',
            'seaborn>=0.11.0',
            'openpyxl>=3.0.0'
        ]

        try:
            import subprocess
            for dep in dependencies:
                print(f"  å®‰è£… {dep}...")
                result = subprocess.run(['pip', 'install', dep],
                                      capture_output=True, text=True)
                if result.returncode != 0:
                    print(f"    âŒ å®‰è£…å¤±è´¥: {result.stderr}")
                    return False
                print(f"    âœ“ {dep}")

            print("âœ… æ‰€æœ‰ä¾èµ–åŒ…å®‰è£…æˆåŠŸ")
            return True

        except Exception as e:
            print(f"âŒ ä¾èµ–åŒ…å®‰è£…å¤±è´¥: {str(e)}")
            return False

    def setup_environment(self) -> bool:
        """
        è®¾ç½®è¿è¡Œç¯å¢ƒ

        Returns:
            æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        print("ğŸ”§ è®¾ç½®è¿è¡Œç¯å¢ƒ...")

        try:
            # åˆ›å»ºå¿…è¦çš„ç›®å½•
            directories = [
                'logs',
                'temp',
                'output',
                'models/trained',
                'data/upload',
                'reports'
            ]

            for directory in directories:
                dir_path = self.skill_dir / directory
                dir_path.mkdir(parents=True, exist_ok=True)
                print(f"    âœ“ åˆ›å»ºç›®å½•: {directory}")

            # åˆ›å»ºç¯å¢ƒé…ç½®æ–‡ä»¶
            env_config = {
                'LOG_LEVEL': 'INFO',
                'MAX_UPLOAD_SIZE': '100MB',
                'DEFAULT_MODEL': 'random_forest',
                'CACHE_TIMEOUT': 3600,
                'ENABLE_MONITORING': True
            }

            env_path = self.skill_dir / '.env'
            with open(env_path, 'w', encoding='utf-8') as f:
                for key, value in env_config.items():
                    f.write(f"{key}={value}\n")

            print("    âœ“ ç¯å¢ƒé…ç½®å·²åˆ›å»º")

            print("âœ… è¿è¡Œç¯å¢ƒè®¾ç½®å®Œæˆ")
            return True

        except Exception as e:
            print(f"âŒ ç¯å¢ƒè®¾ç½®å¤±è´¥: {str(e)}")
            return False

    def create_api_server(self) -> str:
        """
        åˆ›å»ºAPIæœåŠ¡å™¨è„šæœ¬

        Returns:
            APIæœåŠ¡å™¨è„šæœ¬è·¯å¾„
        """
        print("ğŸŒ åˆ›å»ºAPIæœåŠ¡å™¨...")

        api_script = '''#!/usr/bin/env python3
"""
LTVé¢„æµ‹æŠ€èƒ½APIæœåŠ¡å™¨
æä¾›RESTful APIæ¥å£
"""

import json
import os
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ æŠ€èƒ½æ¨¡å—è·¯å¾„
current_dir = Path(__file__).parent
sys.path.append(str(current_dir / 'scripts'))

try:
    from flask import Flask, request, jsonify
    from quick_analysis import quick_ltv_analysis, predict_new_customers
    from ltv_predictor import LTVPredictor
except ImportError as e:
    print(f"ç¼ºå°‘ä¾èµ–åŒ…: {e}")
    print("è¯·è¿è¡Œ: pip install flask")
    sys.exit(1)

app = Flask(__name__)

# å…¨å±€å˜é‡
predictor = None

@app.route('/api/v1/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'version': '1.0.0'
    })

@app.route('/api/v1/analyze', methods=['POST'])
def analyze_data():
    """åˆ†ææ•°æ®å¹¶è®­ç»ƒæ¨¡å‹"""
    try:
        data = request.get_json()

        # éªŒè¯è¾“å…¥å‚æ•°
        if 'data_file' not in data:
            return jsonify({'error': 'ç¼ºå°‘data_fileå‚æ•°'}), 400

        # æ‰§è¡Œåˆ†æ
        results = quick_ltv_analysis(
            file_path=data['data_file'],
            feature_period_months=data.get('feature_period_months', 3),
            prediction_period_months=data.get('prediction_period_months', 12),
            output_dir=data.get('output_dir', './api_results'),
            generate_charts=data.get('generate_charts', True),
            generate_reports=data.get('generate_reports', True)
        )

        return jsonify({
            'status': 'success',
            'results': {
                'best_model': results['summary']['model_summary']['best_model'],
                'r2_score': results['summary']['model_summary']['best_r2_score'],
                'total_customers': results['summary']['data_summary']['total_customers'],
                'avg_ltv': results['summary']['data_summary']['avg_ltv']
            }
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/v1/predict', methods=['POST'])
def predict_ltv():
    """é¢„æµ‹æ–°å®¢æˆ·LTV"""
    try:
        data = request.get_json()

        if 'model_dir' not in data or 'new_orders_file' not in data:
            return jsonify({'error': 'ç¼ºå°‘å¿…è¦å‚æ•°'}), 400

        # æ‰§è¡Œé¢„æµ‹
        predictions = predict_new_customers(
            data['model_dir'],
            data['new_orders_file'],
            data.get('output_path', 'api_predictions.csv')
        )

        return jsonify({
            'status': 'success',
            'predictions_count': len(predictions),
            'avg_predicted_ltv': predictions['é¢„æµ‹LTV'].mean(),
            'max_predicted_ltv': predictions['é¢„æµ‹LTV'].max(),
            'min_predicted_ltv': predictions['é¢„æµ‹LTV'].min()
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/v1/model_info', methods=['GET'])
def get_model_info():
    """è·å–æ¨¡å‹ä¿¡æ¯"""
    return jsonify({
        'available_models': ['linear_regression', 'random_forest'],
        'default_features': ['Rå€¼', 'Få€¼', 'Må€¼'],
        'supported_formats': ['csv', 'xlsx'],
        'version': '1.0.0'
    })

if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨LTVé¢„æµ‹APIæœåŠ¡å™¨...")
    print("ğŸ“¡ æœåŠ¡åœ°å€: http://localhost:5000")
    print("ğŸ“– APIæ–‡æ¡£: http://localhost:5000/api/v1/model_info")

    app.run(host='0.0.0.0', port=5000, debug=True)
'''

        api_path = self.skill_dir / 'api_server.py'
        with open(api_path, 'w', encoding='utf-8') as f:
            f.write(api_script)

        print(f"âœ… APIæœåŠ¡å™¨è„šæœ¬å·²åˆ›å»º: {api_path}")
        return str(api_path)

    def start_server(self, host='localhost', port=5000):
        """
        å¯åŠ¨APIæœåŠ¡å™¨

        Args:
            host: ä¸»æœºåœ°å€
            port: ç«¯å£å·
        """
        print(f"ğŸš€ å¯åŠ¨æœåŠ¡å™¨ {host}:{port}...")

        try:
            # æ£€æŸ¥Flaskæ˜¯å¦å®‰è£…
            import flask
        except ImportError:
            print("âŒ ç¼ºå°‘Flaskä¾èµ–åŒ…")
            print("è¯·è¿è¡Œ: pip install flask")
            return

        # åˆ›å»ºå¹¶å¯åŠ¨APIæœåŠ¡å™¨
        api_path = self.create_api_server()
        os.system(f"python {api_path}")

    def generate_deployment_guide(self, output_path: str = None) -> str:
        """
        ç”Ÿæˆéƒ¨ç½²æŒ‡å—

        Args:
            output_path: è¾“å‡ºè·¯å¾„

        Returns:
            éƒ¨ç½²æŒ‡å—è·¯å¾„
        """
        print("ğŸ“– ç”Ÿæˆéƒ¨ç½²æŒ‡å—...")

        if output_path is None:
            output_path = self.skill_dir / 'DEPLOYMENT_GUIDE.md'

        guide = '''# LTVé¢„æµ‹æŠ€èƒ½éƒ¨ç½²æŒ‡å—

## ç³»ç»Ÿè¦æ±‚

- Python 3.7+
- å†…å­˜: æœ€å°‘2GBï¼Œæ¨è4GB+
- å­˜å‚¨: æœ€å°‘1GBå¯ç”¨ç©ºé—´

## å¿«é€Ÿéƒ¨ç½²

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…Pythonä¾èµ–
pip install pandas numpy scikit-learn matplotlib seaborn openpyxl flask

# æˆ–ä½¿ç”¨requirements.txt
pip install -r requirements.txt
```

### 2. éƒ¨ç½²åŒ…éƒ¨ç½²

```bash
# è§£å‹éƒ¨ç½²åŒ…
unzip ltv_predictor_deployment_*.zip
cd ltv_predictor

# å®‰è£…ä¾èµ–
python scripts/deployment_manager.py install_dependencies

# è®¾ç½®ç¯å¢ƒ
python scripts/deployment_manager.py setup_environment
```

### 3. å¯åŠ¨æœåŠ¡

#### æ–¹å¼1: å‘½ä»¤è¡Œå·¥å…·
```bash
# Windows
start.bat

# Linux/Mac
./start.sh
```

#### æ–¹å¼2: Pythonè„šæœ¬
```bash
python scripts/deployment_manager.py start_server
```

#### æ–¹å¼3: ç›´æ¥å¯åŠ¨API
```bash
python api_server.py
```

## APIæ¥å£

### å¥åº·æ£€æŸ¥
```http
GET /api/v1/health
```

### æ•°æ®åˆ†æ
```http
POST /api/v1/analyze
Content-Type: application/json

{
  "data_file": "path/to/your/data.csv",
  "feature_period_months": 3,
  "prediction_period_months": 12,
  "output_dir": "./results"
}
```

### LTVé¢„æµ‹
```http
POST /api/v1/predict
Content-Type: application/json

{
  "model_dir": "./models",
  "new_orders_file": "new_customers.csv",
  "output_path": "predictions.csv"
}
```

## ä½¿ç”¨ç¤ºä¾‹

### Pythonå®¢æˆ·ç«¯
```python
import requests

# åˆ†ææ•°æ®
response = requests.post('http://localhost:5000/api/v1/analyze', json={
    'data_file': 'data/orders.csv'
})
result = response.json()

# é¢„æµ‹LTV
response = requests.post('http://localhost:5000/api/v1/predict', json={
    'model_dir': './models',
    'new_orders_file': 'new_customers.csv'
})
predictions = response.json()
```

### å‘½ä»¤è¡Œå·¥å…·
```bash
# åŸºç¡€åˆ†æ
python scripts/quick_analysis.py analyze data/orders.csv

# é¢„æµ‹æ–°å®¢æˆ·
python scripts/quick_analysis.py predict ./models new_customers.csv

# æ‰¹é‡é¢„æµ‹
python scripts/quick_analysis.py batch ./models rfm_features.csv
```

## é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡
- `LOG_LEVEL`: æ—¥å¿—çº§åˆ« (DEBUG/INFO/WARNING/ERROR)
- `MAX_UPLOAD_SIZE`: æœ€å¤§ä¸Šä¼ æ–‡ä»¶å¤§å°
- `DEFAULT_MODEL`: é»˜è®¤æ¨¡å‹ (linear_regression/random_forest)
- `ENABLE_MONITORING`: æ˜¯å¦å¯ç”¨ç›‘æ§

### é…ç½®æ–‡ä»¶
ç¼–è¾‘ `deployment_config.json` æ–‡ä»¶æ¥è‡ªå®šä¹‰é…ç½®ã€‚

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ä¾èµ–åŒ…å®‰è£…å¤±è´¥**
   ```bash
   # ä½¿ç”¨å›½å†…é•œåƒ
   pip install -i https://pypi.tuna.tsinghua.edu.cn/simple/ åŒ…å
   ```

2. **å†…å­˜ä¸è¶³**
   - å‡å°‘æ•°æ®é›†å¤§å°
   - è°ƒæ•´æ¨¡å‹å‚æ•°
   - å¢åŠ ç³»ç»Ÿå†…å­˜

3. **æ¨¡å‹è®­ç»ƒæ…¢**
   - å¯ç”¨å¹¶è¡Œå¤„ç†: `n_jobs=-1`
   - å‡å°‘äº¤å‰éªŒè¯æŠ˜æ•°
   - ä½¿ç”¨æ›´ç®€å•çš„æ¨¡å‹

4. **APIæœåŠ¡æ— æ³•å¯åŠ¨**
   - æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
   - ç¡®è®¤Flaskä¾èµ–å·²å®‰è£…
   - æŸ¥çœ‹é”™è¯¯æ—¥å¿—

### æ—¥å¿—æŸ¥çœ‹
```bash
# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
tail -f logs/application.log

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f logs/error.log
```

## æ€§èƒ½ä¼˜åŒ–

### æ•°æ®ä¼˜åŒ–
- ä½¿ç”¨CSVæ ¼å¼è€Œä¸æ˜¯Excel
- é¢„å¤„ç†æ•°æ®å»é™¤å¼‚å¸¸å€¼
- åˆç†è®¾ç½®æ—¶é—´çª—å£

### æ¨¡å‹ä¼˜åŒ–
- å¯ç”¨è¶…å‚æ•°è°ƒä¼˜
- ä½¿ç”¨ç‰¹å¾é€‰æ‹©
- è€ƒè™‘æ¨¡å‹é›†æˆ

### ç³»ç»Ÿä¼˜åŒ–
- å¢åŠ å†…å­˜é…ç½®
- ä½¿ç”¨SSDå­˜å‚¨
- å¯ç”¨ç¼“å­˜æœºåˆ¶

## ç›‘æ§å’Œç»´æŠ¤

### æ€§èƒ½ç›‘æ§
- APIå“åº”æ—¶é—´
- æ¨¡å‹é¢„æµ‹å‡†ç¡®æ€§
- ç³»ç»Ÿèµ„æºä½¿ç”¨ç‡

### å®šæœŸç»´æŠ¤
- æ›´æ–°ä¾èµ–åŒ…ç‰ˆæœ¬
- é‡æ–°è®­ç»ƒæ¨¡å‹
- æ¸…ç†ä¸´æ—¶æ–‡ä»¶

## æŠ€æœ¯æ”¯æŒ

å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š
1. æŸ¥çœ‹æœ¬æ–‡æ¡£çš„æ•…éšœæ’é™¤éƒ¨åˆ†
2. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯
3. æäº¤Issueæˆ–è”ç³»æŠ€æœ¯æ”¯æŒ

---

**ç‰ˆæœ¬**: 1.0.0
**æ›´æ–°æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d')}
'''

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(guide)

        print(f"âœ… éƒ¨ç½²æŒ‡å—å·²åˆ›å»º: {output_path}")
        return str(output_path)

def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description='LTVé¢„æµ‹æŠ€èƒ½éƒ¨ç½²ç®¡ç†å™¨')
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')

    # åˆ›å»ºéƒ¨ç½²åŒ…å‘½ä»¤
    package_parser = subparsers.add_parser('package', help='åˆ›å»ºéƒ¨ç½²åŒ…')
    package_parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    package_parser.add_argument('--no-models', action='store_true', help='ä¸åŒ…å«æ¨¡å‹æ–‡ä»¶')
    package_parser.add_argument('--include-data', action='store_true', help='åŒ…å«æ•°æ®æ–‡ä»¶')
    package_parser.add_argument('--no-docs', action='store_true', help='ä¸åŒ…å«æ–‡æ¡£')

    # éªŒè¯éƒ¨ç½²åŒ…å‘½ä»¤
    validate_parser = subparsers.add_parser('validate', help='éªŒè¯éƒ¨ç½²åŒ…')
    validate_parser.add_argument('package_path', help='éƒ¨ç½²åŒ…è·¯å¾„')

    # å®‰è£…ä¾èµ–å‘½ä»¤
    subparsers.add_parser('install', help='å®‰è£…ä¾èµ–åŒ…')

    # è®¾ç½®ç¯å¢ƒå‘½ä»¤
    subparsers.add_parser('setup', help='è®¾ç½®è¿è¡Œç¯å¢ƒ')

    # å¯åŠ¨æœåŠ¡å™¨å‘½ä»¤
    server_parser = subparsers.add_parser('start_server', help='å¯åŠ¨APIæœåŠ¡å™¨')
    server_parser.add_argument('--host', default='localhost', help='ä¸»æœºåœ°å€')
    server_parser.add_argument('--port', type=int, default=5000, help='ç«¯å£å·')

    # ç”ŸæˆæŒ‡å—å‘½ä»¤
    guide_parser = subparsers.add_parser('guide', help='ç”Ÿæˆéƒ¨ç½²æŒ‡å—')
    guide_parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    if args.command == 'package':
        # åˆ›å»ºéƒ¨ç½²åŒ…
        manager = DeploymentManager()
        manager.create_deployment_package(
            output_path=args.output,
            include_models=not args.no_models,
            include_data=args.include_data,
            include_docs=not args.no_docs
        )

    elif args.command == 'validate':
        # éªŒè¯éƒ¨ç½²åŒ…
        manager = DeploymentManager()
        result = manager.validate_deployment(args.package_path)
        print(f"éªŒè¯ç»“æœ: {'é€šè¿‡' if result['is_valid'] else 'å¤±è´¥'}")
        if result['errors']:
            print("é”™è¯¯:")
            for error in result['errors']:
                print(f"  - {error}")
        if result['warnings']:
            print("è­¦å‘Š:")
            for warning in result['warnings']:
                print(f"  - {warning}")

    elif args.command == 'install':
        # å®‰è£…ä¾èµ–
        manager = DeploymentManager()
        success = manager.install_dependencies()
        if success:
            print("ä¾èµ–å®‰è£…æˆåŠŸ")
        else:
            print("ä¾èµ–å®‰è£…å¤±è´¥")

    elif args.command == 'setup':
        # è®¾ç½®ç¯å¢ƒ
        manager = DeploymentManager()
        success = manager.setup_environment()
        if success:
            print("ç¯å¢ƒè®¾ç½®æˆåŠŸ")
        else:
            print("ç¯å¢ƒè®¾ç½®å¤±è´¥")

    elif args.command == 'start_server':
        # å¯åŠ¨æœåŠ¡å™¨
        manager = DeploymentManager()
        manager.start_server(args.host, args.port)

    elif args.command == 'guide':
        # ç”ŸæˆæŒ‡å—
        manager = DeploymentManager()
        guide_path = manager.generate_deployment_guide(args.output)
        print(f"éƒ¨ç½²æŒ‡å—å·²ç”Ÿæˆ: {guide_path}")

    else:
        parser.print_help()

if __name__ == '__main__':
    main()