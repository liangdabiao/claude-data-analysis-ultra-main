#!/usr/bin/env python3
"""
LTVé¢„æµ‹å¼•æ“
æ•´åˆæ•°æ®é¢„å¤„ç†ã€RFMåˆ†æå’Œå›å½’å»ºæ¨¡çš„å®Œæ•´LTVé¢„æµ‹æµç¨‹
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Union, Any
import os
import json
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

from data_processor import DataProcessor
from regression_models import RegressionModels

class LTVPredictor:
    """
    LTVé¢„æµ‹å¼•æ“

    æ•´åˆæ•°æ®é¢„å¤„ç†ã€RFMåˆ†æå’Œå›å½’å»ºæ¨¡çš„å®Œæ•´æµç¨‹
    åŸºäºç¬¬3è¯¾ç†è®ºå®ç°çš„å®¢æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼é¢„æµ‹ç³»ç»Ÿ
    """

    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–LTVé¢„æµ‹å™¨

        Args:
            config: é…ç½®å‚æ•°å­—å…¸
        """
        # é»˜è®¤é…ç½®
        self.config = {
            'data_processor_config': {
                'feature_period_months': 3,
                'prediction_period_months': 12,
                'remove_outliers': True,
                'min_orders_per_customer': 1
            },
            'regression_config': {
                'test_size': 0.2,
                'cv_folds': 5,
                'scoring_metric': 'r2',
                'enable_hyperparameter_tuning': False
            },
            'feature_columns': ['Rå€¼', 'Få€¼', 'Må€¼'],
            'target_column': 'å¹´åº¦LTV',
            'models_to_train': ['linear_regression', 'random_forest'],
            'customer_column': 'ç”¨æˆ·ç '
        }

        # æ›´æ–°é…ç½®
        if config:
            self.config.update(config)
            if 'data_processor_config' in config:
                self.config['data_processor_config'].update(config['data_processor_config'])
            if 'regression_config' in config:
                self.config['regression_config'].update(config['regression_config'])

        # åˆå§‹åŒ–ç»„ä»¶
        self.data_processor = DataProcessor(self.config['data_processor_config'])
        self.regression_models = RegressionModels(self.config['regression_config'])

        # ç»“æœå­˜å‚¨
        self.training_results = None
        self.model_results = None
        self.predictions = None
        self.feature_importance = None
        self.summary_report = None

        print("ğŸš€ LTVé¢„æµ‹å¼•æ“åˆå§‹åŒ–å®Œæˆ")

    def load_and_preprocess_data(self, file_path: str, **kwargs) -> pd.DataFrame:
        """
        åŠ è½½å’Œé¢„å¤„ç†æ•°æ®

        Args:
            file_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            **kwargs: åŠ è½½å‚æ•°

        Returns:
            é¢„å¤„ç†åçš„æ•°æ®
        """
        print("ğŸ“ å¼€å§‹æ•°æ®åŠ è½½å’Œé¢„å¤„ç†...")

        # åŠ è½½æ•°æ®
        raw_data = self.data_processor.load_order_data(file_path, **kwargs)

        # é¢„å¤„ç†æ•°æ®
        processed_data = self.data_processor.preprocess_data(raw_data)

        return processed_data

    def calculate_rfm_and_prepare_training_data(self, processed_data: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—RFMç‰¹å¾å¹¶å‡†å¤‡è®­ç»ƒæ•°æ®

        Args:
            processed_data: é¢„å¤„ç†åçš„è®¢å•æ•°æ®

        Returns:
            åŒ…å«RFMç‰¹å¾å’ŒLTVæ ‡ç­¾çš„è®­ç»ƒæ•°æ®
        """
        print("ğŸ” å¼€å§‹RFMç‰¹å¾è®¡ç®—å’Œè®­ç»ƒæ•°æ®å‡†å¤‡...")

        # è®¡ç®—RFMç‰¹å¾
        rfm_data = self.data_processor.calculate_rfm_features(processed_data)

        # å®¢æˆ·åˆ†ç¾¤
        segmented_data = self.data_processor.segment_customers(rfm_data)

        # è·å–RFMæ‘˜è¦
        rfm_summary = self.data_processor.get_rfm_summary(segmented_data)
        self.rfm_summary = rfm_summary

        print(f"âœ“ RFMåˆ†æå®Œæˆ:")
        print(f"  - æ€»å®¢æˆ·æ•°: {rfm_summary['total_customers']}")
        print(f"  - Rå€¼å‡å€¼: {rfm_summary['rfm_statistics']['Rå€¼']['mean']:.2f}")
        print(f"  - Få€¼å‡å€¼: {rfm_summary['rfm_statistics']['Få€¼']['mean']:.2f}")
        print(f"  - Må€¼å‡å€¼: {rfm_summary['rfm_statistics']['Må€¼']['mean']:.2f}")
        print(f"  - å¹´åº¦LTVå‡å€¼: {rfm_summary['rfm_statistics']['å¹´åº¦LTV']['mean']:.2f}")

        return segmented_data

    def train_models(self, rfm_data: pd.DataFrame, model_names: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        è®­ç»ƒLTVé¢„æµ‹æ¨¡å‹

        Args:
            rfm_data: RFMç‰¹å¾æ•°æ®
            model_names: è¦è®­ç»ƒçš„æ¨¡å‹åˆ—è¡¨

        Returns:
            è®­ç»ƒç»“æœå­—å…¸
        """
        print("ğŸ¤– å¼€å§‹æ¨¡å‹è®­ç»ƒ...")

        if model_names is None:
            model_names = self.config['models_to_train']

        # å‡†å¤‡è®­ç»ƒæ•°æ®
        feature_columns = self.config['feature_columns']
        target_column = self.config['target_column']

        X, y = self.regression_models.prepare_data(rfm_data, feature_columns, target_column)
        X_train, X_test, y_train, y_test = self.regression_models.split_data(X, y)

        # è®­ç»ƒå¤šä¸ªæ¨¡å‹
        model_results = self.regression_models.train_multiple_models(
            model_names, X_train, y_train, X_test, y_test
        )

        self.model_results = model_results
        self.training_data = {
            'X_train': X_train, 'X_test': X_test,
            'y_train': y_train, 'y_test': y_test
        }

        # æå–ç‰¹å¾é‡è¦æ€§
        self.feature_importance = self.regression_models.feature_importance

        return {
            'model_results': model_results,
            'training_data': self.training_data,
            'feature_importance': self.feature_importance,
            'best_model_name': self.regression_models.best_model_name,
            'rfm_summary': self.rfm_summary
        }

    def predict_ltv(self, data: Union[pd.DataFrame, Dict[str, float]],
                    model_name: Optional[str] = None) -> Union[np.ndarray, float]:
        """
        é¢„æµ‹å®¢æˆ·LTV

        Args:
            data: å®¢æˆ·æ•°æ®ï¼ˆDataFrameæˆ–å•ä¸ªå®¢æˆ·å­—å…¸ï¼‰
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°

        Returns:
            LTVé¢„æµ‹ç»“æœ
        """
        if self.model_results is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨train_models")

        if isinstance(data, dict):
            # å•ä¸ªå®¢æˆ·é¢„æµ‹
            return self._predict_single_customer(data, model_name)
        else:
            # æ‰¹é‡é¢„æµ‹
            return self._predict_batch(data, model_name)

    def _predict_single_customer(self, customer_data: Dict[str, float], model_name: Optional[str] = None) -> float:
        """
        é¢„æµ‹å•ä¸ªå®¢æˆ·çš„LTV

        Args:
            customer_data: å®¢æˆ·RFMç‰¹å¾å­—å…¸
            model_name: æ¨¡å‹åç§°

        Returns:
            LTVé¢„æµ‹å€¼
        """
        # å‡†å¤‡ç‰¹å¾æ•°æ®
        feature_columns = self.config['feature_columns']
        features = [customer_data.get(col, 0) for col in feature_columns]

        # è½¬æ¢ä¸ºDataFrame
        X = pd.DataFrame([features], columns=feature_columns)

        # é¢„æµ‹
        prediction = self.regression_models.predict(model_name, X)

        return float(prediction[0])

    def _predict_batch(self, customer_data: pd.DataFrame, model_name: Optional[str] = None) -> np.ndarray:
        """
        æ‰¹é‡é¢„æµ‹å®¢æˆ·LTV

        Args:
            customer_data: å®¢æˆ·RFMç‰¹å¾DataFrame
            model_name: æ¨¡å‹åç§°

        Returns:
            LTVé¢„æµ‹æ•°ç»„
        """
        # ç¡®ä¿åŒ…å«æ‰€éœ€ç‰¹å¾åˆ—
        feature_columns = self.config['feature_columns']
        missing_cols = [col for col in feature_columns if col not in customer_data.columns]

        if missing_cols:
            raise ValueError(f"æ•°æ®ç¼ºå°‘ç‰¹å¾åˆ—: {missing_cols}")

        X = customer_data[feature_columns]

        # é¢„æµ‹
        predictions = self.regression_models.predict(model_name, X)

        return predictions

    def predict_new_customers(self, customer_orders: pd.DataFrame,
                            model_name: Optional[str] = None) -> pd.DataFrame:
        """
        ä¸ºæ–°å®¢æˆ·é¢„æµ‹LTV

        Args:
            customer_orders: æ–°å®¢æˆ·çš„è®¢å•æ•°æ®
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°

        Returns:
            åŒ…å«LTVé¢„æµ‹çš„å®¢æˆ·æ•°æ®
        """
        print("ğŸ”® ä¸ºæ–°å®¢æˆ·é¢„æµ‹LTV...")

        # ä½¿ç”¨ç›¸åŒçš„é…ç½®è®¡ç®—RFMç‰¹å¾
        temp_processor = DataProcessor(self.config['data_processor_config'])

        # é¢„å¤„ç†æ–°å®¢æˆ·æ•°æ®
        processed_new_data = temp_processor.preprocess_data(customer_orders)

        # è®¡ç®—RFMç‰¹å¾ï¼ˆä»…ç‰¹å¾æœŸï¼‰
        feature_config = {
            'feature_period_months': self.config['data_processor_config']['feature_period_months'],
            'prediction_period_months': 0  # ä¸éœ€è¦LTVæ ‡ç­¾
        }

        # ä¸´æ—¶ä¿®æ”¹é…ç½®
        original_config = temp_processor.config.copy()
        temp_processor.config.update(feature_config)

        try:
            # è®¡ç®—RFMç‰¹å¾
            new_rfm = temp_processor.calculate_rfm_features(processed_new_data)
        except:
            # å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–çš„RFMè®¡ç®—
            print("  ä½¿ç”¨ç®€åŒ–RFMè®¡ç®—...")
            new_rfm = self._simple_rfm_calculation(processed_new_data)
        finally:
            # æ¢å¤é…ç½®
            temp_processor.config = original_config

        # é¢„æµ‹LTV
        feature_columns = self.config['feature_columns']
        X_new = new_rfm[feature_columns]
        predictions = self.regression_models.predict(model_name, X_new)

        # æ·»åŠ é¢„æµ‹ç»“æœ
        new_rfm['é¢„æµ‹LTV'] = predictions
        new_rfm['é¢„æµ‹æ—¶é—´'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        print(f"âœ“ å®Œæˆå¯¹{len(new_rfm)}ä¸ªæ–°å®¢æˆ·çš„LTVé¢„æµ‹")
        print(f"  - å¹³å‡é¢„æµ‹LTV: {predictions.mean():.2f}")
        print(f"  - é¢„æµ‹èŒƒå›´: {predictions.min():.2f} ~ {predictions.max():.2f}")

        return new_rfm

    def _simple_rfm_calculation(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        ç®€åŒ–çš„RFMè®¡ç®—ï¼ˆç”¨äºæ–°å®¢æˆ·ï¼‰

        Args:
            data: è®¢å•æ•°æ®

        Returns:
            RFMç‰¹å¾æ•°æ®
        """
        customer_col = self.config['customer_column']
        date_col = self.data_processor.config['date_column']

        # è·å–å”¯ä¸€å®¢æˆ·
        unique_customers = data[customer_col].unique()
        rfm_data = pd.DataFrame({customer_col: unique_customers})

        # è®¡ç®—Rå€¼ï¼ˆè·ä»Šå¤©æ•°ï¼‰
        latest_date = data[date_col].max()
        r_data = data.groupby(customer_col)[date_col].max().reset_index()
        r_data['Rå€¼'] = (latest_date - r_data[date_col]).dt.days
        rfm_data = rfm_data.merge(r_data[[customer_col, 'Rå€¼']], on=customer_col, how='left')

        # è®¡ç®—Få€¼
        f_data = data.groupby(customer_col)[date_col].count().reset_index()
        f_data.columns = [customer_col, 'Få€¼']
        rfm_data = rfm_data.merge(f_data, on=customer_col, how='left')

        # è®¡ç®—Må€¼
        if 'æ€»ä»·' not in data.columns:
            data['æ€»ä»·'] = data[self.data_processor.config['quantity_column']] * data[self.data_processor.config['price_column']]

        m_data = data.groupby(customer_col)['æ€»ä»·'].sum().reset_index()
        m_data.columns = [customer_col, 'Må€¼']
        rfm_data = rfm_data.merge(m_data, on=customer_col, how='left')

        return rfm_data

    def evaluate_prediction_accuracy(self, test_data: pd.DataFrame,
                                   actual_ltv_column: str = 'å¹´åº¦LTV') -> Dict[str, float]:
        """
        è¯„ä¼°é¢„æµ‹å‡†ç¡®æ€§

        Args:
            test_data: æµ‹è¯•æ•°æ®
            actual_ltv_column: å®é™…LTVåˆ—å

        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        if self.model_results is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨train_models")

        # é¢„æµ‹æµ‹è¯•é›†LTV
        feature_columns = self.config['feature_columns']
        X_test = test_data[feature_columns]
        y_true = test_data[actual_ltv_column]

        # ä½¿ç”¨æœ€ä½³æ¨¡å‹é¢„æµ‹
        y_pred = self.regression_models.predict(self.regression_models.best_model_name, X_test)

        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

        r2 = r2_score(y_true, y_pred)
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

        evaluation_metrics = {
            'r2_score': r2,
            'mae': mae,
            'rmse': rmse,
            'mape': mape,
            'mean_actual_ltv': y_true.mean(),
            'mean_predicted_ltv': y_pred.mean(),
            'total_customers': len(test_data)
        }

        print(f"ğŸ“Š é¢„æµ‹å‡†ç¡®æ€§è¯„ä¼°:")
        print(f"  - RÂ² åˆ†æ•°: {r2:.4f}")
        print(f"  - å¹³å‡ç»å¯¹è¯¯å·®: {mae:.2f}")
        print(f"  - å‡æ–¹æ ¹è¯¯å·®: {rmse:.2f}")
        print(f"  - å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®: {mape:.2f}%")
        print(f"  - å®é™…å¹³å‡LTV: {y_true.mean():.2f}")
        print(f"  - é¢„æµ‹å¹³å‡LTV: {y_pred.mean():.2f}")

        return evaluation_metrics

    def get_feature_analysis(self) -> Dict[str, Any]:
        """
        è·å–ç‰¹å¾åˆ†ææŠ¥å‘Š

        Returns:
            ç‰¹å¾åˆ†æå­—å…¸
        """
        if self.feature_importance is None:
            return {"error": "ç‰¹å¾é‡è¦æ€§æœªè®¡ç®—ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹"}

        analysis = {
            'feature_importance': self.feature_importance,
            'best_model_features': {},
            'feature_insights': {}
        }

        # åˆ†ææœ€ä½³æ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§
        if self.regression_models.best_model_name in self.feature_importance:
            best_features = self.feature_importance[self.regression_models.best_model_name]
            analysis['best_model_features'] = best_features

            # ç”Ÿæˆç‰¹å¾æ´å¯Ÿ
            if best_features:
                top_feature = max(best_features.keys(), key=lambda x: best_features[x])
                analysis['feature_insights'] = {
                    'most_important_feature': top_feature,
                    'most_important_score': best_features[top_feature],
                    'feature_ranking': dict(sorted(best_features.items(), key=lambda x: x[1], reverse=True)),
                    'feature_contribution_analysis': self._analyze_feature_contributions(best_features)
                }

        return analysis

    def _analyze_feature_contributions(self, feature_importance: Dict[str, float]) -> Dict[str, str]:
        """
        åˆ†æç‰¹å¾è´¡çŒ®

        Args:
            feature_importance: ç‰¹å¾é‡è¦æ€§å­—å…¸

        Returns:
            ç‰¹å¾è´¡çŒ®åˆ†æå­—å…¸
        """
        total_importance = sum(feature_importance.values())
        contributions = {}

        for feature, importance in feature_importance.items():
            contribution_pct = (importance / total_importance) * 100

            if feature == 'Rå€¼':
                contributions[feature] = f"æœ€è¿‘æ¶ˆè´¹æ—¶é—´è´¡çŒ®äº†{contribution_pct:.1f}%çš„é¢„æµ‹ä¿¡æ¯ï¼Œå®¢æˆ·æ´»è·ƒåº¦å¯¹LTVå½±å“æ˜¾è‘—"
            elif feature == 'Få€¼':
                contributions[feature] = f"æ¶ˆè´¹é¢‘ç‡è´¡çŒ®äº†{contribution_pct:.1f}%çš„é¢„æµ‹ä¿¡æ¯ï¼Œé¢‘ç¹è´­ä¹°å®¢æˆ·æ›´æœ‰ä»·å€¼"
            elif feature == 'Må€¼':
                contributions[feature] = f"æ¶ˆè´¹é‡‘é¢è´¡çŒ®äº†{contribution_pct:.1f}%çš„é¢„æµ‹ä¿¡æ¯ï¼Œå†å²æ¶ˆè´¹é‡‘é¢æ˜¯LTVçš„å…³é”®æŒ‡æ ‡"
            else:
                contributions[feature] = f"è¯¥ç‰¹å¾è´¡çŒ®äº†{contribution_pct:.1f}%çš„é¢„æµ‹ä¿¡æ¯"

        return contributions

    def generate_summary_report(self) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»¼åˆæ‘˜è¦æŠ¥å‘Š

        Returns:
            æ‘˜è¦æŠ¥å‘Šå­—å…¸
        """
        if self.model_results is None:
            return {"error": "æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè¿è¡Œå®Œæ•´æµç¨‹"}

        report = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'config': self.config,
            'data_summary': self.rfm_summary,
            'model_summary': self.regression_models.get_model_summary(),
            'best_model_performance': {},
            'feature_analysis': self.get_feature_analysis(),
            'recommendations': []
        }

        # æœ€ä½³æ¨¡å‹æ€§èƒ½
        if self.regression_models.best_model_name and self.regression_models.best_model_name in self.model_results:
            best_result = self.model_results[self.regression_models.best_model_name]
            if 'r2_score' in best_result:
                report['best_model_performance'] = {
                    'model_name': self.regression_models.best_model_name,
                    'r2_score': best_result['r2_score'],
                    'mae': best_result.get('mae'),
                    'rmse': best_result.get('rmse'),
                    'mape': best_result.get('mape')
                }

        # ç”Ÿæˆä¸šåŠ¡å»ºè®®
        report['recommendations'] = self._generate_business_recommendations(report)

        self.summary_report = report
        return report

    def _generate_business_recommendations(self, report: Dict[str, Any]) -> List[str]:
        """
        ç”Ÿæˆä¸šåŠ¡å»ºè®®

        Args:
            report: åˆ†ææŠ¥å‘Š

        Returns:
            å»ºè®®åˆ—è¡¨
        """
        recommendations = []

        try:
            # åŸºäºæ¨¡å‹æ€§èƒ½çš„å»ºè®®
            best_performance = report.get('best_model_performance', {})
            r2_score = best_performance.get('r2_score', 0)

            if r2_score > 0.7:
                recommendations.append("æ¨¡å‹é¢„æµ‹æ€§èƒ½ä¼˜ç§€ï¼ˆRÂ² > 0.7ï¼‰ï¼Œå¯ç”¨äºç²¾å‡†è¥é”€å’Œå®¢æˆ·ä»·å€¼ç®¡ç†")
            elif r2_score > 0.5:
                recommendations.append("æ¨¡å‹é¢„æµ‹æ€§èƒ½è‰¯å¥½ï¼ˆRÂ² > 0.5ï¼‰ï¼Œå»ºè®®ç»“åˆä¸šåŠ¡è§„åˆ™è¿›è¡Œå®¢æˆ·åˆ†å±‚")
            else:
                recommendations.append("æ¨¡å‹é¢„æµ‹æ€§èƒ½ä¸€èˆ¬ï¼Œå»ºè®®å¢åŠ æ›´å¤šç‰¹å¾æ•°æ®æˆ–å°è¯•å…¶ä»–ç®—æ³•")

            # åŸºäºç‰¹å¾é‡è¦æ€§çš„å»ºè®®
            feature_analysis = report.get('feature_analysis', {})
            if 'most_important_feature' in feature_analysis:
                top_feature = feature_analysis['most_important_feature']
                if top_feature == 'Må€¼':
                    recommendations.append("æ¶ˆè´¹é‡‘é¢æ˜¯å½±å“LTVçš„æœ€é‡è¦å› ç´ ï¼Œå»ºè®®é‡ç‚¹æå‡å®¢å•ä»·")
                elif top_feature == 'Få€¼':
                    recommendations.append("æ¶ˆè´¹é¢‘ç‡æ˜¯å½±å“LTVçš„æœ€é‡è¦å› ç´ ï¼Œå»ºè®®é‡ç‚¹æé«˜å¤è´­ç‡")
                elif top_feature == 'Rå€¼':
                    recommendations.append("å®¢æˆ·æ´»è·ƒåº¦æ˜¯å½±å“LTVçš„æœ€é‡è¦å› ç´ ï¼Œå»ºè®®åŠ å¼ºå®¢æˆ·äº’åŠ¨å’Œå”¤é†’")

            # åŸºäºæ•°æ®çš„å»ºè®®
            data_summary = report.get('data_summary', {})
            if data_summary and 'total_customers' in data_summary:
                customer_count = data_summary['total_customers']
                if customer_count < 100:
                    recommendations.append("æ ·æœ¬é‡è¾ƒå°‘ï¼Œå»ºè®®ç§¯ç´¯æ›´å¤šæ•°æ®ä»¥æé«˜æ¨¡å‹ç¨³å®šæ€§")
                elif customer_count > 10000:
                    recommendations.append("æ ·æœ¬é‡å……è¶³ï¼Œå¯è€ƒè™‘æ›´å¤æ‚çš„æœºå™¨å­¦ä¹ ç®—æ³•")

        except Exception as e:
            print(f"ç”Ÿæˆå»ºè®®æ—¶å‡ºé”™: {str(e)}")

        if not recommendations:
            recommendations.append("æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå»ºè®®ç»“åˆå…·ä½“ä¸šåŠ¡åœºæ™¯è¿›è¡Œåº”ç”¨")

        return recommendations

    def save_results(self, directory: str):
        """
        ä¿å­˜åˆ†æç»“æœ

        Args:
            directory: ä¿å­˜ç›®å½•
        """
        import os
        from pathlib import Path

        Path(directory).mkdir(parents=True, exist_ok=True)

        # ä¿å­˜æ¨¡å‹
        if self.model_results:
            model_dir = os.path.join(directory, "models")
            self.regression_models.save_models(model_dir)

        # ä¿å­˜æ‘˜è¦æŠ¥å‘Š
        if self.summary_report:
            report_path = os.path.join(directory, "summary_report.json")
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(self.summary_report, f, ensure_ascii=False, indent=2, default=str)

        print(f"âœ“ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {directory}")

    def load_results(self, directory: str):
        """
        åŠ è½½åˆ†æç»“æœ

        Args:
            directory: ç»“æœç›®å½•
        """
        import os

        # åŠ è½½æ¨¡å‹
        model_dir = os.path.join(directory, "models")
        if os.path.exists(model_dir):
            self.regression_models.load_models(model_dir)

        # åŠ è½½æ‘˜è¦æŠ¥å‘Š
        report_path = os.path.join(directory, "summary_report.json")
        if os.path.exists(report_path):
            with open(report_path, 'r', encoding='utf-8') as f:
                self.summary_report = json.load(f)

        print(f"âœ“ åˆ†æç»“æœå·²ä»{directory}åŠ è½½")

# ä¾¿åˆ©å‡½æ•°
def complete_ltv_analysis(file_path: str,
                         output_dir: str = './ltv_results',
                         config: Optional[Dict] = None) -> Dict[str, Any]:
    """
    å®Œæ•´çš„LTVåˆ†ææµç¨‹

    Args:
        file_path: è®¢å•æ•°æ®æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        config: é…ç½®å‚æ•°

    Returns:
        å®Œæ•´åˆ†æç»“æœ
    """
    from pathlib import Path

    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # åˆå§‹åŒ–é¢„æµ‹å™¨
    predictor = LTVPredictor(config)

    print("ğŸš€ å¼€å§‹å®Œæ•´LTVåˆ†ææµç¨‹...")
    print(f"  - è¾“å…¥æ•°æ®: {file_path}")
    print(f"  - è¾“å‡ºç›®å½•: {output_dir}")

    try:
        # 1. åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
        processed_data = predictor.load_and_preprocess_data(file_path)

        # 2. è®¡ç®—RFMç‰¹å¾
        rfm_data = predictor.calculate_rfm_and_prepare_training_data(processed_data)

        # 3. è®­ç»ƒæ¨¡å‹
        training_results = predictor.train_models(rfm_data)

        # 4. ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        summary_report = predictor.generate_summary_report()

        # 5. ä¿å­˜ç»“æœ
        predictor.save_results(output_dir)

        # 6. å¯¼å‡ºRFMæ•°æ®
        rfm_output_path = os.path.join(output_dir, 'rfm_features.csv')
        predictor.data_processor.export_rfm_data(rfm_data, rfm_output_path)

        results = {
            'predictor': predictor,
            'rfm_data': rfm_data,
            'training_results': training_results,
            'summary_report': summary_report,
            'output_paths': {
                'rfm_features': rfm_output_path,
                'models': os.path.join(output_dir, 'models'),
                'summary_report': os.path.join(output_dir, 'summary_report.json')
            }
        }

        print("ğŸ‰ å®Œæ•´LTVåˆ†ææµç¨‹å®Œæˆï¼")

        # æ‰“å°å…³é”®ç»“æœ
        if summary_report and 'best_model_performance' in summary_report:
            best_perf = summary_report['best_model_performance']
            print(f"\nğŸ“Š å…³é”®ç»“æœ:")
            print(f"  - æœ€ä½³æ¨¡å‹: {best_perf.get('model_name', 'Unknown')}")
            print(f"  - æ¨¡å‹RÂ²: {best_perf.get('r2_score', 0):.4f}")
            print(f"  - åˆ†æå®¢æˆ·æ•°: {training_results.get('rfm_summary', {}).get('total_customers', 0)}")

        return results

    except Exception as e:
        print(f"âŒ LTVåˆ†ææµç¨‹å¤±è´¥: {str(e)}")
        raise

if __name__ == "__main__":
    # ç¤ºä¾‹ä½¿ç”¨
    print("ğŸ¯ LTVé¢„æµ‹å¼•æ“æµ‹è¯•")

    # å¦‚æœæœ‰ç¤ºä¾‹æ•°æ®æ–‡ä»¶ï¼Œå¯ä»¥è¿›è¡Œæµ‹è¯•
    sample_file = '../data/sample_orders.csv'
    if os.path.exists(sample_file):
        results = complete_ltv_analysis(sample_file, output_dir='./ltv_test_results')
        print("âœ“ å®Œæ•´æµ‹è¯•å®Œæˆ")
    else:
        print("âš ï¸ ç¤ºä¾‹æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•")