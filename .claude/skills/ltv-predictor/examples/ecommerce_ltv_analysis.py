#!/usr/bin/env python3
"""
ç”µå•†LTVåˆ†æå®Œæ•´ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨LTVé¢„æµ‹æŠ€èƒ½è¿›è¡Œå®Œæ•´çš„ç”µå•†å®¢æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼åˆ†æ
"""

import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np

# æ·»åŠ æŠ€èƒ½æ¨¡å—è·¯å¾„
current_dir = Path(__file__).parent
sys.path.append(str(current_dir.parent / 'scripts'))

from quick_analysis import quick_ltv_analysis

def main():
    """ç”µå•†LTVåˆ†æç¤ºä¾‹"""
    print("ğŸ›’ ç”µå•†å®¢æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼åˆ†æç¤ºä¾‹")
    print("=" * 60)

    # ç¤ºä¾‹æ•°æ®æ–‡ä»¶è·¯å¾„
    sample_data_path = current_dir.parent / 'data' / 'sample_orders.csv'
    output_dir = current_dir.parent / 'examples' / 'ecommerce_analysis_results'

    print(f"ğŸ“ ç¤ºä¾‹æ•°æ®: {sample_data_path}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print()

    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not sample_data_path.exists():
        print(f"âŒ ç¤ºä¾‹æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {sample_data_path}")
        print("è¯·å…ˆè¿è¡Œæ•°æ®å‡†å¤‡è„šæœ¬æˆ–æ£€æŸ¥æ–‡ä»¶è·¯å¾„ã€‚")
        return

    try:
        # 1. åŸºç¡€LTVåˆ†æ
        print("1ï¸âƒ£ æ‰§è¡ŒåŸºç¡€LTVåˆ†æ...")
        print("-" * 30)

        basic_config = {
            'data_processor_config': {
                'feature_period_months': 3,  # ä½¿ç”¨å‰3ä¸ªæœˆæ•°æ®
                'prediction_period_months': 12,  # é¢„æµ‹å12ä¸ªæœˆ
                'remove_outliers': True,
                'min_orders_per_customer': 1
            },
            'regression_config': {
                'test_size': 0.2,
                'cv_folds': 5,
                'scoring_metric': 'r2',
                'enable_hyperparameter_tuning': False
            },
            'models_to_train': ['linear_regression', 'random_forest']
        }

        results = quick_ltv_analysis(
            file_path=str(sample_data_path),
            feature_period_months=3,
            prediction_period_months=12,
            output_dir=str(output_dir / 'basic_analysis'),
            config=basic_config,
            generate_charts=True,
            generate_reports=True
        )

        print("âœ… åŸºç¡€LTVåˆ†æå®Œæˆ")

        # 2. é«˜çº§LTVåˆ†æï¼ˆåŒ…å«è°ƒä¼˜ï¼‰
        print("\n2ï¸âƒ£ æ‰§è¡Œé«˜çº§LTVåˆ†æ...")
        print("-" * 30)

        advanced_config = {
            'data_processor_config': {
                'feature_period_months': 6,  # ä½¿ç”¨å‰6ä¸ªæœˆæ•°æ®
                'prediction_period_months': 12,  # é¢„æµ‹å12ä¸ªæœˆ
                'remove_outliers': True,
                'min_orders_per_customer': 2  # è‡³å°‘2ä¸ªè®¢å•
            },
            'regression_config': {
                'test_size': 0.2,
                'cv_folds': 10,  # æ›´å¤šæŠ˜äº¤å‰éªŒè¯
                'scoring_metric': 'r2',
                'enable_hyperparameter_tuning': True  # å¯ç”¨è¶…å‚æ•°è°ƒä¼˜
            },
            'models_to_train': ['linear_regression', 'random_forest']
        }

        advanced_results = quick_ltv_analysis(
            file_path=str(sample_data_path),
            feature_period_months=6,
            prediction_period_months=12,
            output_dir=str(output_dir / 'advanced_analysis'),
            config=advanced_config,
            generate_charts=True,
            generate_reports=True
        )

        print("âœ… é«˜çº§LTVåˆ†æå®Œæˆ")

        # 3. ç»“æœæ¯”è¾ƒ
        print("\n3ï¸âƒ£ åˆ†æç»“æœæ¯”è¾ƒ...")
        print("-" * 30)

        basic_summary = results.get('summary', {})
        advanced_summary = advanced_results.get('summary', {})

        print("åŸºç¡€åˆ†æç»“æœ:")
        print(f"  - æœ€ä½³æ¨¡å‹: {basic_summary.get('model_summary', {}).get('best_model', 'Unknown')}")
        print(f"  - RÂ²åˆ†æ•°: {basic_summary.get('model_summary', {}).get('best_r2_score', 0):.4f}")
        print(f"  - åˆ†æå®¢æˆ·æ•°: {basic_summary.get('data_summary', {}).get('total_customers', 0)}")
        print(f"  - å¹³å‡LTV: {basic_summary.get('data_summary', {}).get('avg_ltv', 0):.0f}")

        print("\né«˜çº§åˆ†æç»“æœ:")
        print(f"  - æœ€ä½³æ¨¡å‹: {advanced_summary.get('model_summary', {}).get('best_model', 'Unknown')}")
        print(f"  - RÂ²åˆ†æ•°: {advanced_summary.get('model_summary', {}).get('best_r2_score', 0):.4f}")
        print(f"  - åˆ†æå®¢æˆ·æ•°: {advanced_summary.get('data_summary', {}).get('total_customers', 0)}")
        print(f"  - å¹³å‡LTV: {advanced_summary.get('data_summary', {}).get('avg_ltv', 0):.0f}")

        # 4. ä¸šåŠ¡æ´å¯Ÿ
        print("\n4ï¸âƒ£ ä¸šåŠ¡æ´å¯Ÿ...")
        print("-" * 30)

        # è·å–RFMæ•°æ®è¿›è¡Œåˆ†æ
        basic_rfm_path = results['output_paths']['rfm_features']
        if os.path.exists(basic_rfm_path):
            rfm_data = pd.read_csv(basic_rfm_path)

            # å®¢æˆ·ä»·å€¼åˆ†å±‚ç»Ÿè®¡
            if 'å®¢æˆ·ä»·å€¼åˆ†å±‚' in rfm_data.columns:
                segment_counts = rfm_data['å®¢æˆ·ä»·å€¼åˆ†å±‚'].value_counts()
                print("å®¢æˆ·ä»·å€¼åˆ†å±‚åˆ†å¸ƒ:")
                for segment, count in segment_counts.items():
                    percentage = (count / len(rfm_data)) * 100
                    print(f"  - {segment}: {count}äºº ({percentage:.1f}%)")

            # åŸå¸‚åˆ†æ
            if 'åŸå¸‚' in rfm_data.columns:
                city_ltv = rfm_data.groupby('åŸå¸‚')['å¹´åº¦LTV'].agg(['count', 'mean']).sort_values('mean', ascending=False)
                print("\nåŸå¸‚LTVæ’å:")
                for city, stats in city_ltv.head(5).iterrows():
                    print(f"  - {city}: {stats['count']}äºº, å¹³å‡LTV {stats['mean']:,.0f}")

        # 5. æ¨èç­–ç•¥
        print("\n5ï¸âƒ£ æ¨èè¥é”€ç­–ç•¥...")
        print("-" * 30)

        recommendations = basic_summary.get('recommendations_summary', [])
        if recommendations:
            for i, rec in enumerate(recommendations[:5], 1):  # æ˜¾ç¤ºå‰5æ¡å»ºè®®
                print(f"  {i}. {rec}")
        else:
            print("  åŸºäºåˆ†æç»“æœï¼Œå»ºè®®:")
            print("  1. é’ˆå¯¹é«˜ä»·å€¼å®¢æˆ·è®¾è®¡VIPç»´æŠ¤è®¡åˆ’")
            print("  2. å¯¹ä¸­ä»·å€¼å®¢æˆ·è¿›è¡Œäº¤å‰é”€å”®å’Œå‘ä¸Šé”€å”®")
            print("  3. å¯¹ä½ä»·å€¼å®¢æˆ·åˆ¶å®šæ¿€æ´»å’Œç•™å­˜ç­–ç•¥")
            print("  4. é‡ç‚¹å…³æ³¨ä¸€çº¿åŸå¸‚å®¢æˆ·çš„ä¸ªæ€§åŒ–æœåŠ¡")
            print("  5. å»ºç«‹å®¢æˆ·ç”Ÿå‘½å‘¨æœŸç®¡ç†æµç¨‹")

        # 6. æ–‡ä»¶ç”Ÿæˆæ€»ç»“
        print("\n6ï¸âƒ£ ç”Ÿæˆæ–‡ä»¶æ€»ç»“...")
        print("-" * 30)

        print("åŸºç¡€åˆ†æç”Ÿæˆæ–‡ä»¶:")
        print(f"  ğŸ“Š RFMç‰¹å¾æ•°æ®: {results['output_paths']['rfm_features']}")
        print(f"  ğŸ¤– è®­ç»ƒæ¨¡å‹: {results['output_paths']['models']}")
        print(f"  ğŸ“‹ åˆ†ææ‘˜è¦: {results['summary_path']}")

        chart_count = len(results.get('chart_paths', {}))
        report_count = len(results.get('report_paths', {}))
        print(f"  ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨: {chart_count}ä¸ª")
        print(f"  ğŸ“„ åˆ†ææŠ¥å‘Š: {report_count}ä¸ª")

        print("\né«˜çº§åˆ†æç”Ÿæˆæ–‡ä»¶:")
        print(f"  ğŸ“Š RFMç‰¹å¾æ•°æ®: {advanced_results['output_paths']['rfm_features']}")
        print(f"  ğŸ¤– è®­ç»ƒæ¨¡å‹: {advanced_results['output_paths']['models']}")
        print(f"  ğŸ“‹ åˆ†ææ‘˜è¦: {advanced_results['summary_path']}")

        chart_count = len(advanced_results.get('chart_paths', {}))
        report_count = len(advanced_results.get('report_paths', {}))
        print(f"  ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨: {chart_count}ä¸ª")
        print(f"  ğŸ“„ åˆ†ææŠ¥å‘Š: {report_count}ä¸ª")

        print("\n" + "=" * 60)
        print("ğŸ‰ ç”µå•†LTVåˆ†æç¤ºä¾‹å®Œæˆï¼")
        print("=" * 60)
        print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜è‡³: {output_dir}")
        print("\nğŸ“– åç»­æ­¥éª¤:")
        print("1. æŸ¥çœ‹ç”Ÿæˆçš„HTMLæŠ¥å‘Šäº†è§£è¯¦ç»†åˆ†æç»“æœ")
        print("2. ä½¿ç”¨å¯è§†åŒ–å›¾è¡¨æ´å¯Ÿå®¢æˆ·è¡Œä¸ºæ¨¡å¼")
        print("3. åŸºäºæ¨èç­–ç•¥åˆ¶å®šè¥é”€è®¡åˆ’")
        print("4. å®šæœŸæ›´æ–°æ•°æ®é‡æ–°åˆ†æä»¥è·Ÿè¸ªå˜åŒ–")

    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()