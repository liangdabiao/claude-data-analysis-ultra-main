#!/usr/bin/env python3
"""
å¿«é€ŸLTVé¢„æµ‹ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å·²è®­ç»ƒçš„æ¨¡åž‹å¿«é€Ÿé¢„æµ‹æ–°å®¢æˆ·çš„LTV
"""

import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np

# æ·»åŠ æŠ€èƒ½æ¨¡å—è·¯å¾„
current_dir = Path(__file__).parent
sys.path.append(str(current_dir.parent / 'scripts'))

from quick_analysis import quick_ltv_analysis, predict_new_customers, batch_predict_ltv

def create_sample_new_customers():
    """åˆ›å»ºç¤ºä¾‹æ–°å®¢æˆ·æ•°æ®"""
    np.random.seed(42)

    # æ¨¡æ‹Ÿæ–°å®¢æˆ·è®¢å•æ•°æ®
    new_customers = []

    # ç”Ÿæˆ10ä¸ªæ–°å®¢æˆ·çš„è¿‘æœŸè®¢å•
    for i in range(10, 20):  # å®¢æˆ·IDä»Ž10å¼€å§‹
        customer_id = f"CUST{i:03d}"
        city = np.random.choice(['åŒ—äº¬', 'ä¸Šæµ·', 'æ·±åœ³', 'å¹¿å·ž', 'æ­å·ž', 'æˆéƒ½', 'æ­¦æ±‰'])

        # æ¯ä¸ªå®¢æˆ·1-3ä¸ªè®¢å•
        num_orders = np.random.randint(1, 4)

        for j in range(num_orders):
            order_id = 2000 + i * 10 + j
            product_code = f"PROD{np.random.randint(1, 15):03d}"
            order_date = pd.Timestamp('2023-01-01') + pd.Timedelta(days=np.random.randint(0, 90))
            product_desc = f"æµ‹è¯•äº§å“{product_code}"
            quantity = np.random.randint(1, 5)
            price = np.random.uniform(20, 200)

            new_customers.append({
                'è®¢å•å·': order_id,
                'äº§å“ç ': product_code,
                'æ¶ˆè´¹æ—¥æœŸ': order_date.strftime('%Y-%m-%d %H:%M'),
                'äº§å“è¯´æ˜Ž': product_desc,
                'æ•°é‡': quantity,
                'å•ä»·': round(price, 2),
                'ç”¨æˆ·ç ': customer_id,
                'åŸŽå¸‚': city
            })

    return pd.DataFrame(new_customers)

def main():
    """å¿«é€ŸLTVé¢„æµ‹ç¤ºä¾‹"""
    print("âš¡ å¿«é€ŸLTVé¢„æµ‹ç¤ºä¾‹")
    print("=" * 60)

    # è·¯å¾„è®¾ç½®
    sample_data_path = current_dir.parent / 'data' / 'sample_orders.csv'
    model_output_dir = current_dir.parent / 'examples' / 'quick_prediction' / 'models'
    new_customers_output_dir = current_dir.parent / 'examples' / 'quick_prediction'

    print(f"ðŸ“ è®­ç»ƒæ•°æ®: {sample_data_path}")
    print(f"ðŸ¤– æ¨¡åž‹ç›®å½•: {model_output_dir}")
    print(f"ðŸ“ è¾“å‡ºç›®å½•: {new_customers_output_dir}")
    print()

    try:
        # ç¬¬ä¸€æ­¥ï¼šè®­ç»ƒåŸºç¡€æ¨¡åž‹
        print("1ï¸âƒ£ è®­ç»ƒLTVé¢„æµ‹æ¨¡åž‹...")
        print("-" * 30)

        if not sample_data_path.exists():
            print(f"âŒ ç¤ºä¾‹æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {sample_data_path}")
            return

        # å¿«é€Ÿè®­ç»ƒé…ç½®
        quick_config = {
            'data_processor_config': {
                'feature_period_months': 3,
                'prediction_period_months': 12,
                'remove_outliers': False,  # å¿«é€Ÿè®­ç»ƒä¸åŽ»é™¤å¼‚å¸¸å€¼
                'min_orders_per_customer': 1
            },
            'regression_config': {
                'test_size': 0.3,  # æ›´å¤§çš„æµ‹è¯•é›†
                'cv_folds': 3,  # æ›´å°‘çš„äº¤å‰éªŒè¯æŠ˜æ•°
                'scoring_metric': 'r2',
                'enable_hyperparameter_tuning': False  # ä¸è°ƒä»¥èŠ‚çœæ—¶é—´
            },
            'models_to_train': ['random_forest']  # åªè®­ç»ƒéšæœºæ£®æž—
        }

        # è®­ç»ƒæ¨¡åž‹
        training_results = quick_ltv_analysis(
            file_path=str(sample_data_path),
            feature_period_months=3,
            prediction_period_months=12,
            output_dir=str(model_output_dir),
            config=quick_config,
            generate_charts=False,  # ä¸ç”Ÿæˆå›¾è¡¨ä»¥èŠ‚çœæ—¶é—´
            generate_reports=False   # ä¸ç”ŸæˆæŠ¥å‘Šä»¥èŠ‚çœæ—¶é—´
        )

        print("âœ… æ¨¡åž‹è®­ç»ƒå®Œæˆ")

        # ç¬¬äºŒæ­¥ï¼šåˆ›å»ºæ–°å®¢æˆ·æ•°æ®
        print("\n2ï¸âƒ£ åˆ›å»ºæ–°å®¢æˆ·æ•°æ®...")
        print("-" * 30)

        new_customers_df = create_sample_new_customers()
        new_customers_file = new_customers_output_dir / 'new_customers.csv'
        new_customers_df.to_csv(new_customers_file, index=False, encoding='utf-8-sig')

        print(f"âœ… æ–°å®¢æˆ·æ•°æ®å·²åˆ›å»º: {new_customers_file}")
        print(f"   - å®¢æˆ·æ•°: {new_customers_df['ç”¨æˆ·ç '].nunique()}")
        print(f"   - è®¢å•æ•°: {len(new_customers_df)}")
        print(f"   - æ—¶é—´èŒƒå›´: {new_customers_df['æ¶ˆè´¹æ—¥æœŸ'].min()} è‡³ {new_customers_df['æ¶ˆè´¹æ—¥æœŸ'].max()}")

        # ç¬¬ä¸‰æ­¥ï¼šé¢„æµ‹æ–°å®¢æˆ·LTV
        print("\n3ï¸âƒ£ é¢„æµ‹æ–°å®¢æˆ·LTV...")
        print("-" * 30)

        predictions_file = new_customers_output_dir / 'new_customer_predictions.csv'
        predictions_df = predict_new_customers(
            model_dir=str(model_output_dir),
            new_orders_file=str(new_customers_file),
            output_path=str(predictions_file)
        )

        print("âœ… æ–°å®¢æˆ·LTVé¢„æµ‹å®Œæˆ")

        # ç¬¬å››æ­¥ï¼šåˆ†æžé¢„æµ‹ç»“æžœ
        print("\n4ï¸âƒ£ åˆ†æžé¢„æµ‹ç»“æžœ...")
        print("-" * 30)

        if predictions_df is not None:
            print("é¢„æµ‹ç»“æžœç»Ÿè®¡:")
            print(f"  - é¢„æµ‹å®¢æˆ·æ•°: {len(predictions_df)}")
            print(f"  - å¹³å‡é¢„æµ‹LTV: {predictions_df['é¢„æµ‹LTV'].mean():,.0f}")
            print(f"  - æœ€é«˜é¢„æµ‹LTV: {predictions_df['é¢„æµ‹LTV'].max():,.0f}")
            print(f"  - æœ€ä½Žé¢„æµ‹LTV: {predictions_df['é¢„æµ‹LTV'].min():,.0f}")

            # æŒ‰åŸŽå¸‚åˆ†ç»„åˆ†æžï¼ˆå¦‚æžœæœ‰åŸŽå¸‚ä¿¡æ¯ï¼‰
            if 'åŸŽå¸‚' in predictions_df.columns:
                city_analysis = predictions_df.groupby('åŸŽå¸‚')['é¢„æµ‹LTV'].agg(['count', 'mean', 'std']).round(2)
                print("\nå„åŸŽå¸‚LTVé¢„æµ‹:")
                for city, stats in city_analysis.iterrows():
                    print(f"  - {city}: {stats['count']}äºº, å¹³å‡{stats['mean']:,.0f}, æ ‡å‡†å·®{stats['std']:,.0f}")
            else:
                print("\næ³¨ï¼šé¢„æµ‹ç»“æžœä¸­ä¸åŒ…å«åŸŽå¸‚ä¿¡æ¯ï¼Œæ— æ³•æŒ‰åŸŽå¸‚åˆ†æž")

            # å®¢æˆ·åˆ†ç¾¤
            def categorize_ltv(ltv):
                if ltv >= 1000:
                    return "é«˜ä»·å€¼å®¢æˆ·"
                elif ltv >= 500:
                    return "ä¸­ä»·å€¼å®¢æˆ·"
                else:
                    return "ä½Žä»·å€¼å®¢æˆ·"

            predictions_df['ä»·å€¼åˆ†å±‚'] = predictions_df['é¢„æµ‹LTV'].apply(categorize_ltv)
            segment_counts = predictions_df['ä»·å€¼åˆ†å±‚'].value_counts()
            print("\nå®¢æˆ·ä»·å€¼åˆ†å±‚:")
            for segment, count in segment_counts.items():
                percentage = (count / len(predictions_df)) * 100
                print(f"  - {segment}: {count}äºº ({percentage:.1f}%)")

        # ç¬¬äº”æ­¥ï¼šç”Ÿæˆå¿«é€Ÿå»ºè®®
        print("\n5ï¸âƒ£ è¥é”€å»ºè®®...")
        print("-" * 30)

        if predictions_df is not None:
            # é«˜ä»·å€¼å®¢æˆ·å»ºè®®
            high_value = predictions_df[predictions_df['é¢„æµ‹LTV'] >= 1000]
            if not high_value.empty:
                print("é«˜ä»·å€¼å®¢æˆ·ç­–ç•¥:")
                print("  - æä¾›VIPä¸“å±žæœåŠ¡")
                print("  - å®‰æŽ’å®¢æˆ·ç»ç†ä¸“äººå¯¹æŽ¥")
                print("  - å®šåˆ¶ä¸ªæ€§åŒ–è¥é”€æ–¹æ¡ˆ")
                print(f"  - é‡ç‚¹ç»´æŠ¤çš„{len(high_value)}ä½å®¢æˆ·: {', '.join(high_value['ç”¨æˆ·ç '].tolist())}")

            # ä¸­ä»·å€¼å®¢æˆ·å»ºè®®
            medium_value = predictions_df[(predictions_df['é¢„æµ‹LTV'] >= 500) & (predictions_df['é¢„æµ‹LTV'] < 1000)]
            if not medium_value.empty:
                print("\nä¸­ä»·å€¼å®¢æˆ·ç­–ç•¥:")
                print("  - æŽ¨èå‡çº§äº§å“å’Œå¥—é¤")
                print("  - æä¾›ä¼˜æƒ åˆ¸åˆºæ¿€æ¶ˆè´¹")
                print("  - å¢žåŠ äº’åŠ¨é¢‘çŽ‡")
                print(f"  - é‡ç‚¹å…³æ³¨çš„{len(medium_value)}ä½å®¢æˆ·: {', '.join(medium_value['ç”¨æˆ·ç '].tolist())}")

            # ä½Žä»·å€¼å®¢æˆ·å»ºè®®
            low_value = predictions_df[predictions_df['é¢„æµ‹LTV'] < 500]
            if not low_value.empty:
                print("\nä½Žä»·å€¼å®¢æˆ·ç­–ç•¥:")
                print("  - å‘æ”¾æ–°äººç¤¼åŒ…å’Œä¼˜æƒ åˆ¸")
                print("  - æŽ¨èæ€§ä»·æ¯”é«˜çš„äº§å“")
                print("  - å¢žåŠ äº§å“ä½“éªŒæœºä¼š")
                print(f"  - éœ€è¦æ¿€æ´»çš„{len(low_value)}ä½å®¢æˆ·: {', '.join(low_value['ç”¨æˆ·ç '].tolist())}")

        # ç¬¬å…­æ­¥ï¼šæ€»ç»“
        print("\n6ï¸âƒ£ é¢„æµ‹æ€»ç»“...")
        print("-" * 30)

        print("âœ… å¿«é€ŸLTVé¢„æµ‹æµç¨‹å®Œæˆ")
        print(f"ðŸ“ æ¨¡åž‹æ–‡ä»¶: {model_output_dir}")
        print(f"ðŸ“Š æ–°å®¢æˆ·æ•°æ®: {new_customers_file}")
        print(f"ðŸŽ¯ é¢„æµ‹ç»“æžœ: {predictions_file}")

        print("\nðŸ“– ä½¿ç”¨è¯´æ˜Ž:")
        print("1. æ¨¡åž‹å·²è®­ç»ƒå¹¶ä¿å­˜ï¼Œå¯ç›´æŽ¥ç”¨äºŽæ–°å®¢æˆ·é¢„æµ‹")
        print("2. æ–°å®¢æˆ·æ•°æ®æ ¼å¼éœ€ä¸Žè®­ç»ƒæ•°æ®ä¿æŒä¸€è‡´")
        print("3. é¢„æµ‹ç»“æžœå¯ç”¨äºŽåˆ¶å®šä¸ªæ€§åŒ–è¥é”€ç­–ç•¥")
        print("4. å»ºè®®å®šæœŸé‡æ–°è®­ç»ƒæ¨¡åž‹ä»¥ä¿æŒé¢„æµ‹å‡†ç¡®æ€§")

        print("\nðŸ”§ æ‰¹é‡é¢„æµ‹:")
        print("å¦‚éœ€æ‰¹é‡é¢„æµ‹å¤§é‡å®¢æˆ·ï¼Œå¯ä½¿ç”¨:")
        print(f"python -c \"from quick_analysis import batch_predict_ltv; batch_predict_ltv('{model_output_dir}', 'rfm_file.csv', 'batch_predictions.csv')\"")

    except Exception as e:
        print(f"\nâŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()