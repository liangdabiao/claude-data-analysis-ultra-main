# ABæµ‹è¯•åˆ†ææŠ€èƒ½ä½¿ç”¨æŒ‡å—

ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„æ™ºèƒ½ABæµ‹è¯•åˆ†æå·¥å…·ï¼Œä¸ºäº§å“ç»ç†ã€æ•°æ®åˆ†æå¸ˆå’Œè¥é”€äººå‘˜æä¾›ä¸“ä¸šçš„ABæµ‹è¯•åˆ†æèƒ½åŠ›ã€‚

## ğŸš€ å¿«é€Ÿä¸Šæ‰‹

### 1. ç¯å¢ƒå‡†å¤‡

ç¡®ä¿å®‰è£…äº†å¿…è¦çš„PythonåŒ…ï¼š

```bash
pip install pandas numpy scipy matplotlib seaborn statsmodels
```

### 2. å¿«é€ŸéªŒè¯

è¿è¡Œå¿«é€Ÿæµ‹è¯•æ¥éªŒè¯æŠ€èƒ½åŠŸèƒ½ï¼š

```bash
python quick_test.py
```

### 3. åŸºç¡€ä½¿ç”¨ç¤ºä¾‹

```python
from scripts.ab_test_analyzer import ABTestAnalyzer
from scripts.statistical_tests import StatisticalTests
from scripts.visualizer import ABTestVisualizer

# åˆå§‹åŒ–åˆ†æå™¨
analyzer = ABTestAnalyzer()
stats_tests = StatisticalTests()
visualizer = ABTestVisualizer()

# åŠ è½½æ•°æ®
data = analyzer.load_data('examples/sample_data/sample_ab_test_data.csv')

# åŸºç¡€åˆ†æ
conversion_results = analyzer.analyze_conversion(
    data, group_col='é¡µé¢ç‰ˆæœ¬', conversion_col='æ˜¯å¦è´­ä¹°'
)

print("è½¬åŒ–ç‡åˆ†æç»“æœ:", conversion_results)
```

## ğŸ“Š æ ¸å¿ƒåŠŸèƒ½æ¦‚è§ˆ

| åŠŸèƒ½æ¨¡å— | ä¸»è¦èƒ½åŠ› | é€‚ç”¨åœºæ™¯ |
|---------|---------|---------|
| **åŸºç¡€åˆ†æ** | è½¬åŒ–ç‡ã€ç•™å­˜ç‡ã€æå‡ç‡è®¡ç®— | äº§å“æ”¹ç‰ˆã€åŠŸèƒ½ä¼˜åŒ– |
| **ç»Ÿè®¡æ£€éªŒ** | tæ£€éªŒã€å¡æ–¹æ£€éªŒã€ç½®ä¿¡åŒºé—´ | éªŒè¯å®éªŒæ•ˆæœæ˜¾è‘—æ€§ |
| **ç”¨æˆ·åˆ†ç¾¤** | ä»·å€¼åˆ†ç¾¤ã€è¡Œä¸ºåˆ†ç¾¤ã€äº¤äº’æ•ˆåº” | ç²¾ç»†åŒ–è¿è¥ã€ä¸ªæ€§åŒ–æ¨è |
| **å¯è§†åŒ–** | å›¾è¡¨ç”Ÿæˆã€ä»ªè¡¨æ¿ã€æŠ¥å‘Šå¯¼å‡º | ç»“æœå±•ç¤ºã€å†³ç­–æ”¯æŒ |
| **é«˜çº§åˆ†æ** | è´å¶æ–¯æ–¹æ³•ã€å¤šå˜é‡ã€å› æœæ¨æ–­ | å¤æ‚å®éªŒè®¾è®¡ã€æ·±åº¦æ´å¯Ÿ |

## ğŸ”§ å…¸å‹ä½¿ç”¨æµç¨‹

### åœºæ™¯1ï¼šç½‘é¡µæ”¹ç‰ˆæ•ˆæœè¯„ä¼°

```python
# 1. æ•°æ®å‡†å¤‡
data = analyzer.load_data('website_ab_test.csv')

# 2. åŸºç¡€è½¬åŒ–ç‡åˆ†æ
conversion_results = analyzer.analyze_conversion(
    data=data,
    group_col='é¡µé¢ç‰ˆæœ¬',
    conversion_col='æ˜¯å¦è´­ä¹°'
)

# 3. ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
t_test_result = stats_tests.t_test(
    data=data,
    group_col='é¡µé¢ç‰ˆæœ¬',
    metric_col='æ˜¯å¦è´­ä¹°'
)

# 4. ç”ŸæˆæŠ¥å‘Š
fig = visualizer.plot_conversion_comparison(conversion_results)
plt.show()

print(f"æ–°é¡µé¢è½¬åŒ–ç‡: {conversion_results['test_group_rate']:.2%}")
print(f"æ—§é¡µé¢è½¬åŒ–ç‡: {conversion_results['control_group_rate']:.2%}")
print(f"æå‡å¹…åº¦: {conversion_results['lift']:.2%}")
print(f"ç»Ÿè®¡æ˜¾è‘—æ€§: {'æ˜¾è‘—' if t_test_result['p_value'] < 0.05 else 'ä¸æ˜¾è‘—'}")
```

### åœºæ™¯2ï¼šç”¨æˆ·åˆ†ç¾¤æ·±åº¦åˆ†æ

```python
from scripts.segment_analyzer import SegmentAnalyzer

segment_analyzer = SegmentAnalyzer()

# 1. ä»·å€¼åˆ†ç¾¤
value_segments = segment_analyzer.value_based_segmentation(
    data=data,
    value_col='ç´¯è®¡æ¶ˆè´¹é‡‘é¢',
    n_tiers=3  # é«˜ã€ä¸­ã€ä½ä»·å€¼
)

# 2. åˆ†ç¾¤è½¬åŒ–ç‡åˆ†æ
segment_conversion = segment_analyzer.segment_conversion_analysis(
    data=data,
    segment_col='ä»·å€¼ç»„åˆ«',
    group_col='é¡µé¢ç‰ˆæœ¬',
    conversion_col='æ˜¯å¦è´­ä¹°'
)

# 3. äº¤äº’æ•ˆåº”åˆ†æ
interaction_analysis = segment_analyzer.interaction_analysis(
    data=data,
    group_col='é¡µé¢ç‰ˆæœ¬',
    segment_col='ä»·å€¼ç»„åˆ«',
    outcome_col='æ˜¯å¦è´­ä¹°'
)

# 4. å¯è§†åŒ–äº¤äº’æ•ˆåº”
fig = visualizer.plot_interaction_effects(interaction_analysis)
plt.show()
```

### åœºæ™¯3ï¼šè¥é”€æ´»åŠ¨æ•ˆæœè¯„ä¼°

```python
# 1. ç•™å­˜ç‡åˆ†æ
retention_results = analyzer.analyze_retention(
    data=data,
    group_col='æ´»åŠ¨ç»„åˆ«',
    retention_col='retention_7'  # 7æ—¥ç•™å­˜
)

# 2. ç•™å­˜ç‡å¯è§†åŒ–
fig = visualizer.plot_retention_curves(retention_results)

# 3. é•¿æœŸæ•ˆæœåˆ†æ
long_term_analysis = analyzer.long_term_impact_analysis(
    data=data,
    time_col='æ—¥æœŸ',
    group_col='æ´»åŠ¨ç»„åˆ«',
    metric_col='æ—¥æ´»è·ƒç”¨æˆ·'
)
```

## ğŸ“ˆ å¸¸è§é—®é¢˜è§£ç­”

### Q: å¦‚ä½•é€‰æ‹©åˆé€‚çš„ç»Ÿè®¡æ£€éªŒæ–¹æ³•ï¼Ÿ

**A: æ ¹æ®æ•°æ®ç±»å‹å’Œç ”ç©¶ç›®æ ‡é€‰æ‹©ï¼š**

- **è¿ç»­å˜é‡ + ä¸¤ç»„æ¯”è¾ƒ** â†’ tæ£€éªŒ
- **åˆ†ç±»å˜é‡ + ä¸¤ç»„æ¯”è¾ƒ** â†’ å¡æ–¹æ£€éªŒ
- **è¿ç»­å˜é‡ + å¤šç»„æ¯”è¾ƒ** â†’ æ–¹å·®åˆ†æ (ANOVA)
- **ç›¸å…³å…³ç³»åˆ†æ** â†’ ç›¸å…³åˆ†æ
- **å°æ ·æœ¬ + éœ€è¦å…ˆéªŒä¿¡æ¯** â†’ è´å¶æ–¯æ–¹æ³•

### Q: æ ·æœ¬é‡ä¸å¤Ÿæ€ä¹ˆåŠï¼Ÿ

**A: è§£å†³æ–¹æ¡ˆï¼š**

1. **è®¡ç®—æœ€å°æ ·æœ¬é‡**ï¼šä½¿ç”¨åŠŸæ•ˆåˆ†æè®¡ç®—æ‰€éœ€æ ·æœ¬é‡
2. **å»¶é•¿å®éªŒæ—¶é—´**ï¼šæ”¶é›†æ›´å¤šæ•°æ®
3. **ä½¿ç”¨è´å¶æ–¯æ–¹æ³•**ï¼šåœ¨å°æ ·æœ¬æƒ…å†µä¸‹æ›´æœ‰æ•ˆ
4. **è€ƒè™‘æ•ˆåº”é‡**ï¼šå…³æ³¨å®é™…ä¸šåŠ¡æ„ä¹‰è€Œéå•çº¯ç»Ÿè®¡æ˜¾è‘—æ€§

### Q: å¦‚ä½•è§£é‡Špå€¼ï¼Ÿ

**A: på€¼çš„æ­£ç¡®ç†è§£ï¼š**

- på€¼æ˜¯**åœ¨åŸå‡è®¾ä¸ºçœŸ**çš„æƒ…å†µä¸‹ï¼Œè§‚å¯Ÿåˆ°å½“å‰ç»“æœæˆ–æ›´æç«¯ç»“æœçš„æ¦‚ç‡
- på€¼å° â‰  æ•ˆåº”é‡å¤§
- på€¼å¤§ â‰  æ²¡æœ‰æ•ˆæœ
- éœ€è¦ç»“åˆæ•ˆåº”é‡å’Œä¸šåŠ¡èƒŒæ™¯æ¥è§£é‡Š

### Q: å¤šé‡æ¯”è¾ƒå¦‚ä½•å¤„ç†ï¼Ÿ

**A: ä½¿ç”¨æ ¡æ­£æ–¹æ³•ï¼š**

```python
# Bonferroniæ ¡æ­£ (ä¿å®ˆ)
analyzer.set_multiple_comparison_correction('bonferroni')

# FDRæ ¡æ­£ (è¾ƒå®½æ¾)
analyzer.set_multiple_comparison_correction('fdr_bh')

# Holmæ ¡æ­£
analyzer.set_multiple_comparison_correction('holm')
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. å®éªŒè®¾è®¡é˜¶æ®µ

```python
# æ ·æœ¬é‡è®¡ç®—
sample_size = analyzer.calculate_sample_size(
    baseline_rate=0.10,  # åŸºå‡†è½¬åŒ–ç‡
    expected_lift=0.20,   # æœŸæœ›æå‡20%
    alpha=0.05,          # æ˜¾è‘—æ€§æ°´å¹³
    power=0.80           # ç»Ÿè®¡åŠŸæ•ˆ
)

print(f"å»ºè®®æ ·æœ¬é‡: {sample_size} (æ¯ç»„)")
```

### 2. æ•°æ®è´¨é‡æ£€æŸ¥

```python
# éšæœºåˆ†ç»„éªŒè¯
randomization_check = analyzer.check_randomization(
    data=data,
    group_col='å®éªŒç»„åˆ«',
    feature_cols=['å¹´é¾„', 'æ€§åˆ«', 'å†å²æ¶ˆè´¹']
)

# æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
data_quality = analyzer.data_quality_check(
    data=data,
    required_cols=['ç”¨æˆ·ID', 'å®éªŒç»„åˆ«', 'è½¬åŒ–çŠ¶æ€']
)
```

### 3. ç»“æœè§£é‡Š

```python
# ç»¼åˆåˆ†ææŠ¥å‘Š
comprehensive_report = analyzer.generate_comprehensive_report(
    data=data,
    group_col='é¡µé¢ç‰ˆæœ¬',
    conversion_col='æ˜¯å¦è´­ä¹°',
    segment_cols=['ä»·å€¼ç»„åˆ«', 'æ€§åˆ«'],
    metrics=['conversion_rate', 'retention_rate', 'revenue']
)

# å¯¼å‡ºæŠ¥å‘Š
report_html = analyzer.export_report(
    results=comprehensive_report,
    format='html',
    filename='ab_test_report.html'
)
```

## ğŸ“š è¿›é˜¶å­¦ä¹ 

### ç»Ÿè®¡å­¦åŸºç¡€æ¦‚å¿µ

- **å‡è®¾æ£€éªŒ**: åŸå‡è®¾ vs å¤‡æ‹©å‡è®¾
- **æ•ˆåº”é‡**: Cohen's d, Cramer's V
- **ç½®ä¿¡åŒºé—´**: å‚æ•°ä¼°è®¡çš„èŒƒå›´
- **ç»Ÿè®¡åŠŸæ•ˆ**: æ£€éªŒå‡ºçœŸå®æ•ˆåº”çš„èƒ½åŠ›

### é«˜çº§åˆ†ææ–¹æ³•

- **è´å¶æ–¯ABæµ‹è¯•**: èå…¥å…ˆéªŒä¿¡æ¯
- **å¤šå˜é‡å®éªŒ**: åŒæ—¶æµ‹è¯•å¤šä¸ªå› ç´ 
- **æ—¶é—´åºåˆ—åˆ†æ**: è€ƒè™‘æ—¶é—´è¶‹åŠ¿
- **å› æœæ¨æ–­**: å»ºç«‹å› æœå…³ç³»

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ

1. **æ•°æ®æ ¼å¼é”™è¯¯**
   ```python
   # æ£€æŸ¥æ•°æ®æ ¼å¼
   print(data.dtypes)
   print(data.head())
   ```

2. **æ ·æœ¬é‡ä¸è¶³**
   ```python
   # è®¡ç®—æœ€å°æ ·æœ¬é‡
   min_sample_size = analyzer.calculate_sample_size(...)
   if len(data) < min_sample_size:
       print("è­¦å‘Šï¼šæ ·æœ¬é‡ä¸è¶³")
   ```

3. **åˆ†ç»„ä¸å‡è¡¡**
   ```python
   # æ£€æŸ¥åˆ†ç»„å‡è¡¡æ€§
   group_balance = analyzer.check_group_balance(data, 'å®éªŒç»„åˆ«')
   print(group_balance)
   ```

## ğŸ“ è·å–å¸®åŠ©

- æŸ¥çœ‹ç¤ºä¾‹ä»£ç ï¼š`examples/`ç›®å½•
- è¿è¡Œæµ‹è¯•è„šæœ¬ï¼š`python test_skill.py`
- é˜…è¯»è¯¦ç»†æ–‡æ¡£ï¼š`SKILL.md`

## ğŸ‰ å¼€å§‹ä½ çš„ç¬¬ä¸€ä¸ªABæµ‹è¯•åˆ†æ

```bash
# å…‹éš†æˆ–ä¸‹è½½æŠ€èƒ½
cd .claude/skills/ab-testing-analyzer/

# è¿è¡ŒåŸºç¡€ç¤ºä¾‹
python examples/basic_ab_test_example.py

# æŸ¥çœ‹æ›´å¤šç¤ºä¾‹
ls examples/
```

ç°åœ¨ä½ å¯ä»¥å¼€å§‹ä¸“ä¸šçš„ABæµ‹è¯•åˆ†æäº†ï¼ğŸš€