#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Markov Chain Attribution Analysis
Advanced attribution analysis using Markov chain models and removal effects
"""

import pandas as pd
import numpy as np
from scipy.linalg import inv
import networkx as nx
import warnings
warnings.filterwarnings('ignore')

class MarkovChainAttributor:
    """Markov chain-based attribution analysis"""

    def __init__(self):
        """Initialize the Markov chain attributor"""
        self.transition_matrix = None
        self.removal_effects = {}
        self.attribution_weights = {}
        self.channel_graph = None

    def build_transition_matrix(self, paths_df):
        """
        Build transition probability matrix from customer paths

        Args:
            paths_df (pd.DataFrame): Customer journey paths

        Returns:
            pd.DataFrame: Transition probability matrix
        """
        print("\n=== æ„å»ºé©¬å°”å¯å¤«è½¬ç§»çŸ©é˜µ ===")

        # Extract all unique states (channels + start + end states)
        all_states = set()
        for path in paths_df['path']:
            all_states.update(path)

        # Initialize transition counts
        transition_counts = {}
        for state1 in all_states:
            for state2 in all_states:
                transition_counts[f"{state1}>{state2}"] = 0

        # Count transitions
        for path in paths_df['path']:
            for i in range(len(path) - 1):
                current_state = path[i]
                next_state = path[i + 1]
                transition_counts[f"{current_state}>{next_state}"] += 1

        # Calculate transition probabilities
        transition_probabilities = {}
        state_totals = {}

        # Calculate totals for each state (excluding end states)
        for transition, count in transition_counts.items():
            state = transition.split('>')[0]
            if state not in ['æˆåŠŸè½¬åŒ–', 'æœªè½¬åŒ–']:
                state_totals[state] = state_totals.get(state, 0) + count

        # Calculate probabilities
        for transition, count in transition_counts.items():
            state = transition.split('>')[0]
            if state in state_totals and state_totals[state] > 0:
                transition_probabilities[transition] = count / state_totals[state]
            else:
                transition_probabilities[transition] = 0

        # Create transition matrix
        states_list = sorted(list(all_states))
        transition_matrix = pd.DataFrame(0.0, index=states_list, columns=states_list)

        # Fill transition matrix
        for transition, prob in transition_probabilities.items():
            from_state, to_state = transition.split('>')
            transition_matrix.at[from_state, to_state] = prob

        # Set diagonal elements for absorbing states
        for state in ['æˆåŠŸè½¬åŒ–', 'æœªè½¬åŒ–']:
            transition_matrix.at[state, state] = 1.0

        # Set diagonal elements for other states to ensure rows sum to 1
        for state in states_list:
            if state not in ['æˆåŠŸè½¬åŒ–', 'æœªè½¬åŒ–']:
                row_sum = transition_matrix.loc[state].sum()
                if row_sum < 1.0:
                    # Add remaining probability to 'æœªè½¬åŒ–'
                    transition_matrix.at[state, 'æœªè½¬åŒ–'] = 1.0 - row_sum

        self.transition_matrix = transition_matrix

        print(f"è½¬ç§»çŸ©é˜µå½¢çŠ¶: {transition_matrix.shape}")
        print(f"çŠ¶æ€æ•°é‡: {len(states_list)}")
        print(f"çŠ¶æ€åˆ—è¡¨: {states_list}")

        return transition_matrix

    def calculate_removal_effects(self, paths_df, base_conversion_rate):
        """
        Calculate removal effects for each channel

        Args:
            paths_df (pd.DataFrame): Customer journey paths
            base_conversion_rate (float): Base conversion rate

        Returns:
            dict: Removal effects for each channel
        """
        print("\n=== è®¡ç®—ç§»é™¤æ•ˆåº” ===")

        transition_matrix = self.transition_matrix.copy()
        channels = [state for state in transition_matrix.columns
                   if state not in ['å¼€å§‹', 'æœªè½¬åŒ–', 'æˆåŠŸè½¬åŒ–']]

        removal_effects = {}
        base_cvr = base_conversion_rate

        for channel in channels:
            # Create matrix without the channel
            reduced_matrix = transition_matrix.drop(channel, axis=0).drop(channel, axis=1)

            # Adjust probabilities for remaining channels
            for col in reduced_matrix.columns:
                if col not in ['æœªè½¬åŒ–', 'æˆåŠŸè½¬åŒ–']:
                    row_sum = reduced_matrix.loc[col].sum()
                    if row_sum < 1.0:
                        # Add remaining probability to 'æœªè½¬åŒ–'
                        reduced_matrix.at[col, 'æœªè½¬åŒ–'] = 1.0 - row_sum

            # Ensure 'æœªè½¬åŒ–' state absorbs properly
            reduced_matrix.at['æœªè½¬åŒ–', 'æœªè½¬åŒ–'] = 1.0

            # Calculate conversion rate with channel removed
            try:
                # Split matrix into transient and absorbing states
                transient_states = [state for state in reduced_matrix.index
                                  if state not in ['æœªè½¬åŒ–', 'æˆåŠŸè½¬åŒ–']]
                absorbing_states = ['æœªè½¬åŒ–', 'æˆåŠŸè½¬åŒ–']

                if len(transient_states) > 0:
                    Q = reduced_matrix.loc[transient_states, transient_states].values
                    R = reduced_matrix.loc[transient_states, absorbing_states].values

                    # Calculate fundamental matrix
                    I = np.identity(len(Q))
                    N = inv(I - Q)

                    # Calculate absorption probabilities
                    B = np.dot(N, R)

                    # Get probability of successful conversion from start
                    start_index = transient_states.index('å¼€å§‹') if 'å¼€å§‹' in transient_states else 0
                    success_index = absorbing_states.index('æˆåŠŸè½¬åŒ–')
                    new_cvr = B[start_index, success_index]
                else:
                    new_cvr = 0.0

            except:
                # Fallback calculation
                new_cvr = 0.0

            # Calculate removal effect
            removal_effect = 1 - (new_cvr / base_cvr) if base_cvr > 0 else 0
            removal_effects[channel] = removal_effect

            print(f"{channel}: ç§»é™¤æ•ˆåº” = {removal_effect:.4f}")

        self.removal_effects = removal_effects
        return removal_effects

    def calculate_attribution_weights(self):
        """
        Calculate attribution weights based on removal effects

        Returns:
            dict: Attribution weights for each channel
        """
        print("\n=== è®¡ç®—é©¬å°”å¯å¤«å½’å› æƒé‡ ===")

        if not self.removal_effects:
            print("é”™è¯¯: éœ€è¦å…ˆè®¡ç®—ç§»é™¤æ•ˆåº”")
            return {}

        # Normalize removal effects to get attribution weights
        total_effect = sum(self.removal_effects.values())

        if total_effect == 0:
            print("è­¦å‘Š: æ€»ç§»é™¤æ•ˆåº”ä¸º0ï¼Œä½¿ç”¨å‡åŒ€æƒé‡")
            channels = list(self.removal_effects.keys())
            attribution_weights = {channel: 1.0/len(channels) for channel in channels}
        else:
            attribution_weights = {
                channel: effect / total_effect
                for channel, effect in self.removal_effects.items()
            }

        # Sort by attribution weight
        sorted_weights = dict(sorted(attribution_weights.items(),
                                     key=lambda x: x[1], reverse=True))

        print("é©¬å°”å¯å¤«å½’å› æƒé‡:")
        for channel, weight in sorted_weights.items():
            print(f"  {channel}: {weight:.4f} ({weight*100:.1f}%)")

        self.attribution_weights = sorted_weights
        return sorted_weights

    def analyze_channel_transitions(self):
        """
        Analyze channel transition patterns

        Returns:
            dict: Channel transition analysis
        """
        print("\n=== æ¸ é“è½¬æ¢åˆ†æ ===")

        if self.transition_matrix is None:
            print("é”™è¯¯: éœ€è¦å…ˆæ„å»ºè½¬ç§»çŸ©é˜µ")
            return {}

        channels = [state for state in self.transition_matrix.columns
                   if state not in ['å¼€å§‹', 'æœªè½¬åŒ–', 'æˆåŠŸè½¬åŒ–']]

        transition_analysis = {}

        for channel in channels:
            # Outgoing transitions
            outgoing = self.transition_matrix.loc[channel].drop(
                index=['å¼€å§‹', 'æœªè½¬åŒ–', 'æˆåŠŸè½¬åŒ–', channel], errors='ignore'
            )
            outgoing_transitions = outgoing[outgoing > 0].sort_values(ascending=False)

            # Incoming transitions
            incoming = self.transition_matrix[channel].drop(
                index=['å¼€å§‹', 'æœªè½¬åŒ–', 'æˆåŠŸè½¬åŒ–', channel], errors='ignore'
            )
            incoming_transitions = incoming[incoming > 0].sort_values(ascending=False)

            transition_analysis[channel] = {
                'outgoing_transitions': outgoing_transitions.to_dict(),
                'incoming_transitions': incoming_transitions.to_dict(),
                'total_outgoing_prob': outgoing_transitions.sum(),
                'total_incoming_prob': incoming_transitions.sum()
            }

        # Find most common transitions
        all_transitions = []
        for channel in channels:
            outgoing = transition_analysis[channel]['outgoing_transitions']
            for target, prob in outgoing.items():
                all_transitions.append({
                    'from': channel,
                    'to': target,
                    'probability': prob
                })

        all_transitions.sort(key=lambda x: x['probability'], reverse=True)

        print("æœ€å¸¸è§çš„æ¸ é“è½¬æ¢:")
        for i, transition in enumerate(all_transitions[:10]):
            print(f"  {i+1}. {transition['from']} â†’ {transition['to']}: {transition['probability']:.4f}")

        return {
            'channel_transitions': transition_analysis,
            'top_transitions': all_transitions[:10]
        }

    def build_channel_graph(self):
        """
        Build network graph of channel transitions

        Returns:
            networkx.DiGraph: Channel transition graph
        """
        print("\n=== æ„å»ºæ¸ é“è½¬æ¢å›¾ ===")

        if self.transition_matrix is None:
            print("é”™è¯¯: éœ€è¦å…ˆæ„å»ºè½¬ç§»çŸ©é˜µ")
            return None

        channels = [state for state in self.transition_matrix.columns
                   if state not in ['å¼€å§‹', 'æœªè½¬åŒ–', 'æˆåŠŸè½¬åŒ–']]

        # Create directed graph
        G = nx.DiGraph()

        # Add nodes
        for channel in channels:
            G.add_node(channel)

        # Add edges based on transition probabilities
        for channel in channels:
            outgoing = self.transition_matrix.loc[channel].drop(
                index=['å¼€å§‹', 'æœªè½¬åŒ–', 'æˆåŠŸè½¬åŒ–', channel], errors='ignore'
            )
            for target, prob in outgoing.items():
                if prob > 0.01:  # Only include significant transitions
                    G.add_edge(channel, target, weight=prob)

        # Calculate network metrics
        network_metrics = {}
        for node in G.nodes():
            network_metrics[node] = {
                'in_degree': G.in_degree(node),
                'out_degree': G.out_degree(node),
                'clustering': nx.clustering(G, node),
                'betweenness': nx.betweenness_centrality(G).get(node, 0)
            }

        print(f"æ¸ é“è½¬æ¢å›¾æ„å»ºå®Œæˆ:")
        print(f"  èŠ‚ç‚¹æ•°: {G.number_of_nodes()}")
        print(f"  è¾¹æ•°: {G.number_of_edges()}")
        print(f"  å¼ºè¿é€šåˆ†é‡: {nx.number_strongly_connected_components(G)}")

        self.channel_graph = G
        return G

    def simulate_attribution_scenarios(self, scenarios):
        """
        Simulate different attribution scenarios

        Args:
            scenarios (dict): Dictionary of scenario configurations

        Returns:
            dict: Scenario simulation results
        """
        print("\n=== æ¨¡æ‹Ÿå½’å› åœºæ™¯ ===")

        if not self.transition_matrix:
            print("é”™è¯¯: éœ€è¦å…ˆæ„å»ºè½¬ç§»çŸ©é˜µ")
            return {}

        results = {}
        base_matrix = self.transition_matrix.copy()

        for scenario_name, config in scenarios.items():
            print(f"\næ¨¡æ‹Ÿåœºæ™¯: {scenario_name}")

            # Modify transition matrix based on scenario
            modified_matrix = base_matrix.copy()

            for channel, modifications in config.items():
                if channel in modified_matrix.index:
                    for target_channel, new_prob in modifications.items():
                        if target_channel in modified_matrix.columns:
                            modified_matrix.at[channel, target_channel] = new_prob

            # Calculate new conversion rate
            try:
                transient_states = [state for state in modified_matrix.index
                                  if state not in ['æœªè½¬åŒ–', 'æˆåŠŸè½¬åŒ–']]
                absorbing_states = ['æœªè½¬åŒ–', 'æˆåŠŸè½¬åŒ–']

                if len(transient_states) > 0:
                    Q = modified_matrix.loc[transient_states, transient_states].values
                    R = modified_matrix.loc[transient_states, absorbing_states].values

                    I = np.identity(len(Q))
                    N = inv(I - Q)
                    B = np.dot(N, R)

                    start_index = transient_states.index('å¼€å§‹') if 'å¼€å§‹' in transient_states else 0
                    success_index = absorbing_states.index('æˆåŠŸè½¬åŒ–')
                    simulated_cvr = B[start_index, success_index]
                else:
                    simulated_cvr = 0.0

            except Exception as e:
                print(f"åœºæ™¯è®¡ç®—å¤±è´¥: {str(e)}")
                simulated_cvr = 0.0

            results[scenario_name] = {
                'conversion_rate': simulated_cvr,
                'configuration': config
            }

        return results

    def generate_markov_insights(self):
        """
        Generate insights from Markov chain analysis

        Returns:
            dict: Markov chain analysis insights
        """
        print("\n=== ç”Ÿæˆé©¬å°”å¯å¤«é“¾æ´å¯Ÿ ===")

        insights = {}

        if self.attribution_weights:
            # Identify dominant channels
            sorted_channels = sorted(self.attribution_weights.items(),
                                    key=lambda x: x[1], reverse=True)

            insights['dominant_channels'] = sorted_channels[:3]
            insights['underperforming_channels'] = sorted_channels[-3:]

        if self.transition_matrix is not None:
            # Analyze conversion bottlenecks
            channels = [state for state in self.transition_matrix.columns
                       if state not in ['å¼€å§‹', 'æœªè½¬åŒ–', 'æˆåŠŸè½¬åŒ–']]

            bottlenecks = []
            for channel in channels:
                direct_to_conversion = self.transition_matrix.at[channel, 'æˆåŠŸè½¬åŒ–']
                if direct_to_conversion > 0:
                    bottlenecks.append((channel, direct_to_conversion))

            bottlenecks.sort(key=lambda x: x[1], reverse=True)
            insights['conversion_bottlenecks'] = bottlenecks

        if self.channel_graph is not None:
            # Network insights
            centrality = nx.betweenness_centrality(self.channel_graph)
            insights['most_influential_channels'] = sorted(
                centrality.items(), key=lambda x: x[1], reverse=True
            )[:3]

        print("é©¬å°”å¯å¤«é“¾åˆ†ææ´å¯Ÿ:")
        if 'dominant_channels' in insights:
            print("  ä¸»å¯¼æ¸ é“:")
            for channel, weight in insights['dominant_channels']:
                print(f"    {channel}: {weight:.4f}")

        return insights

    def run_complete_markov_analysis(self, paths_df):
        """
        Run complete Markov chain attribution analysis

        Args:
            paths_df (pd.DataFrame): Customer journey paths

        Returns:
            dict: Complete Markov chain analysis results
        """
        print("ğŸ”— å¼€å§‹é©¬å°”å¯å¤«é“¾å½’å› åˆ†æ")
        print("=" * 50)

        # Calculate base conversion rate
        base_conversion_rate = paths_df['converted'].mean()

        # 1. Build transition matrix
        transition_matrix = self.build_transition_matrix(paths_df)

        # 2. Calculate removal effects
        removal_effects = self.calculate_removal_effects(paths_df, base_conversion_rate)

        # 3. Calculate attribution weights
        attribution_weights = self.calculate_attribution_weights()

        # 4. Analyze channel transitions
        transition_analysis = self.analyze_channel_transitions()

        # 5. Build channel graph
        channel_graph = self.build_channel_graph()

        # 6. Generate insights
        insights = self.generate_markov_insights()

        results = {
            'transition_matrix': transition_matrix,
            'removal_effects': removal_effects,
            'attribution_weights': attribution_weights,
            'transition_analysis': transition_analysis,
            'channel_graph': channel_graph,
            'insights': insights,
            'base_conversion_rate': base_conversion_rate
        }

        print(f"\nâœ… é©¬å¯å¤«é“¾åˆ†æå®Œæˆï¼")
        print(f"åŸºç¡€è½¬åŒ–ç‡: {base_conversion_rate:.2%}")
        print(f"è¯†åˆ«äº† {len(attribution_weights)} ä¸ªæ¸ é“çš„å½’å› æƒé‡")
        print(f"åˆ†æäº† {len(transition_analysis['channel_transitions'])} ä¸ªæ¸ é“çš„è½¬æ¢æ¨¡å¼")

        return results

def main():
    """Example usage of Markov chain attributor"""
    attributor = MarkovChainAttributor()

    # Create sample data for demonstration
    sample_paths = [
        ['å¼€å§‹', 'ä»˜è´¹æœç´¢', 'ç¤¾äº¤åª’ä½“', 'æˆåŠŸè½¬åŒ–'],
        ['å¼€å§‹', 'ç¤¾äº¤åª’ä½“', 'ä»˜è´¹æœç´¢', 'æˆåŠŸè½¬åŒ–'],
        ['å¼€å§‹', 'é‚®ä»¶è¥é”€', 'ç¤¾äº¤åª’ä½“', 'ä»˜è´¹æœç´¢', 'æˆåŠŸè½¬åŒ–'],
        ['å¼€å§‹', 'ä»˜è´¹æœç´¢', 'æœªè½¬åŒ–'],
        ['å¼€å§‹', 'ç¤¾äº¤åª’ä½“', 'æœªè½¬åŒ–'],
        ['å¼€å§‹', 'é‚®ä»¶è¥é”€', 'æœªè½¬åŒ–']
    ]

    paths_df = pd.DataFrame({
        'user_id': range(len(sample_paths)),
        'path': sample_paths,
        'converted': [1, 1, 1, 0, 0, 0],
        'conversion_value': [100, 150, 80, 0, 0, 0]
    })

    results = attributor.run_complete_markov_analysis(paths_df)

    print(f"\né©¬å°”å¯å¤«å½’å› æƒé‡:")
    for channel, weight in results['attribution_weights'].items():
        print(f"  {channel}: {weight:.4f}")

if __name__ == "__main__":
    main()