"""
æ•°æ®æ¢ç´¢åˆ†æå™¨ (EDA Analyzer) - è‡ªåŠ¨åŒ–æ¢ç´¢æ€§æ•°æ®åˆ†ææ ¸å¿ƒæ¨¡å—

æä¾›å…¨é¢çš„EDAåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- è‡ªåŠ¨æ•°æ®è´¨é‡æ£€æŸ¥
- ç»Ÿè®¡æè¿°åˆ†æ
- å¼‚å¸¸å€¼æ£€æµ‹
- ç›¸å…³æ€§åˆ†æ
- æ•°æ®åˆ†å¸ƒåˆ†æ
- æ™ºèƒ½æ´å¯Ÿç”Ÿæˆ
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Union, Any
import warnings
from scipy import stats
from scipy.stats import normaltest, shapiro, anderson, jarque_bera
import json
from datetime import datetime

warnings.filterwarnings('ignore')


class EDAAnalyzer:
    """æ•°æ®æ¢ç´¢åˆ†æå™¨ - è‡ªåŠ¨åŒ–EDAæ ¸å¿ƒå¼•æ“"""

    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–EDAåˆ†æå™¨

        Parameters:
        - config: é…ç½®å‚æ•°å­—å…¸
        """
        self.config = config or {}
        self.data = None
        self.results = {}
        self.report = None

        # é»˜è®¤é…ç½®
        self.default_config = {
            'missing_threshold': 0.05,  # ç¼ºå¤±å€¼é˜ˆå€¼
            'outlier_method': 'iqr',    # å¼‚å¸¸å€¼æ£€æµ‹æ–¹æ³•
            'correlation_method': 'pearson',  # ç›¸å…³æ€§è®¡ç®—æ–¹æ³•
            'significance_level': 0.05,  # æ˜¾è‘—æ€§æ°´å¹³
            'sample_size_threshold': 10000,  # å¤§æ•°æ®é›†é˜ˆå€¼
            'encoding_detection': True,  # è‡ªåŠ¨ç¼–ç æ£€æµ‹
            'chinese_support': True     # ä¸­æ–‡æ”¯æŒ
        }

        # åˆå¹¶é…ç½®
        self.config = {**self.default_config, **self.config}

    def load_data(self, data_path: str, **kwargs) -> pd.DataFrame:
        """
        åŠ è½½æ•°æ®æ–‡ä»¶

        Parameters:
        - data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
        - **kwargs: pandas.read_csvçš„é¢å¤–å‚æ•°

        Returns:
        - åŠ è½½çš„DataFrame
        """
        try:
            # è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶æ ¼å¼
            if data_path.endswith('.csv'):
                # è‡ªåŠ¨æ£€æµ‹ç¼–ç 
                if self.config['encoding_detection']:
                    encodings = ['utf-8', 'gbk', 'gb2312', 'utf-8-sig', 'latin1']
                    for encoding in encodings:
                        try:
                            data = pd.read_csv(data_path, encoding=encoding, **kwargs)
                            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œä½¿ç”¨ç¼–ç : {encoding}")
                            break
                        except UnicodeDecodeError:
                            continue
                    else:
                        raise ValueError("æ— æ³•æ£€æµ‹åˆ°æ­£ç¡®çš„æ–‡ä»¶ç¼–ç ")
                else:
                    data = pd.read_csv(data_path, **kwargs)

            elif data_path.endswith(('.xlsx', '.xls')):
                data = pd.read_excel(data_path, **kwargs)
                print("âœ… Excelæ–‡ä»¶åŠ è½½æˆåŠŸ")

            elif data_path.endswith('.json'):
                data = pd.read_json(data_path, **kwargs)
                print("âœ… JSONæ–‡ä»¶åŠ è½½æˆåŠŸ")

            else:
                raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä½¿ç”¨CSVã€Excelæˆ–JSONæ ¼å¼")

            self.data = data
            self._log_basic_info()

            return data

        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
            raise

    def _log_basic_info(self):
        """è®°å½•æ•°æ®åŸºæœ¬ä¿¡æ¯"""
        if self.data is not None:
            print(f"ğŸ“Š æ•°æ®åŸºæœ¬ä¿¡æ¯:")
            print(f"   - æ•°æ®å½¢çŠ¶: {self.data.shape}")
            print(f"   - å†…å­˜ä½¿ç”¨: {self.data.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
            print(f"   - åˆ—æ•°: {len(self.data.columns)}")
            print(f"   - æ•°æ®ç±»å‹åˆ†å¸ƒ:\n{self.data.dtypes.value_counts()}")

    def data_quality_check(self, data: Optional[pd.DataFrame] = None) -> Dict:
        """
        æ•°æ®è´¨é‡æ£€æŸ¥

        Parameters:
        - data: å¾…æ£€æŸ¥çš„æ•°æ®

        Returns:
        - æ•°æ®è´¨é‡æŠ¥å‘Š
        """
        if data is None:
            data = self.data

        if data is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®")

        quality_report = {
            'basic_info': {
                'shape': data.shape,
                'memory_usage_mb': data.memory_usage(deep=True).sum() / 1024**2,
                'total_cells': data.shape[0] * data.shape[1]
            },
            'missing_values': {},
            'data_types': {},
            'duplicates': {},
            'outliers': {},
            'data_quality_score': 0,
            'issues': [],
            'recommendations': []
        }

        # 1. ç¼ºå¤±å€¼åˆ†æ
        missing_analysis = self._analyze_missing_values(data)
        quality_report['missing_values'] = missing_analysis

        # 2. æ•°æ®ç±»å‹åˆ†æ
        dtype_analysis = self._analyze_data_types(data)
        quality_report['data_types'] = dtype_analysis

        # 3. é‡å¤å€¼åˆ†æ
        duplicate_analysis = self._analyze_duplicates(data)
        quality_report['duplicates'] = duplicate_analysis

        # 4. å¼‚å¸¸å€¼åˆ†æï¼ˆä»…æ•°å€¼åˆ—ï¼‰
        outlier_analysis = self._analyze_outliers(data)
        quality_report['outliers'] = outlier_analysis

        # 5. è®¡ç®—æ•°æ®è´¨é‡åˆ†æ•°
        quality_score = self._calculate_quality_score(quality_report)
        quality_report['data_quality_score'] = quality_score

        # 6. ç”Ÿæˆé—®é¢˜å’Œå»ºè®®
        issues, recommendations = self._generate_quality_recommendations(quality_report)
        quality_report['issues'] = issues
        quality_report['recommendations'] = recommendations

        self.results['data_quality'] = quality_report
        return quality_report

    def _analyze_missing_values(self, data: pd.DataFrame) -> Dict:
        """åˆ†æç¼ºå¤±å€¼"""
        missing_info = {}

        # æ€»ä½“ç¼ºå¤±å€¼æƒ…å†µ
        total_missing = data.isnull().sum().sum()
        total_cells = data.shape[0] * data.shape[1]
        overall_missing_rate = total_missing / total_cells

        missing_info['overall'] = {
            'total_missing': total_missing,
            'total_cells': total_cells,
            'missing_rate': overall_missing_rate,
            'quality_rating': self._rate_missing_quality(overall_missing_rate)
        }

        # å„åˆ—ç¼ºå¤±å€¼è¯¦æƒ…
        missing_columns = {}
        for col in data.columns:
            missing_count = data[col].isnull().sum()
            if missing_count > 0:
                missing_rate = missing_count / len(data)
                missing_columns[col] = {
                    'missing_count': missing_count,
                    'missing_rate': missing_rate,
                    'severity': self._classify_missing_severity(missing_rate)
                }

        missing_info['columns'] = missing_columns
        missing_info['missing_columns_count'] = len(missing_columns)

        # ç¼ºå¤±å€¼æ¨¡å¼åˆ†æ
        missing_patterns = self._analyze_missing_patterns(data)
        missing_info['patterns'] = missing_patterns

        return missing_info

    def _analyze_data_types(self, data: pd.DataFrame) -> Dict:
        """åˆ†ææ•°æ®ç±»å‹"""
        dtype_info = {
            'type_distribution': data.dtypes.value_counts().to_dict(),
            'numeric_columns': list(data.select_dtypes(include=[np.number]).columns),
            'categorical_columns': list(data.select_dtypes(include=['object', 'category']).columns),
            'datetime_columns': list(data.select_dtypes(include=['datetime64']).columns),
            'type_issues': []
        }

        # æ£€æµ‹å¯èƒ½çš„ç±»å‹é—®é¢˜
        for col in data.columns:
            if data[col].dtype == 'object':
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ˜¯æ•°å€¼ç±»å‹
                try:
                    pd.to_numeric(data[col], errors='raise')
                    dtype_info['type_issues'].append({
                        'column': col,
                        'issue': 'å¯èƒ½åº”è¯¥æ˜¯æ•°å€¼ç±»å‹',
                        'suggestion': 'å°è¯•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹'
                    })
                except:
                    pass

                # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ˜¯æ—¥æœŸç±»å‹
                if data[col].dtype == 'object':
                    sample_values = data[col].dropna().head(5).astype(str)
                    if any('/' in val or '-' in val for val in sample_values if val):
                        try:
                            pd.to_datetime(data[col], errors='raise')
                            dtype_info['type_issues'].append({
                                'column': col,
                                'issue': 'å¯èƒ½åº”è¯¥æ˜¯æ—¥æœŸç±»å‹',
                                'suggestion': 'å°è¯•è½¬æ¢ä¸ºæ—¥æœŸç±»å‹'
                            })
                        except:
                            pass

        return dtype_info

    def _analyze_duplicates(self, data: pd.DataFrame) -> Dict:
        """åˆ†æé‡å¤å€¼"""
        duplicate_info = {}

        # å®Œå…¨é‡å¤è¡Œ
        duplicate_rows = data.duplicated().sum()
        duplicate_info['exact_duplicates'] = {
            'count': duplicate_rows,
            'rate': duplicate_rows / len(data),
            'severity': self._classify_duplicate_severity(duplicate_rows / len(data))
        }

        # åŸºäºå…³é”®å­—æ®µçš„é‡å¤ï¼ˆå¦‚æœå­˜åœ¨IDåˆ—ï¼‰
        id_columns = [col for col in data.columns if any(keyword in col.lower()
                      for keyword in ['id', 'ç¼–å·', 'code', 'æ ‡è¯†'])]

        if id_columns:
            for id_col in id_columns[:3]:  # æœ€å¤šæ£€æŸ¥3ä¸ªIDåˆ—
                id_duplicates = data[id_col].duplicated().sum()
                duplicate_info[f'{id_col}_duplicates'] = {
                    'count': id_duplicates,
                    'rate': id_duplicates / len(data),
                    'severity': self._classify_duplicate_severity(id_duplicates / len(data))
                }

        return duplicate_info

    def _analyze_outliers(self, data: pd.DataFrame) -> Dict:
        """åˆ†æå¼‚å¸¸å€¼"""
        outlier_info = {}
        numeric_columns = data.select_dtypes(include=[np.number]).columns

        method = self.config['outlier_method']

        for col in numeric_columns:
            outliers = self._detect_outliers(data[col], method)
            if len(outliers) > 0:
                outlier_info[col] = {
                    'outlier_count': len(outliers),
                    'outlier_rate': len(outliers) / len(data),
                    'outlier_indices': outliers.tolist(),
                    'severity': self._classify_outlier_severity(len(outliers) / len(data))
                }

        outlier_info['total_outlier_columns'] = len(outlier_info)
        outlier_info['detection_method'] = method

        return outlier_info

    def _detect_outliers(self, series: pd.Series, method: str = 'iqr') -> np.ndarray:
        """æ£€æµ‹å¼‚å¸¸å€¼"""
        series_clean = series.dropna()

        if method == 'iqr':
            Q1 = series_clean.quantile(0.25)
            Q3 = series_clean.quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            outliers = series_clean[(series_clean < lower_bound) | (series_clean > upper_bound)]

        elif method == 'zscore':
            z_scores = np.abs(stats.zscore(series_clean))
            outliers = series_clean[z_scores > 3]

        elif method == 'modified_zscore':
            median = series_clean.median()
            mad = np.median(np.abs(series_clean - median))
            modified_z_scores = 0.6745 * (series_clean - median) / mad
            outliers = series_clean[np.abs(modified_z_scores) > 3.5]

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¼‚å¸¸å€¼æ£€æµ‹æ–¹æ³•: {method}")

        return outliers.index.values

    def generate_statistical_summary(self, data: Optional[pd.DataFrame] = None) -> Dict:
        """
        ç”Ÿæˆç»Ÿè®¡æè¿°æ‘˜è¦

        Parameters:
        - data: å¾…åˆ†æçš„æ•°æ®

        Returns:
        - ç»Ÿè®¡æ‘˜è¦
        """
        if data is None:
            data = self.data

        if data is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®")

        summary = {
            'dataset_info': {
                'shape': data.shape,
                'columns_count': len(data.columns),
                'memory_usage_mb': data.memory_usage(deep=True).sum() / 1024**2
            },
            'numeric_summary': {},
            'categorical_summary': {},
            'distribution_tests': {},
            'correlation_analysis': {}
        }

        # æ•°å€¼åˆ—ç»Ÿè®¡æ‘˜è¦
        numeric_cols = data.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            numeric_stats = data[numeric_cols].describe()

            # æ·»åŠ é¢å¤–çš„ç»Ÿè®¡æŒ‡æ ‡
            for col in numeric_cols:
                if data[col].dtype in [np.number]:
                    extra_stats = {
                        'skewness': stats.skew(data[col].dropna()),
                        'kurtosis': stats.kurtosis(data[col].dropna()),
                        'cv': stats.variation(data[col].dropna()),  # å˜å¼‚ç³»æ•°
                        'missing_rate': data[col].isnull().sum() / len(data),
                        'unique_count': data[col].nunique()
                    }

                    # æ­£æ€æ€§æ£€éªŒï¼ˆå¦‚æœæ ·æœ¬é‡åˆé€‚ï¼‰
                    if len(data[col].dropna()) >= 8 and len(data[col].dropna()) <= 5000:
                        try:
                            # Shapiro-Wilkæ£€éªŒï¼ˆå°æ ·æœ¬ï¼‰
                            if len(data[col].dropna()) <= 50:
                                stat, p_value = shapiro(data[col].dropna())
                                test_name = 'Shapiro-Wilk'
                            else:
                                # D'Agostino's K-squaredæ£€éªŒï¼ˆå¤§æ ·æœ¬ï¼‰
                                stat, p_value = normaltest(data[col].dropna())
                                test_name = "D'Agostino's K-squared"

                            summary['distribution_tests'][col] = {
                                'test_name': test_name,
                                'statistic': stat,
                                'p_value': p_value,
                                'is_normal': p_value > self.config['significance_level'],
                                'interpretation': 'æ­£æ€åˆ†å¸ƒ' if p_value > self.config['significance_level'] else 'éæ­£æ€åˆ†å¸ƒ'
                            }
                        except:
                            summary['distribution_tests'][col] = {
                                'test_name': 'Failed',
                                'reason': 'æ— æ³•æ‰§è¡Œæ­£æ€æ€§æ£€éªŒ'
                            }

                    summary['numeric_summary'][col] = {
                        **numeric_stats[col].to_dict(),
                        **extra_stats
                    }

        # åˆ†ç±»åˆ—ç»Ÿè®¡æ‘˜è¦
        categorical_cols = data.select_dtypes(include=['object', 'category']).columns
        if len(categorical_cols) > 0:
            for col in categorical_cols:
                cat_stats = {
                    'unique_count': data[col].nunique(),
                    'most_frequent': data[col].mode().iloc[0] if not data[col].mode().empty else None,
                    'most_frequent_count': data[col].value_counts().iloc[0] if len(data[col].value_counts()) > 0 else 0,
                    'missing_rate': data[col].isnull().sum() / len(data),
                    'value_counts': data[col].value_counts().head(10).to_dict()  # å‰10ä¸ªå€¼
                }

                # åˆ†ç±»å˜é‡çš„å‡åŒ€æ€§æ£€éªŒ
                if data[col].nunique() <= 10:  # åªå¯¹ç±»åˆ«æ•°è¾ƒå°‘çš„å˜é‡è¿›è¡Œæ£€éªŒ
                    try:
                        observed = data[col].value_counts().values
                        expected = [len(data) / len(observed)] * len(observed)
                        chi2_stat, p_value = stats.chisquare(observed, expected)

                        cat_stats['uniformity_test'] = {
                            'chi2_statistic': chi2_stat,
                            'p_value': p_value,
                            'is_uniform': p_value > self.config['significance_level'],
                            'interpretation': 'åˆ†å¸ƒå‡åŒ€' if p_value > self.config['significance_level'] else 'åˆ†å¸ƒä¸å‡åŒ€'
                        }
                    except:
                        cat_stats['uniformity_test'] = {
                            'test_name': 'Failed',
                            'reason': 'æ— æ³•æ‰§è¡Œå‡åŒ€æ€§æ£€éªŒ'
                        }

                summary['categorical_summary'][col] = cat_stats

        # ç›¸å…³æ€§åˆ†æ
        if len(numeric_cols) > 1:
            correlation_matrix = data[numeric_cols].corr(method=self.config['correlation_method'])

            # æ‰¾å‡ºé«˜ç›¸å…³æ€§çš„å˜é‡å¯¹
            high_corr_pairs = []
            for i in range(len(correlation_matrix.columns)):
                for j in range(i+1, len(correlation_matrix.columns)):
                    corr_val = correlation_matrix.iloc[i, j]
                    if abs(corr_val) > 0.7:  # é«˜ç›¸å…³æ€§é˜ˆå€¼
                        high_corr_pairs.append({
                            'variable1': correlation_matrix.columns[i],
                            'variable2': correlation_matrix.columns[j],
                            'correlation': corr_val,
                            'strength': self._interpret_correlation_strength(abs(corr_val))
                        })

            summary['correlation_analysis'] = {
                'correlation_matrix': correlation_matrix.to_dict(),
                'method': self.config['correlation_method'],
                'high_correlation_pairs': high_corr_pairs,
                'max_correlation': correlation_matrix.abs().max().max(),
                'avg_correlation': correlation_matrix.abs().mean().mean()
            }

        self.results['statistical_summary'] = summary
        return summary

    def auto_eda(self, data: Optional[pd.DataFrame] = None) -> Dict:
        """
        è‡ªåŠ¨åŒ–EDAåˆ†æ

        Parameters:
        - data: å¾…åˆ†æçš„æ•°æ®

        Returns:
        - å®Œæ•´çš„EDAåˆ†æç»“æœ
        """
        if data is None:
            data = self.data

        if data is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®")

        print("ğŸš€ å¼€å§‹è‡ªåŠ¨åŒ–EDAåˆ†æ...")

        # 1. æ•°æ®è´¨é‡æ£€æŸ¥
        print("   1. æ•°æ®è´¨é‡æ£€æŸ¥...")
        quality_report = self.data_quality_check(data)

        # 2. ç»Ÿè®¡æ‘˜è¦åˆ†æ
        print("   2. ç»Ÿè®¡æ‘˜è¦åˆ†æ...")
        stats_summary = self.generate_statistical_summary(data)

        # 3. ç”Ÿæˆæ´å¯Ÿ
        print("   3. ç”Ÿæˆæ•°æ®æ´å¯Ÿ...")
        insights = self._generate_insights(quality_report, stats_summary)

        # 4. æ•°æ®å»ºè®®
        print("   4. ç”Ÿæˆå¤„ç†å»ºè®®...")
        recommendations = self._generate_recommendations(quality_report, stats_summary)

        # ç»¼åˆç»“æœ
        eda_results = {
            'analysis_time': datetime.now().isoformat(),
            'data_quality': quality_report,
            'statistical_summary': stats_summary,
            'insights': insights,
            'recommendations': recommendations,
            'next_steps': self._suggest_next_steps(quality_report, stats_summary)
        }

        self.results['auto_eda'] = eda_results
        self._print_eda_summary(eda_results)

        return eda_results

    def _generate_insights(self, quality_report: Dict, stats_summary: Dict) -> List[str]:
        """ç”Ÿæˆæ•°æ®æ´å¯Ÿ"""
        insights = []

        # æ•°æ®è´¨é‡æ´å¯Ÿ
        quality_score = quality_report['data_quality_score']
        if quality_score >= 0.8:
            insights.append("æ•°æ®è´¨é‡ä¼˜ç§€ï¼Œé€‚åˆç›´æ¥è¿›è¡Œåˆ†æ")
        elif quality_score >= 0.6:
            insights.append("æ•°æ®è´¨é‡è‰¯å¥½ï¼Œä½†å­˜åœ¨ä¸€äº›éœ€è¦å…³æ³¨çš„é—®é¢˜")
        else:
            insights.append("æ•°æ®è´¨é‡éœ€è¦æ”¹å–„ï¼Œå»ºè®®è¿›è¡Œæ•°æ®æ¸…æ´—")

        # ç¼ºå¤±å€¼æ´å¯Ÿ
        missing_rate = quality_report['missing_values']['overall']['missing_rate']
        if missing_rate > 0.1:
            insights.append(f"æ•°æ®å­˜åœ¨è¾ƒé«˜ç¼ºå¤±ç‡({missing_rate:.1%})ï¼Œéœ€è¦é’ˆå¯¹æ€§å¤„ç†")
        elif missing_rate > 0.05:
            insights.append(f"æ•°æ®å­˜åœ¨å°‘é‡ç¼ºå¤±å€¼({missing_rate:.1%})ï¼Œå¯è€ƒè™‘å¡«å……æˆ–åˆ é™¤")

        # æ•°æ®åˆ†å¸ƒæ´å¯Ÿ
        normal_distributions = sum(1 for test in stats_summary['distribution_tests'].values()
                                 if test.get('is_normal', False))
        total_tests = len(stats_summary['distribution_tests'])

        if total_tests > 0:
            normal_ratio = normal_distributions / total_tests
            if normal_ratio > 0.7:
                insights.append("å¤§éƒ¨åˆ†æ•°å€¼å˜é‡å‘ˆæ­£æ€åˆ†å¸ƒï¼Œé€‚åˆå‚æ•°ç»Ÿè®¡æ–¹æ³•")
            elif normal_ratio < 0.3:
                insights.append("å¤§éƒ¨åˆ†æ•°å€¼å˜é‡å‘ˆéæ­£æ€åˆ†å¸ƒï¼Œå»ºè®®ä½¿ç”¨éå‚æ•°æ–¹æ³•")

        # ç›¸å…³æ€§æ´å¯Ÿ
        if 'correlation_analysis' in stats_summary:
            high_corr_count = len(stats_summary['correlation_analysis']['high_correlation_pairs'])
            if high_corr_count > 0:
                insights.append(f"å‘ç°{high_corr_count}å¯¹é«˜åº¦ç›¸å…³çš„å˜é‡ï¼Œå¯èƒ½å­˜åœ¨å¤šé‡å…±çº¿æ€§é—®é¢˜")

        return insights

    def _generate_recommendations(self, quality_report: Dict, stats_summary: Dict) -> List[str]:
        """ç”Ÿæˆå¤„ç†å»ºè®®"""
        recommendations = []

        # åŸºäºè´¨é‡æŠ¥å‘Šçš„å»ºè®®
        recommendations.extend(quality_report.get('recommendations', []))

        # åŸºäºç»Ÿè®¡æ‘˜è¦çš„å»ºè®®
        # å¼‚å¸¸å€¼å¤„ç†å»ºè®®
        outlier_columns = len(quality_report['outliers'])
        if outlier_columns > 0:
            recommendations.append(f"å‘ç°{outlier_columns}ä¸ªå˜é‡å­˜åœ¨å¼‚å¸¸å€¼ï¼Œå»ºè®®è¿›è¡Œå¼‚å¸¸å€¼å¤„ç†")

        # æ•°æ®ç±»å‹å»ºè®®
        type_issues = quality_report['data_types']['type_issues']
        if type_issues:
            recommendations.append("æ£€æµ‹åˆ°æ•°æ®ç±»å‹é—®é¢˜ï¼Œå»ºè®®æ£€æŸ¥å¹¶ä¿®æ­£æ•°æ®ç±»å‹")

        # æ­£æ€æ€§å»ºè®®
        for col, test in stats_summary['distribution_tests'].items():
            if not test.get('is_normal', False) and test.get('p_value') is not None:
                recommendations.append(f"å˜é‡'{col}'éæ­£æ€åˆ†å¸ƒï¼Œè€ƒè™‘æ•°æ®å˜æ¢æˆ–ä½¿ç”¨éå‚æ•°æ–¹æ³•")

        return recommendations

    def _suggest_next_steps(self, quality_report: Dict, stats_summary: Dict) -> List[str]:
        """å»ºè®®ä¸‹ä¸€æ­¥æ“ä½œ"""
        next_steps = []

        # åŸºäºæ•°æ®è´¨é‡ç¡®å®šä¼˜å…ˆçº§
        quality_score = quality_report['data_quality_score']

        if quality_score < 0.6:
            next_steps.extend([
                "1. ä¼˜å…ˆè¿›è¡Œæ•°æ®æ¸…æ´—å’Œè´¨é‡æ”¹å–„",
                "2. å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼",
                "3. ä¿®æ­£æ•°æ®ç±»å‹é—®é¢˜"
            ])
        else:
            next_steps.extend([
                "1. è¿›è¡Œæ•°æ®å¯è§†åŒ–åˆ†æ",
                "2. æ¢ç´¢å˜é‡é—´å…³ç³»",
                "3. è€ƒè™‘ç‰¹å¾å·¥ç¨‹"
            ])

        # åŸºäºæ•°æ®ç‰¹å¾å»ºè®®åˆ†ææ–¹æ³•
        numeric_cols = len(stats_summary['numeric_summary'])
        categorical_cols = len(stats_summary['categorical_summary'])

        if numeric_cols > 5:
            next_steps.append("å»ºè®®è¿›è¡Œé™ç»´åˆ†æï¼ˆå¦‚PCAï¼‰")

        if categorical_cols > 3:
            next_steps.append("å»ºè®®è¿›è¡Œç¼–ç è½¬æ¢å¤„ç†")

        # ç›¸å…³æ€§åˆ†æå»ºè®®
        if 'correlation_analysis' in stats_summary:
            high_corr_pairs = stats_summary['correlation_analysis']['high_correlation_pairs']
            if high_corr_pairs:
                next_steps.append("å¤„ç†é«˜ç›¸å…³æ€§å˜é‡ä»¥é¿å…å¤šé‡å…±çº¿æ€§")

        return next_steps

    def _print_eda_summary(self, eda_results: Dict):
        """æ‰“å°EDAåˆ†ææ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ‰ è‡ªåŠ¨åŒ–EDAåˆ†æå®Œæˆ!")
        print("="*60)

        quality_score = eda_results['data_quality']['data_quality_score']
        print(f"\nğŸ“Š æ•°æ®è´¨é‡è¯„åˆ†: {quality_score:.2f}/1.00")

        print(f"\nğŸ’¡ ä¸»è¦æ´å¯Ÿ:")
        for insight in eda_results['insights']:
            print(f"   â€¢ {insight}")

        print(f"\nğŸ“‹ å…³é”®å»ºè®®:")
        for rec in eda_results['recommendations'][:5]:  # æ˜¾ç¤ºå‰5ä¸ªå»ºè®®
            print(f"   â€¢ {rec}")

        print(f"\nğŸ”„ ä¸‹ä¸€æ­¥æ“ä½œ:")
        for step in eda_results['next_steps']:
            print(f"   â€¢ {step}")

    # è¾…åŠ©æ–¹æ³•
    def _rate_missing_quality(self, missing_rate: float) -> str:
        """è¯„ä¼°ç¼ºå¤±å€¼è´¨é‡"""
        if missing_rate == 0:
            return "å®Œç¾"
        elif missing_rate < 0.01:
            return "ä¼˜ç§€"
        elif missing_rate < 0.05:
            return "è‰¯å¥½"
        elif missing_rate < 0.15:
            return "ä¸€èˆ¬"
        else:
            return "è¾ƒå·®"

    def _classify_missing_severity(self, missing_rate: float) -> str:
        """åˆ†ç±»ç¼ºå¤±å€¼ä¸¥é‡ç¨‹åº¦"""
        if missing_rate < 0.01:
            return "å¾ˆä½"
        elif missing_rate < 0.05:
            return "ä½"
        elif missing_rate < 0.15:
            return "ä¸­ç­‰"
        elif missing_rate < 0.30:
            return "é«˜"
        else:
            return "æé«˜"

    def _classify_duplicate_severity(self, duplicate_rate: float) -> str:
        """åˆ†ç±»é‡å¤å€¼ä¸¥é‡ç¨‹åº¦"""
        if duplicate_rate < 0.01:
            return "å¾ˆä½"
        elif duplicate_rate < 0.05:
            return "ä½"
        elif duplicate_rate < 0.10:
            return "ä¸­ç­‰"
        else:
            return "é«˜"

    def _classify_outlier_severity(self, outlier_rate: float) -> str:
        """åˆ†ç±»å¼‚å¸¸å€¼ä¸¥é‡ç¨‹åº¦"""
        if outlier_rate < 0.01:
            return "å¾ˆä½"
        elif outlier_rate < 0.05:
            return "ä½"
        elif outlier_rate < 0.10:
            return "ä¸­ç­‰"
        else:
            return "é«˜"

    def _analyze_missing_patterns(self, data: pd.DataFrame) -> Dict:
        """åˆ†æç¼ºå¤±å€¼æ¨¡å¼"""
        # è®¡ç®—ç¼ºå¤±å€¼æ¨¡å¼
        missing_matrix = data.isnull()

        # æ‰¾å‡ºå¸¸è§çš„ç¼ºå¤±å€¼ç»„åˆ
        missing_combinations = {}

        # å¦‚æœæ•°æ®å¤ªå¤§ï¼Œè¿›è¡Œé‡‡æ ·
        if len(data) > self.config['sample_size_threshold']:
            sample_data = data.sample(min(self.config['sample_size_threshold'], len(data)))
        else:
            sample_data = data

        missing_combinations = sample_data.isnull().value_counts().head(10).to_dict()

        return {
            'common_patterns': {str(k): v for k, v in missing_combinations.items()},
            'total_patterns': len(missing_combinations)
        }

    def _calculate_quality_score(self, quality_report: Dict) -> float:
        """è®¡ç®—æ•°æ®è´¨é‡åˆ†æ•°"""
        score = 1.0

        # ç¼ºå¤±å€¼æ‰£åˆ†
        missing_rate = quality_report['missing_values']['overall']['missing_rate']
        score -= missing_rate * 0.5

        # é‡å¤å€¼æ‰£åˆ†
        duplicate_rate = quality_report['duplicates']['exact_duplicates']['rate']
        score -= duplicate_rate * 0.3

        # å¼‚å¸¸å€¼æ‰£åˆ†
        outlier_cols = quality_report['outliers']['total_outlier_columns']
        if outlier_cols > 0:
            avg_outlier_rate = np.mean([
                info['outlier_rate'] for info in quality_report['outliers'].values()
            ])
            score -= avg_outlier_rate * 0.2

        # æ•°æ®ç±»å‹é—®é¢˜æ‰£åˆ†
        type_issues = len(quality_report['data_types']['type_issues'])
        score -= type_issues * 0.1

        return max(0, score)

    def _generate_quality_recommendations(self, quality_report: Dict) -> Tuple[List[str], List[str]]:
        """ç”Ÿæˆè´¨é‡ç›¸å…³çš„å»ºè®®"""
        issues = []
        recommendations = []

        # ç¼ºå¤±å€¼é—®é¢˜
        missing_rate = quality_report['missing_values']['overall']['missing_rate']
        if missing_rate > 0.05:
            issues.append(f"æ•°æ®ç¼ºå¤±ç‡è¾ƒé«˜({missing_rate:.1%})")
            recommendations.append("å»ºè®®ä½¿ç”¨é€‚å½“çš„å¡«å……ç­–ç•¥å¤„ç†ç¼ºå¤±å€¼")

        # é‡å¤å€¼é—®é¢˜
        duplicate_rate = quality_report['duplicates']['exact_duplicates']['rate']
        if duplicate_rate > 0.01:
            issues.append(f"å­˜åœ¨é‡å¤æ•°æ®({duplicate_rate:.1%})")
            recommendations.append("å»ºè®®æ£€æŸ¥å¹¶å¤„ç†é‡å¤æ•°æ®")

        # å¼‚å¸¸å€¼é—®é¢˜
        outlier_cols = quality_report['outliers']['total_outlier_columns']
        if outlier_cols > 0:
            issues.append(f"å‘ç°{outlier_cols}ä¸ªå˜é‡å­˜åœ¨å¼‚å¸¸å€¼")
            recommendations.append("å»ºè®®æ£€æŸ¥å¼‚å¸¸å€¼å¹¶å†³å®šå¤„ç†ç­–ç•¥")

        # æ•°æ®ç±»å‹é—®é¢˜
        type_issues = quality_report['data_types']['type_issues']
        if type_issues:
            issues.append("æ£€æµ‹åˆ°æ•°æ®ç±»å‹é—®é¢˜")
            recommendations.append("å»ºè®®ä¿®æ­£æ•°æ®ç±»å‹ä»¥è·å¾—æ›´å¥½çš„åˆ†æç»“æœ")

        return issues, recommendations

    def _interpret_correlation_strength(self, corr_value: float) -> str:
        """è§£é‡Šç›¸å…³æ€§å¼ºåº¦"""
        abs_corr = abs(corr_value)
        if abs_corr >= 0.9:
            return "æå¼º"
        elif abs_corr >= 0.7:
            return "å¼º"
        elif abs_corr >= 0.5:
            return "ä¸­ç­‰"
        elif abs_corr >= 0.3:
            return "å¼±"
        else:
            return "æå¼±"

    def export_results(self, output_path: str, format: str = 'json'):
        """
        å¯¼å‡ºåˆ†æç»“æœ

        Parameters:
        - output_path: è¾“å‡ºè·¯å¾„
        - format: è¾“å‡ºæ ¼å¼ ('json', 'csv')
        """
        if not self.results:
            print("âŒ æ²¡æœ‰å¯å¯¼å‡ºçš„åˆ†æç»“æœ")
            return

        if format == 'json':
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, ensure_ascii=False, indent=2, default=str)
            print(f"âœ… åˆ†æç»“æœå·²å¯¼å‡ºåˆ° {output_path}")

        elif format == 'csv':
            # å¯¼å‡ºä¸ºCSVæ ¼å¼ï¼ˆä¸»è¦ç”¨äºç»Ÿè®¡æ‘˜è¦ï¼‰
            if 'statistical_summary' in self.results:
                # æ•°å€¼ç»Ÿè®¡
                if self.results['statistical_summary']['numeric_summary']:
                    numeric_df = pd.DataFrame(self.results['statistical_summary']['numeric_summary']).T
                    numeric_df.to_csv(output_path.replace('.csv', '_numeric.csv'), encoding='utf-8-sig')

                # åˆ†ç±»ç»Ÿè®¡
                if self.results['statistical_summary']['categorical_summary']:
                    categorical_df = pd.DataFrame(self.results['statistical_summary']['categorical_summary']).T
                    categorical_df.to_csv(output_path.replace('.csv', '_categorical.csv'), encoding='utf-8-sig')

                print(f"âœ… ç»Ÿè®¡æ‘˜è¦å·²å¯¼å‡ºåˆ°CSVæ–‡ä»¶")
        else:
            raise ValueError("ä¸æ”¯æŒçš„è¾“å‡ºæ ¼å¼ï¼Œè¯·ä½¿ç”¨ 'json' æˆ– 'csv'")