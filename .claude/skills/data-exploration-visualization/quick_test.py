#!/usr/bin/env python3
"""
æ•°æ®æ¢ç´¢å¯è§†åŒ–æŠ€èƒ½å¿«é€Ÿæµ‹è¯•
å¿«é€ŸéªŒè¯æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os
import pandas as pd
import numpy as np
from pathlib import Path
import time
import traceback

# æ·»åŠ æŠ€èƒ½è·¯å¾„
skill_path = Path(__file__).parent
sys.path.append(str(skill_path / "scripts"))

def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    print("ğŸ“Š åˆ›å»ºæµ‹è¯•æ•°æ®...")

    np.random.seed(42)
    n_samples = 200

    data = {
        'id': range(1, n_samples + 1),
        'age': np.random.randint(18, 70, n_samples),
        'gender': np.random.choice(['Male', 'Female'], n_samples),
        'income': np.random.lognormal(10, 0.5, n_samples),
        'score': np.random.normal(75, 15, n_samples),
        'category': np.random.choice(['A', 'B', 'C'], n_samples, p=[0.5, 0.3, 0.2]),
        'target': np.random.choice([0, 1], n_samples, p=[0.7, 0.3])
    }

    df = pd.DataFrame(data)

    # æ·»åŠ ä¸€äº›ç¼ºå¤±å€¼
    missing_indices = np.random.choice(df.index, size=10, replace=False)
    df.loc[missing_indices, 'income'] = np.nan

    print(f"   âœ“ æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ: {df.shape}")
    return df

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…"""
    print("ğŸ” æ£€æŸ¥ä¾èµ–åŒ…...")

    required_packages = {
        'pandas': 'pandas',
        'numpy': 'numpy',
        'matplotlib': 'matplotlib',
        'seaborn': 'seaborn',
        'scipy': 'scipy',
        'sklearn': 'scikit-learn',
        'xgboost': 'xgboost',
        'plotly': 'plotly',
        'jinja2': 'jinja2'
    }

    optional_packages = {
        'shap': 'shap',
        'lightgbm': 'lightgbm',
        'imblearn': 'imbalanced-learn',
        'weasyprint': 'weasyprint'
    }

    missing_required = []
    missing_optional = []

    # æ£€æŸ¥å¿…éœ€åŒ…
    for module_name, package_name in required_packages.items():
        try:
            __import__(module_name)
        except ImportError:
            missing_required.append(package_name)

    # æ£€æŸ¥å¯é€‰åŒ…
    for module_name, package_name in optional_packages.items():
        try:
            __import__(module_name)
        except ImportError:
            missing_optional.append(package_name)

    if missing_required:
        print("   âŒ ç¼ºå°‘å¿…éœ€ä¾èµ–åŒ…:")
        for package in missing_required:
            print(f"      - {package}")
        print(f"\n   è¯·å®‰è£…: pip install {' '.join(missing_required)}")
        return False

    if missing_optional:
        print("   âš ï¸ ç¼ºå°‘å¯é€‰ä¾èµ–åŒ… (æŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨):")
        for package in missing_optional:
            print(f"      - {package}")

    print("   âœ“ æ‰€æœ‰å¿…è¦ä¾èµ–åŒ…å·²å®‰è£…")
    return True

def test_eda_analyzer():
    """æµ‹è¯•EDAåˆ†æå™¨"""
    print("\nğŸ” æµ‹è¯•EDAåˆ†æå™¨...")

    try:
        from eda_analyzer import EDAAnalyzer

        # åˆ›å»ºåˆ†æå™¨
        analyzer = EDAAnalyzer()

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        data = create_test_data()

        # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
        print("   æµ‹è¯•æ•°æ®è´¨é‡æ£€æŸ¥...")
        quality_report = analyzer.data_quality_check(data)
        assert quality_report is not None, "æ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥"
        print("     âœ“ æ•°æ®è´¨é‡æ£€æŸ¥")

        print("   æµ‹è¯•ç»Ÿè®¡æ‘˜è¦...")
        stats_summary = analyzer.generate_statistical_summary(data)
        assert stats_summary is not None, "ç»Ÿè®¡æ‘˜è¦ç”Ÿæˆå¤±è´¥"
        print("     âœ“ ç»Ÿè®¡æ‘˜è¦ç”Ÿæˆ")

        print("   æµ‹è¯•ç›¸å…³æ€§åˆ†æ...")
        corr_matrix = analyzer.correlation_analysis(data)
        assert corr_matrix is not None, "ç›¸å…³æ€§åˆ†æå¤±è´¥"
        print("     âœ“ ç›¸å…³æ€§åˆ†æ")

        print("   æµ‹è¯•è‡ªåŠ¨EDA...")
        eda_results = analyzer.auto_eda(data)
        assert eda_results is not None, "è‡ªåŠ¨EDAå¤±è´¥"
        print("     âœ“ è‡ªåŠ¨EDAåˆ†æ")

        print("   âœ“ EDAåˆ†æå™¨æµ‹è¯•é€šè¿‡")
        return True, eda_results

    except Exception as e:
        print(f"   âŒ EDAåˆ†æå™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return False, None

def test_visualizer():
    """æµ‹è¯•å¯è§†åŒ–å™¨"""
    print("\nğŸ“ˆ æµ‹è¯•å¯è§†åŒ–å™¨...")

    try:
        from visualizer import DataVisualizer

        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = DataVisualizer()

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        data = create_test_data()

        # æµ‹è¯•åˆ†å¸ƒå›¾
        print("   æµ‹è¯•åˆ†å¸ƒå›¾...")
        fig = visualizer.plot_distribution(data, 'age', interactive=False)
        assert fig is not None, "åˆ†å¸ƒå›¾ç”Ÿæˆå¤±è´¥"
        print("     âœ“ åˆ†å¸ƒå›¾ç”Ÿæˆ")

        # æµ‹è¯•ç›¸å…³æ€§çƒ­å›¾
        print("   æµ‹è¯•ç›¸å…³æ€§çƒ­å›¾...")
        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
        if len(numeric_cols) > 1:
            fig = visualizer.plot_correlation(data, numeric_cols, interactive=False)
            assert fig is not None, "ç›¸å…³æ€§çƒ­å›¾ç”Ÿæˆå¤±è´¥"
            print("     âœ“ ç›¸å…³æ€§çƒ­å›¾ç”Ÿæˆ")

        # æµ‹è¯•æ•£ç‚¹å›¾
        print("   æµ‹è¯•æ•£ç‚¹å›¾...")
        if len(numeric_cols) >= 2:
            fig = visualizer.plot_scatter(data, numeric_cols[0], numeric_cols[1], interactive=False)
            assert fig is not None, "æ•£ç‚¹å›¾ç”Ÿæˆå¤±è´¥"
            print("     âœ“ æ•£ç‚¹å›¾ç”Ÿæˆ")

        # æµ‹è¯•è‡ªåŠ¨å¯è§†åŒ–
        print("   æµ‹è¯•è‡ªåŠ¨å¯è§†åŒ–...")
        charts = visualizer.auto_visualize(
            data,
            target_col='target',
            save_charts=False
        )
        assert charts is not None, "è‡ªåŠ¨å¯è§†åŒ–å¤±è´¥"
        print("     âœ“ è‡ªåŠ¨å¯è§†åŒ–")

        print("   âœ“ å¯è§†åŒ–å™¨æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"   âŒ å¯è§†åŒ–å™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return False

def test_preprocessor():
    """æµ‹è¯•æ•°æ®é¢„å¤„ç†å™¨"""
    print("\nğŸ§¹ æµ‹è¯•æ•°æ®é¢„å¤„ç†å™¨...")

    try:
        from data_preprocessor import DataPreprocessor

        # åˆ›å»ºé¢„å¤„ç†å™¨
        preprocessor = DataPreprocessor({
            'missing_threshold': 0.5,
            'feature_selection': False,  # å…³é—­ç‰¹å¾é€‰æ‹©åŠ å¿«æµ‹è¯•
            'test_size': 0.2
        })

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        data = create_test_data()

        # æµ‹è¯•æ•°æ®è´¨é‡åˆ†æ
        print("   æµ‹è¯•æ•°æ®è´¨é‡åˆ†æ...")
        quality_report = preprocessor.analyze_data_quality(data)
        assert quality_report is not None, "æ•°æ®è´¨é‡åˆ†æå¤±è´¥"
        print("     âœ“ æ•°æ®è´¨é‡åˆ†æ")

        # æµ‹è¯•æ•°æ®æ¸…æ´—
        print("   æµ‹è¯•æ•°æ®æ¸…æ´—...")
        cleaned_data = preprocessor.clean_data(data)
        assert cleaned_data is not None, "æ•°æ®æ¸…æ´—å¤±è´¥"
        print("     âœ“ æ•°æ®æ¸…æ´—")

        # æµ‹è¯•ç±»å‹è½¬æ¢
        print("   æµ‹è¯•ç±»å‹è½¬æ¢...")
        transformed_data = preprocessor.transform_data_types(cleaned_data)
        assert transformed_data is not None, "ç±»å‹è½¬æ¢å¤±è´¥"
        print("     âœ“ ç±»å‹è½¬æ¢")

        # æµ‹è¯•è‡ªåŠ¨é¢„å¤„ç†
        print("   æµ‹è¯•è‡ªåŠ¨é¢„å¤„ç†...")
        results = preprocessor.auto_preprocess(data, target_col='target', save_report=False)
        assert results is not None, "è‡ªåŠ¨é¢„å¤„ç†å¤±è´¥"
        assert 'preprocessed_data' in results, "é¢„å¤„ç†æ•°æ®ç¼ºå¤±"
        print("     âœ“ è‡ªåŠ¨é¢„å¤„ç†")

        print("   âœ“ æ•°æ®é¢„å¤„ç†å™¨æµ‹è¯•é€šè¿‡")
        return True, results

    except Exception as e:
        print(f"   âŒ æ•°æ®é¢„å¤„ç†å™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return False, None

def test_modeling_evaluator():
    """æµ‹è¯•å»ºæ¨¡è¯„ä¼°å™¨"""
    print("\nğŸ¤– æµ‹è¯•å»ºæ¨¡è¯„ä¼°å™¨...")

    try:
        from modeling_evaluator import ModelingEvaluator

        # åˆ›å»ºå»ºæ¨¡å™¨
        modeler = ModelingEvaluator({
            'cv_folds': 3,  # å‡å°‘æŠ˜æ•°åŠ å¿«æµ‹è¯•
            'enable_hyperparameter_tuning': False,  # å…³é—­è°ƒåŠ å¿«æµ‹è¯•
            'n_iter_search': 5
        })

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        data = create_test_data()

        # æµ‹è¯•å•ä¸ªæ¨¡å‹è®­ç»ƒ
        print("   æµ‹è¯•å•ä¸ªæ¨¡å‹è®­ç»ƒ...")
        # å‡†å¤‡æ•°æ®
        X = data[['age', 'income', 'score']]
        y = data['target']

        # åˆ†å‰²æ•°æ®
        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        result = modeler.train_single_model(
            X_train, y_train, X_test, y_test,
            'logistic_regression', tune_hyperparameters=False
        )
        assert result is not None, "å•ä¸ªæ¨¡å‹è®­ç»ƒå¤±è´¥"
        print("     âœ“ å•ä¸ªæ¨¡å‹è®­ç»ƒ")

        # æµ‹è¯•å¤šæ¨¡å‹è®­ç»ƒ
        print("   æµ‹è¯•å¤šæ¨¡å‹è®­ç»ƒ...")
        results = modeler.train_multiple_models(
            X_train, y_train, X_test, y_test,
            model_names=['logistic_regression', 'random_forest']
        )
        assert results is not None, "å¤šæ¨¡å‹è®­ç»ƒå¤±è´¥"
        print("     âœ“ å¤šæ¨¡å‹è®­ç»ƒ")

        # æµ‹è¯•è‡ªåŠ¨å»ºæ¨¡
        print("   æµ‹è¯•è‡ªåŠ¨å»ºæ¨¡...")
        modeling_results = modeler.auto_modeling(
            data,
            target_col='target',
            model_names=['logistic_regression', 'random_forest']
        )
        assert modeling_results is not None, "è‡ªåŠ¨å»ºæ¨¡å¤±è´¥"
        print("     âœ“ è‡ªåŠ¨å»ºæ¨¡")

        print("   âœ“ å»ºæ¨¡è¯„ä¼°å™¨æµ‹è¯•é€šè¿‡")
        return True, modeling_results

    except Exception as e:
        print(f"   âŒ å»ºæ¨¡è¯„ä¼°å™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return False, None

def test_report_generator():
    """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨"""
    print("\nğŸ“‹ æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨...")

    try:
        from report_generator import ReportGenerator

        # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
        generator = ReportGenerator({
            'report_title': 'æµ‹è¯•æŠ¥å‘Š',
            'author': 'æµ‹è¯•ç”¨æˆ·'
        })

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        data = create_test_data()

        # æµ‹è¯•å¿«é€ŸæŠ¥å‘Šç”Ÿæˆ
        print("   æµ‹è¯•å¿«é€ŸæŠ¥å‘Šç”Ÿæˆ...")
        report_path = generator.generate_quick_report(
            data=data,
            target_col='target',
            output_path='test_quick_report.html'
        )
        assert report_path is not None, "å¿«é€ŸæŠ¥å‘Šç”Ÿæˆå¤±è´¥"
        assert os.path.exists(report_path), "æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨"
        print("     âœ“ å¿«é€ŸæŠ¥å‘Šç”Ÿæˆ")

        # æµ‹è¯•ç»¼åˆæŠ¥å‘Šç”Ÿæˆ
        print("   æµ‹è¯•ç»¼åˆæŠ¥å‘Šç”Ÿæˆ...")
        # åˆ›å»ºæ¨¡æ‹Ÿçš„EDAå’Œå»ºæ¨¡ç»“æœ
        eda_results = {
            'data_quality': {'overall_score': 85.5},
            'insights': ['æµ‹è¯•æ´å¯Ÿ1', 'æµ‹è¯•æ´å¯Ÿ2']
        }

        model_results = {
            'best_model': {
                'name': 'logistic_regression',
                'metrics': {'accuracy': 0.85, 'precision': 0.82, 'recall': 0.88, 'f1': 0.85}
            }
        }

        comprehensive_path = generator.generate_comprehensive_report(
            data=data,
            eda_results=eda_results,
            model_results=model_results,
            output_path='test_comprehensive_report.html',
            format='html'
        )
        assert comprehensive_path is not None, "ç»¼åˆæŠ¥å‘Šç”Ÿæˆå¤±è´¥"
        assert os.path.exists(comprehensive_path), "ç»¼åˆæŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨"
        print("     âœ“ ç»¼åˆæŠ¥å‘Šç”Ÿæˆ")

        print("   âœ“ æŠ¥å‘Šç”Ÿæˆå™¨æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"   âŒ æŠ¥å‘Šç”Ÿæˆå™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return False

def test_integration():
    """é›†æˆæµ‹è¯•"""
    print("\nğŸ”— æµ‹è¯•æ¨¡å—é›†æˆ...")

    try:
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        data = create_test_data()

        # 1. EDAåˆ†æ
        print("   1. æ‰§è¡ŒEDAåˆ†æ...")
        from eda_analyzer import EDAAnalyzer
        analyzer = EDAAnalyzer()
        eda_results = analyzer.auto_eda(data)

        # 2. æ•°æ®é¢„å¤„ç†
        print("   2. æ‰§è¡Œæ•°æ®é¢„å¤„ç†...")
        from data_preprocessor import DataPreprocessor
        preprocessor = DataPreprocessor()
        preprocessing_results = preprocessor.auto_preprocess(data, target_col='target')

        # 3. å¯è§†åŒ–
        print("   3. ç”Ÿæˆå¯è§†åŒ–...")
        from visualizer import DataVisualizer
        visualizer = DataVisualizer()
        charts = visualizer.auto_visualize(data, target_col='target', save_charts=False)

        # 4. å»ºæ¨¡
        print("   4. æ‰§è¡Œå»ºæ¨¡...")
        from modeling_evaluator import ModelingEvaluator
        modeler = ModelingEvaluator({'enable_hyperparameter_tuning': False})
        model_results = modeler.auto_modeling(data, target_col='target', model_names=['logistic_regression'])

        # 5. æŠ¥å‘Šç”Ÿæˆ
        print("   5. ç”ŸæˆæŠ¥å‘Š...")
        from report_generator import ReportGenerator
        generator = ReportGenerator()
        report_path = generator.generate_comprehensive_report(
            data=data,
            eda_results=eda_results,
            model_results=model_results,
            output_path='test_integration_report.html'
        )

        # éªŒè¯æ‰€æœ‰æ­¥éª¤éƒ½æˆåŠŸ
        assert eda_results is not None, "EDAåˆ†æå¤±è´¥"
        assert preprocessing_results is not None, "æ•°æ®é¢„å¤„ç†å¤±è´¥"
        assert charts is not None, "å¯è§†åŒ–å¤±è´¥"
        assert model_results is not None, "å»ºæ¨¡å¤±è´¥"
        assert report_path is not None and os.path.exists(report_path), "æŠ¥å‘Šç”Ÿæˆå¤±è´¥"

        print("   âœ“ é›†æˆæµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"   âŒ é›†æˆæµ‹è¯•å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return False

def test_performance():
    """æ€§èƒ½æµ‹è¯•"""
    print("\nâš¡ æ€§èƒ½æµ‹è¯•...")

    try:
        import time

        # åˆ›å»ºè¾ƒå¤§çš„æµ‹è¯•æ•°æ®
        print("   åˆ›å»ºæ€§èƒ½æµ‹è¯•æ•°æ®...")
        n_samples = 1000
        data = pd.DataFrame({
            'feature_1': np.random.randn(n_samples),
            'feature_2': np.random.randn(n_samples),
            'feature_3': np.random.randn(n_samples),
            'target': np.random.choice([0, 1], n_samples)
        })

        # æµ‹è¯•EDAæ€§èƒ½
        print("   æµ‹è¯•EDAæ€§èƒ½...")
        start_time = time.time()
        from eda_analyzer import EDAAnalyzer
        analyzer = EDAAnalyzer()
        analyzer.auto_eda(data)
        eda_time = time.time() - start_time
        print(f"     âœ“ EDAè€—æ—¶: {eda_time:.2f}ç§’")

        # æµ‹è¯•å»ºæ¨¡æ€§èƒ½
        print("   æµ‹è¯•å»ºæ¨¡æ€§èƒ½...")
        start_time = time.time()
        from modeling_evaluator import ModelingEvaluator
        modeler = ModelingEvaluator({'enable_hyperparameter_tuning': False})
        modeler.auto_modeling(data, target_col='target', model_names=['logistic_regression'])
        modeling_time = time.time() - start_time
        print(f"     âœ“ å»ºæ¨¡è€—æ—¶: {modeling_time:.2f}ç§’")

        # æ€§èƒ½æ–­è¨€
        assert eda_time < 30, f"EDAè€—æ—¶è¿‡é•¿: {eda_time}ç§’"
        assert modeling_time < 60, f"å»ºæ¨¡è€—æ—¶è¿‡é•¿: {modeling_time}ç§’"

        print("   âœ“ æ€§èƒ½æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"   âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def cleanup_test_files():
    """æ¸…ç†æµ‹è¯•æ–‡ä»¶"""
    print("\nğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶...")

    test_files = [
        'test_quick_report.html',
        'test_comprehensive_report.html',
        'test_integration_report.html',
        'quick_start_charts',
        'quick_start_output'
    ]

    cleaned = 0
    for file_path in test_files:
        path = Path(file_path)
        try:
            if path.is_file():
                path.unlink()
                cleaned += 1
            elif path.is_dir():
                import shutil
                shutil.rmtree(path)
                cleaned += 1
        except:
            pass

    print(f"   âœ“ æ¸…ç†äº† {cleaned} ä¸ªæµ‹è¯•æ–‡ä»¶")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª æ•°æ®æ¢ç´¢å¯è§†åŒ–æŠ€èƒ½ - å¿«é€Ÿæµ‹è¯•")
    print("=" * 60)

    start_time = time.time()

    # æµ‹è¯•ç»“æœè®°å½•
    test_results = {
        'dependencies': False,
        'eda_analyzer': False,
        'visualizer': False,
        'preprocessor': False,
        'modeling_evaluator': False,
        'report_generator': False,
        'integration': False,
        'performance': False
    }

    try:
        # 1. æ£€æŸ¥ä¾èµ–
        test_results['dependencies'] = check_dependencies()
        if not test_results['dependencies']:
            print("\nâŒ ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
            return

        # 2. æµ‹è¯•å„ä¸ªæ¨¡å—
        test_results['eda_analyzer'], eda_results = test_eda_analyzer()
        test_results['visualizer'] = test_visualizer()
        test_results['preprocessor'], preprocessing_results = test_preprocessor()
        test_results['modeling_evaluator'], modeling_results = test_modeling_evaluator()
        test_results['report_generator'] = test_report_generator()

        # 3. é›†æˆæµ‹è¯•
        test_results['integration'] = test_integration()

        # 4. æ€§èƒ½æµ‹è¯•
        test_results['performance'] = test_performance()

        # 5. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        total_time = time.time() - start_time

        print("\n" + "=" * 60)
        print("ğŸ“‹ æµ‹è¯•ç»“æœæ‘˜è¦")
        print("=" * 60)

        passed_tests = sum(test_results.values())
        total_tests = len(test_results)

        for test_name, result in test_results.items():
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"{test_name:20} : {status}")

        print(f"\næ€»ä½“ç»“æœ: {passed_tests}/{total_tests} æµ‹è¯•é€šè¿‡")
        print(f"æµ‹è¯•è€—æ—¶: {total_time:.2f}ç§’")

        if passed_tests == total_tests:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®æ¢ç´¢å¯è§†åŒ–æŠ€èƒ½å·²å°±ç»ªã€‚")
            print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
            print("   1. è¿è¡Œ examples/quick_start_example.py ä½“éªŒå®Œæ•´åŠŸèƒ½")
            print("   2. è¿è¡Œ examples/medical_data_analysis.py æŸ¥çœ‹åŒ»ç–—æ•°æ®ç¤ºä¾‹")
            print("   3. è¿è¡Œ examples/financial_data_analysis.py æŸ¥çœ‹é‡‘èæ•°æ®ç¤ºä¾‹")
        else:
            failed_tests = [name for name, result in test_results.items() if not result]
            print(f"\nâš ï¸  {len(failed_tests)} ä¸ªæµ‹è¯•å¤±è´¥: {', '.join(failed_tests)}")
            print("   è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜åé‡æ–°æµ‹è¯•ã€‚")

    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        traceback.print_exc()
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        cleanup_test_files()

if __name__ == "__main__":
    main()