#!/usr/bin/env python3
"""
å¿«é€Ÿå¼€å§‹ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•å¿«é€Ÿä½¿ç”¨æ•°æ®æ¢ç´¢å¯è§†åŒ–æŠ€èƒ½è¿›è¡Œæ•°æ®åˆ†æ
"""

import sys
import os
import pandas as pd
import numpy as np
from pathlib import Path

# æ·»åŠ æŠ€èƒ½è·¯å¾„
skill_path = Path(__file__).parent.parent
sys.path.append(str(skill_path / "scripts"))

def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®é›†"""
    print("ğŸ“Š åˆ›å»ºç¤ºä¾‹æ•°æ®é›†...")

    np.random.seed(42)
    n_samples = 800

    data = {
        'id': range(1, n_samples + 1),
        'age': np.random.randint(18, 75, n_samples),
        'gender': np.random.choice(['Male', 'Female'], n_samples, p=[0.52, 0.48]),
        'income': np.random.lognormal(10.5, 0.6, n_samples),
        'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'],
                                   n_samples, p=[0.3, 0.4, 0.25, 0.05]),
        'experience_years': np.random.exponential(8, n_samples),
        'satisfaction': np.random.randint(1, 6, n_samples),
        'performance_score': np.random.normal(75, 15, n_samples),
        'team_size': np.random.randint(2, 15, n_samples),
        'hours_per_week': np.random.normal(40, 5, n_samples),
        'projects_completed': np.random.poisson(8, n_samples),
        'training_hours': np.random.randint(0, 100, n_samples),
        'salary': np.random.lognormal(10.8, 0.4, n_samples),
    }

    # åˆ›å»ºç›¸å…³æ€§
    df = pd.DataFrame(data)

    # ç»éªŒä¸è–ªèµ„çš„ç›¸å…³æ€§
    df['salary'] = df['salary'] * (0.7 + 0.3 * df['experience_years'] / df['experience_years'].max())

    # ç»©æ•ˆä¸æ»¡æ„åº¦ç›¸å…³æ€§
    df['performance_score'] = df['performance_score'] + df['satisfaction'] * 3

    # é¡¹ç›®å®Œæˆæ•°é‡ä¸ç»éªŒç›¸å…³æ€§
    df['projects_completed'] = df['projects_completed'] + (df['experience_years'] / 2).astype(int)

    # åˆ›å»ºç›®æ ‡å˜é‡ï¼šé«˜ç»©æ•ˆå‘˜å·¥ï¼ˆç»©æ•ˆåˆ†æ•° > 85ï¼‰
    df['high_performer'] = (df['performance_score'] > 85).astype(int)

    # æ·»åŠ ä¸€äº›ç¼ºå¤±å€¼
    missing_indices = np.random.choice(df.index, size=int(0.05 * len(df)), replace=False)
    df.loc[missing_indices, 'training_hours'] = np.nan

    print(f"   âœ“ æ•°æ®é›†åˆ›å»ºå®Œæˆ: {df.shape}")
    print(f"   âœ“ é«˜ç»©æ•ˆå‘˜å·¥æ¯”ä¾‹: {df['high_performer'].mean():.2%}")

    return df

def quick_eda_example():
    """å¿«é€ŸEDAç¤ºä¾‹"""
    print("\nğŸ” å¿«é€ŸEDAåˆ†æç¤ºä¾‹...")

    # åˆ›å»ºæ•°æ®
    data = create_sample_data()

    try:
        from eda_analyzer import EDAAnalyzer

        # åˆå§‹åŒ–åˆ†æå™¨
        analyzer = EDAAnalyzer()

        # è‡ªåŠ¨åŒ–EDAåˆ†æ
        print("   æ‰§è¡Œè‡ªåŠ¨åŒ–EDA...")
        results = analyzer.auto_eda(data)

        print(f"   âœ“ EDAåˆ†æå®Œæˆ")
        print(f"   - æ•°æ®è´¨é‡åˆ†æ•°: {results.get('data_quality', {}).get('overall_score', 'N/A')}")
        print(f"   - å‘ç°çš„æ´å¯Ÿ: {len(results.get('insights', []))}")

        # æ˜¾ç¤ºå‰3ä¸ªæ´å¯Ÿ
        insights = results.get('insights', [])[:3]
        for i, insight in enumerate(insights, 1):
            print(f"   {i}. {insight}")

        return data, results

    except Exception as e:
        print(f"   âŒ EDAåˆ†æå¤±è´¥: {str(e)}")
        return data, None

def quick_visualization_example(data):
    """å¿«é€Ÿå¯è§†åŒ–ç¤ºä¾‹"""
    print("\nğŸ“ˆ å¿«é€Ÿå¯è§†åŒ–ç¤ºä¾‹...")

    try:
        from visualizer import DataVisualizer

        # åˆå§‹åŒ–å¯è§†åŒ–å™¨
        visualizer = DataVisualizer()

        # è‡ªåŠ¨ç”Ÿæˆå›¾è¡¨
        print("   è‡ªåŠ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        charts = visualizer.auto_visualize(
            data,
            target_col='high_performer',
            save_charts=True,
            output_dir='quick_start_charts'
        )

        print(f"   âœ“ ç”Ÿæˆäº† {charts['charts_generated']} ä¸ªå›¾è¡¨")

        # ç”Ÿæˆç‰¹å®šå›¾è¡¨
        print("   ç”Ÿæˆç‰¹å®šå›¾è¡¨...")

        # 1. å¹´é¾„åˆ†å¸ƒ
        age_chart = visualizer.plot_distribution(data, 'age', interactive=False)
        print("     âœ“ å¹´é¾„åˆ†å¸ƒå›¾")

        # 2. è–ªèµ„ vs ç»éªŒæ•£ç‚¹å›¾
        scatter_chart = visualizer.plot_scatter(
            data, 'experience_years', 'salary',
            color_col='high_performer',
            interactive=False
        )
        print("     âœ“ è–ªèµ„-ç»éªŒæ•£ç‚¹å›¾")

        # 3. æ•™è‚²æ°´å¹³åˆ†å¸ƒ
        education_chart = visualizer.plot_categorical(data, 'education', interactive=False)
        print("     âœ“ æ•™è‚²æ°´å¹³åˆ†å¸ƒå›¾")

        return charts

    except Exception as e:
        print(f"   âŒ å¯è§†åŒ–å¤±è´¥: {str(e)}")
        return None

def quick_preprocessing_example(data):
    """å¿«é€Ÿæ•°æ®é¢„å¤„ç†ç¤ºä¾‹"""
    print("\nğŸ§¹ å¿«é€Ÿæ•°æ®é¢„å¤„ç†ç¤ºä¾‹...")

    try:
        from data_preprocessor import DataPreprocessor

        # åˆå§‹åŒ–é¢„å¤„ç†å™¨
        preprocessor = DataPreprocessor({
            'missing_threshold': 0.3,
            'feature_selection': False,  # å…³é—­ç‰¹å¾é€‰æ‹©ä»¥åŠ å¿«æ¼”ç¤º
            'test_size': 0.2
        })

        # è‡ªåŠ¨é¢„å¤„ç†
        print("   æ‰§è¡Œè‡ªåŠ¨é¢„å¤„ç†...")
        results = preprocessor.auto_preprocess(
            data,
            target_col='high_performer',
            save_report=True
        )

        print(f"   âœ“ é¢„å¤„ç†å®Œæˆ")
        print(f"   - åŸå§‹æ•°æ®: {results['original_data'].shape}")
        print(f"   - é¢„å¤„ç†å: {results['preprocessed_data'].shape}")
        print(f"   - é¢„å¤„ç†æ­¥éª¤: {len(results['preprocessing_steps'])}")

        # æ˜¾ç¤ºé¢„å¤„ç†æ­¥éª¤
        for step in results['preprocessing_steps'][:5]:
            print(f"     - {step}")

        return results

    except Exception as e:
        print(f"   âŒ é¢„å¤„ç†å¤±è´¥: {str(e)}")
        return None

def quick_modeling_example(data):
    """å¿«é€Ÿå»ºæ¨¡ç¤ºä¾‹"""
    print("\nğŸ¤– å¿«é€Ÿå»ºæ¨¡ç¤ºä¾‹...")

    try:
        from modeling_evaluator import ModelingEvaluator

        # åˆå§‹åŒ–å»ºæ¨¡å™¨
        modeler = ModelingEvaluator({
            'cv_folds': 3,  # å‡å°‘æŠ˜æ•°åŠ å¿«æ¼”ç¤º
            'enable_hyperparameter_tuning': False,  # å…³é—­è°ƒå‚åŠ å¿«æ¼”ç¤º
            'n_iter_search': 5
        })

        # è‡ªåŠ¨å»ºæ¨¡
        print("   æ‰§è¡Œè‡ªåŠ¨å»ºæ¨¡...")
        results = modeler.auto_modeling(
            data,
            target_col='high_performer',
            model_names=['logistic_regression', 'random_forest']  # ä½¿ç”¨è¾ƒå°‘çš„æ¨¡å‹
        )

        print(f"   âœ“ å»ºæ¨¡å®Œæˆ")
        print(f"   - è®­ç»ƒæ¨¡å‹æ•°: {len(results['model_results'])}")
        print(f"   - æœ€ä½³æ¨¡å‹: {results['best_model']['name']}")

        best_metrics = results['best_model']['metrics']
        print(f"   - æœ€ä½³å‡†ç¡®ç‡: {best_metrics.get('accuracy', 0):.3f}")

        return results

    except Exception as e:
        print(f"   âŒ å»ºæ¨¡å¤±è´¥: {str(e)}")
        return None

def quick_report_example(data, eda_results=None, model_results=None):
    """å¿«é€ŸæŠ¥å‘Šç”Ÿæˆç¤ºä¾‹"""
    print("\nğŸ“‹ å¿«é€ŸæŠ¥å‘Šç”Ÿæˆç¤ºä¾‹...")

    try:
        from report_generator import ReportGenerator

        # åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        generator = ReportGenerator({
            'report_title': 'å‘˜å·¥ç»©æ•ˆåˆ†ææŠ¥å‘Š',
            'author': 'æ•°æ®åˆ†æåŠ©æ‰‹',
            'include_toc': True,
            'include_summary': True
        })

        # ç”Ÿæˆå¿«é€ŸæŠ¥å‘Š
        print("   ç”Ÿæˆå¿«é€Ÿåˆ†ææŠ¥å‘Š...")
        report_path = generator.generate_quick_report(
            data=data,
            target_col='high_performer',
            output_path='quick_analysis_report.html'
        )

        print(f"   âœ“ æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

        # å¦‚æœæœ‰å®Œæ•´ç»“æœï¼Œç”Ÿæˆç»¼åˆæŠ¥å‘Š
        if eda_results or model_results:
            print("   ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š...")
            comprehensive_path = generator.generate_comprehensive_report(
                data=data,
                eda_results=eda_results,
                model_results=model_results,
                output_path='comprehensive_analysis_report.html',
                format='html'
            )

            print(f"   âœ“ ç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆ: {comprehensive_path}")

        return report_path

    except Exception as e:
        print(f"   âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
        return None

def run_complete_pipeline():
    """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
    print("ğŸš€ è¿è¡Œå®Œæ•´æ•°æ®åˆ†ææµç¨‹...")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path('quick_start_output')
    output_dir.mkdir(exist_ok=True)

    # 1. æ•°æ®åˆ›å»ºå’ŒEDA
    data, eda_results = quick_eda_example()

    # 2. å¯è§†åŒ–
    charts = quick_visualization_example(data)

    # 3. é¢„å¤„ç†
    preprocessing_results = quick_preprocessing_example(data)

    # 4. å»ºæ¨¡
    model_results = quick_modeling_example(data)

    # 5. æŠ¥å‘Šç”Ÿæˆ
    report_path = quick_report_example(data, eda_results, model_results)

    # 6. æ€»ç»“
    print("\nğŸ‰ å¿«é€Ÿå¼€å§‹ç¤ºä¾‹å®Œæˆï¼")

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š æ•°æ®æ‘˜è¦:")
    print(f"   - æ ·æœ¬æ•°é‡: {len(data):,}")
    print(f"   - ç‰¹å¾æ•°é‡: {len(data.columns)}")
    print(f"   - é«˜ç»©æ•ˆå‘˜å·¥: {data['high_performer'].sum()} ({data['high_performer'].mean():.1%})")

    print(f"\nğŸ“ˆ åˆ†æç»“æœ:")
    if eda_results:
        quality_score = eda_results.get('data_quality', {}).get('overall_score', 0)
        print(f"   - æ•°æ®è´¨é‡åˆ†æ•°: {quality_score:.1f}")

    if model_results:
        best_accuracy = model_results['best_model']['metrics'].get('accuracy', 0)
        print(f"   - æœ€ä½³æ¨¡å‹å‡†ç¡®ç‡: {best_accuracy:.3f}")

    if charts:
        print(f"   - ç”Ÿæˆå›¾è¡¨æ•°: {charts['charts_generated']}")

    # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶
    print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    for file_path in Path('.').glob('quick_start_*'):
        if file_path.is_file():
            print(f"   ğŸ“„ {file_path}")

    if report_path:
        print(f"\nğŸ“‹ åˆ†ææŠ¥å‘Š: {report_path}")
        print("   è¯·åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€HTMLæ–‡ä»¶æŸ¥çœ‹å®Œæ•´æŠ¥å‘Šã€‚")

def demonstrate_specific_features():
    """æ¼”ç¤ºç‰¹å®šåŠŸèƒ½"""
    print("\nğŸ”§ æ¼”ç¤ºç‰¹å®šåŠŸèƒ½...")

    try:
        # 1. æ•°æ®è´¨é‡æ£€æŸ¥
        from eda_analyzer import EDAAnalyzer
        data = create_sample_data()
        analyzer = EDAAnalyzer()

        print("   1. æ•°æ®è´¨é‡æ£€æŸ¥...")
        quality_report = analyzer.data_quality_check(data)
        print(f"      - æ•°æ®è¡Œæ•°: {quality_report['total_rows']}")
        print(f"      - æ•°æ®åˆ—æ•°: {quality_report['total_columns']}")
        print(f"      - ç¼ºå¤±å€¼: {quality_report['missing_values']}")

        # 2. å¼‚å¸¸å€¼æ£€æµ‹
        print("\n   2. å¼‚å¸¸å€¼æ£€æµ‹...")
        outliers = analyzer.detect_outliers(data, 'salary')
        print(f"      - è–ªèµ„å¼‚å¸¸å€¼: {outliers.sum()} ä¸ª")

        # 3. ç›¸å…³æ€§åˆ†æ
        print("\n   3. ç›¸å…³æ€§åˆ†æ...")
        correlation_matrix = analyzer.correlation_analysis(data)
        strong_corr = []
        for i in range(len(correlation_matrix.columns)):
            for j in range(i+1, len(correlation_matrix.columns)):
                corr_val = correlation_matrix.iloc[i, j]
                if abs(corr_val) > 0.5:
                    strong_corr.append(
                        f"{correlation_matrix.columns[i]} - {correlation_matrix.columns[j]}: {corr_val:.2f}"
                    )
        print(f"      - å¼ºç›¸å…³æ€§ç‰¹å¾å¯¹: {len(strong_corr)}")
        for corr in strong_corr[:3]:
            print(f"        â€¢ {corr}")

        # 4. ç‰¹å¾é‡è¦æ€§
        if model_results := quick_modeling_example(data):
            print("\n   4. ç‰¹å¾é‡è¦æ€§åˆ†æ...")
            if 'feature_importance' in model_results:
                top_features = list(model_results['feature_importance'].keys())[:5]
                print(f"      - æœ€é‡è¦çš„5ä¸ªç‰¹å¾:")
                for i, feature in enumerate(top_features, 1):
                    print(f"        {i}. {feature}")

    except Exception as e:
        print(f"   âŒ åŠŸèƒ½æ¼”ç¤ºå¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ æ•°æ®æ¢ç´¢å¯è§†åŒ–æŠ€èƒ½ - å¿«é€Ÿå¼€å§‹ç¤ºä¾‹")
    print("=" * 60)

    try:
        # æ£€æŸ¥ä¾èµ–
        print("ğŸ” æ£€æŸ¥ä¾èµ–åŒ…...")
        required_packages = ['pandas', 'numpy', 'matplotlib', 'seaborn', 'scikit-learn']
        missing_packages = []

        for package in required_packages:
            try:
                __import__(package)
            except ImportError:
                missing_packages.append(package)

        if missing_packages:
            print(f"   âŒ ç¼ºå°‘ä¾èµ–åŒ…: {', '.join(missing_packages)}")
            print(f"   è¯·å®‰è£…: pip install {' '.join(missing_packages)}")
            return

        print("   âœ“ æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…")

        # è¿è¡Œå®Œæ•´æµç¨‹
        run_complete_pipeline()

        # æ¼”ç¤ºç‰¹å®šåŠŸèƒ½
        demonstrate_specific_features()

        # ä½¿ç”¨å»ºè®®
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("   1. å°†æ‚¨è‡ªå·±çš„CSVæ•°æ®æ›¿æ¢ç¤ºä¾‹æ•°æ®")
        print("   2. è°ƒæ•´é…ç½®å‚æ•°ä»¥é€‚åº”æ‚¨çš„éœ€æ±‚")
        print("   3. æŸ¥çœ‹ç”Ÿæˆçš„HTMLæŠ¥å‘Šè·å–è¯¦ç»†åˆ†æç»“æœ")
        print("   4. å°è¯•ä¸åŒçš„æ¨¡å‹å’Œé¢„å¤„ç†æ–¹æ³•")
        print("   5. ä½¿ç”¨å›¾è¡¨åŠŸèƒ½åˆ›å»ºè‡ªå®šä¹‰å¯è§†åŒ–")

        print("\nğŸ“š æ›´å¤šç¤ºä¾‹:")
        print("   - medical_data_analysis.py: åŒ»ç–—æ•°æ®åˆ†æç¤ºä¾‹")
        print("   - financial_data_analysis.py: é‡‘èæ•°æ®åˆ†æç¤ºä¾‹")

    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()