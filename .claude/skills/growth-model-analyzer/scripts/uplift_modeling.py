"""
Upliftå»ºæ¨¡æ¨¡å— - å¢é•¿æ¨¡å‹æ ¸å¿ƒæœºå™¨å­¦ä¹ ç»„ä»¶

æä¾›å…ˆè¿›çš„Upliftå»ºæ¨¡åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- XGBoost Upliftå»ºæ¨¡
- å¢é‡åˆ†æ•°è®¡ç®—
- Qiniæ›²çº¿åˆ†æ
- æ¨¡å‹æ•ˆæœè¯„ä¼°
- ç­–ç•¥æ•ˆæœé¢„æµ‹
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Union
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import warnings
warnings.filterwarnings('ignore')


class UpliftModeler:
    """Upliftå»ºæ¨¡å™¨ - å¢é•¿æ¨¡å‹æœºå™¨å­¦ä¹ æ ¸å¿ƒ"""

    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–Upliftå»ºæ¨¡å™¨

        Parameters:
        - config: é…ç½®å‚æ•°å­—å…¸
        """
        self.config = config or {}
        self.models = {}
        self.scalers = {}
        self.feature_names = []
        self.results = {}

    def prepare_uplift_data(self,
                           data: pd.DataFrame,
                           treatment_col: str = 'è£‚å˜ç±»å‹',
                           outcome_col: str = 'æ˜¯å¦è½¬åŒ–',
                           control_value: str = 'æ— è£‚å˜é¡µé¢',
                           treatment_value: str = None) -> pd.DataFrame:
        """
        å‡†å¤‡Upliftå»ºæ¨¡æ•°æ®

        Parameters:
        - data: åŸå§‹æ•°æ®
        - treatment_col: å¤„ç†ç»„åˆ—å
        - outcome_col: ç»“æœåˆ—å
        - control_value: å¯¹ç…§ç»„å€¼
        - treatment_value: å¤„ç†ç»„å€¼ (å¦‚æœä¸ºNoneï¼Œä½¿ç”¨æ‰€æœ‰éå¯¹ç…§ç»„)

        Returns:
        - å‡†å¤‡å¥½çš„Upliftæ•°æ®
        """
        # ç­›é€‰ç›¸å…³æ•°æ®
        if treatment_value:
            uplift_data = data[data[treatment_col].isin([control_value, treatment_value])].copy()
        else:
            # ä½¿ç”¨æ‰€æœ‰éå¯¹ç…§ç»„ä½œä¸ºå¤„ç†ç»„
            uplift_data = data[data[treatment_col].isin([control_value]) | ~data[treatment_col].isin([control_value])].copy()

        # æ„é€ Upliftæ ‡ç­¾
        def create_uplift_label(row):
            if row[treatment_col] == control_value:
                # å¯¹ç…§ç»„
                return 2 if row[outcome_col] == 1 else 3  # CR, CN
            else:
                # å¤„ç†ç»„
                return 0 if row[outcome_col] == 1 else 1  # TR, TN

        uplift_data['uplift_label'] = uplift_data.apply(create_uplift_label, axis=1)

        print(f"âœ… Upliftæ•°æ®å‡†å¤‡å®Œæˆ: {len(uplift_data)} æ¡è®°å½•")
        print(f"   - å¤„ç†ç»„: {len(uplift_data[uplift_data[treatment_col] != control_value])} æ¡")
        print(f"   - å¯¹ç…§ç»„: {len(uplift_data[uplift_data[treatment_col] == control_value])} æ¡")

        return uplift_data

    def build_uplift_model(self,
                          data: pd.DataFrame,
                          feature_cols: List[str] = None,
                          treatment_col: str = 'è£‚å˜_type',
                          outcome_col: str = 'æ˜¯å¦è½¬åŒ–',
                          model_type: str = 'xgboost',
                          test_size: float = 0.2,
                          random_state: int = 42) -> Dict:
        """
        æ„å»ºUpliftæ¨¡å‹

        Parameters:
        - data: å‡†å¤‡å¥½çš„Upliftæ•°æ®
        - feature_cols: ç‰¹å¾åˆ—ååˆ—è¡¨
        - treatment_col: å¤„ç†ç»„ç¼–ç åˆ—å
        - outcome_col: ç»“æœåˆ—å
        - model_type: æ¨¡å‹ç±»å‹ ('xgboost', 'lightgbm')
        - test_size: æµ‹è¯•é›†æ¯”ä¾‹
        - random_state: éšæœºç§å­

        Returns:
        - æ¨¡å‹è®­ç»ƒç»“æœ
        """
        # ç¡®å®šç‰¹å¾åˆ—
        if feature_cols is None:
            # æ’é™¤æ ‡è¯†ç¬¦å’Œç»“æœåˆ—
            exclude_cols = [treatment_col, outcome_col, 'uplift_label', 'ç”¨æˆ·ç ', 'è£‚å˜ç±»å‹']
            feature_cols = [col for col in data.columns if col not in exclude_cols]

        self.feature_names = feature_cols

        # å‡†å¤‡è®­ç»ƒæ•°æ®
        X = data[feature_cols]
        y = data['uplift_label']

        # å¤„ç†åˆ†ç±»å˜é‡
        X = pd.get_dummies(X, drop_first=True)

        # åˆ†å‰²è®­ç»ƒæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state, stratify=y
        )

        # æ ‡å‡†åŒ–ç‰¹å¾
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # è®­ç»ƒæ¨¡å‹
        if model_type == 'xgboost':
            model = xgb.XGBClassifier(
                objective='multi:softprob',
                num_class=4,
                random_state=random_state,
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")

        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ{model_type.upper()} Upliftæ¨¡å‹...")
        model.fit(X_train_scaled, y_train)
        print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")

        # ä¿å­˜æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨
        self.models['uplift'] = model
        self.scalers['uplift'] = scaler

        # æ¨¡å‹è¯„ä¼°
        y_pred = model.predict(X_test_scaled)
        y_prob = model.predict_proba(X_test_scaled)

        classification_rep = classification_report(y_test, y_pred, output_dict=True)
        conf_matrix = confusion_matrix(y_test, y_pred)

        results = {
            'model': model,
            'scaler': scaler,
            'feature_names': list(X.columns),
            'X_train': X_train,
            'X_test': X_test,
            'y_train': y_train,
            'y_test': y_test,
            'y_pred': y_pred,
            'y_prob': y_prob,
            'classification_report': classification_rep,
            'confusion_matrix': conf_matrix.tolist(),
            'accuracy': np.mean(y_pred == y_test)
        }

        self.results['uplift_model'] = results
        return results

    def calculate_uplift_scores(self,
                              data: pd.DataFrame,
                              treatment_col: str = 'è£‚å˜ç±»å‹',
                              outcome_col: str = 'æ˜¯å¦è½¬åŒ–',
                              model_name: str = 'uplift') -> pd.DataFrame:
        """
        è®¡ç®—å¢é‡åˆ†æ•°

        Parameters:
        - data: æµ‹è¯•æ•°æ®
        - treatment_col: å¤„ç†ç»„åˆ—å
        - outcome_col: ç»“æœåˆ—å
        - model_name: æ¨¡å‹åç§°

        Returns:
        - åŒ…å«å¢é‡åˆ†æ•°çš„DataFrame
        """
        if model_name not in self.models:
            raise ValueError(f"æ¨¡å‹ {model_name} ä¸å­˜åœ¨ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")

        model = self.models[model_name]
        scaler = self.scalers[model_name]

        # å‡†å¤‡ç‰¹å¾æ•°æ®
        feature_data = data[self.feature_names]
        feature_data = pd.get_dummies(feature_data, drop_first=True)

        # ç¡®ä¿ç‰¹å¾åˆ—åŒ¹é…
        for col in self.feature_names:
            if col not in feature_data.columns:
                feature_data[col] = 0

        feature_data = feature_data[self.feature_names]

        # æ ‡å‡†åŒ–
        X_scaled = scaler.transform(feature_data)

        # é¢„æµ‹æ¦‚ç‡
        probas = model.predict_proba(X_scaled)

        # P_TR: Treatment Responders (å¤„ç†ç»„å“åº”è€…)
        # P_TN: Treatment Non-responders (å¤„ç†ç»„éå“åº”è€…)
        # P_CR: Control Responders (å¯¹ç…§ç»„å“åº”è€…)
        # P_CN: Control Non-responders (å¯¹ç…§ç»„éå“åº”è€…)
        P_TR, P_TN, P_CR, P_CN = probas[:, 0], probas[:, 1], probas[:, 2], probas[:, 3]

        # è®¡ç®—å¢é‡åˆ†æ•° (Uplift Score)
        # å¢é‡åˆ†æ•° = (P_TR - P_TN) + (P_CN - P_CR)
        epsilon = 1e-15  # é¿å…é™¤é›¶
        uplift_score = (P_TR - P_TN) / (P_TR + P_TN + epsilon) + (P_CN - P_CR) / (P_CN + P_CR + epsilon)

        # æ„å»ºç»“æœDataFrame
        results_df = data[['ç”¨æˆ·ç ', treatment_col, outcome_col]].copy()
        results_df['P_TR'] = P_TR
        results_df['P_TN'] = P_TN
        results_df['P_CR'] = P_CR
        results_df['P_CN'] = P_CN
        results_df['uplift_score'] = uplift_score

        print(f"âœ… å¢é‡åˆ†æ•°è®¡ç®—å®Œæˆ")
        print(f"   - å¹³å‡å¢é‡åˆ†æ•°: {uplift_score.mean():.4f}")
        print(f"   - æ ‡å‡†å·®: {uplift_score.std():.4f}")

        return results_df

    def analyze_qini_curve(self,
                          uplift_scores_df: pd.DataFrame,
                          treatment_col: str = 'è£‚å˜ç±»å‹',
                          outcome_col: str = 'æ˜¯å¦è½¬åŒ–',
                          control_value: str = 'æ— è£‚å˜é¡µé¢') -> Dict:
        """
        åˆ†æQiniæ›²çº¿

        Parameters:
        - uplift_scores_df: åŒ…å«å¢é‡åˆ†æ•°çš„DataFrame
        - treatment_col: å¤„ç†ç»„åˆ—å
        - outcome_col: ç»“æœåˆ—å
        - control_value: å¯¹ç…§ç»„å€¼

        Returns:
        - Qiniæ›²çº¿åˆ†æç»“æœ
        """
        # æŒ‰å¢é‡åˆ†æ•°é™åºæ’åº
        df_sorted = uplift_scores_df.sort_values('uplift_score', ascending=False).reset_index(drop=True)
        df_sorted['rank'] = df_sorted.index + 1
        df_sorted['fraction'] = df_sorted['rank'] / len(df_sorted)

        # è®¡ç®—TRå’ŒCRæ€»æ•°
        tr_total = len(df_sorted[(df_sorted[treatment_col] != control_value) & (df_sorted[outcome_col] == 1)])
        cr_total = len(df_sorted[(df_sorted[treatment_col] == control_value) & (df_sorted[outcome_col] == 1)])

        if tr_total == 0 or cr_total == 0:
            raise ValueError("æ•°æ®ä¸­ç¼ºå°‘è¶³å¤Ÿçš„è½¬åŒ–æ ·æœ¬")

        # è®¡ç®—ç´¯ç§¯æŒ‡æ ‡
        df_sorted['is_tr'] = ((df_sorted[treatment_col] != control_value) & (df_sorted[outcome_col] == 1)).astype(int)
        df_sorted['is_cr'] = ((df_sorted[treatment_col] == control_value) & (df_sorted[outcome_col] == 1)).astype(int)

        df_sorted['cum_tr'] = df_sorted['is_tr'].cumsum()
        df_sorted['cum_cr'] = df_sorted['is_cr'].cumsum()

        # è®¡ç®—Qiniå¢ç›Š
        df_sorted['qini_gain'] = (df_sorted['cum_tr'] / tr_total) - (df_sorted['cum_cr'] / cr_total)

        # è®¡ç®—éšæœºæ¨¡å‹çš„Qiniå¢ç›Š
        df_sorted['random_qini'] = df_sorted['fraction'] * df_sorted['qini_gain'].iloc[-1]

        # è®¡ç®—AUC
        qini_auc = np.trapz(df_sorted['qini_gain'], df_sorted['fraction'])
        random_auc = np.trapz(df_sorted['random_qini'], df_sorted['fraction'])
        auqc = qini_auc - random_auc  # Adjusted Uplift Qini Curve

        results = {
            'qini_data': df_sorted[['fraction', 'qini_gain', 'random_qini']].to_dict(),
            'qini_auc': qini_auc,
            'random_auc': random_auc,
            'auqc': auqc,
            'total_tr': tr_total,
            'total_cr': cr_total,
            'model_performance': self._evaluate_qini_performance(auqc)
        }

        print(f"âœ… Qiniæ›²çº¿åˆ†æå®Œæˆ")
        print(f"   - Qini AUC: {qini_auc:.4f}")
        print(f"   - Random AUC: {random_auc:.4f}")
        print(f"   - AUQC: {auqc:.4f}")
        print(f"   - æ¨¡å‹è¡¨ç°: {results['model_performance']}")

        return results

    def uplift_segmentation(self,
                           uplift_scores_df: pd.DataFrame,
                           n_segments: int = 5) -> pd.DataFrame:
        """
        åŸºäºå¢é‡åˆ†æ•°çš„ç”¨æˆ·åˆ†ç¾¤

        Parameters:
        - uplift_scores_df: åŒ…å«å¢é‡åˆ†æ•°çš„DataFrame
        - n_segments: åˆ†ç¾¤æ•°é‡

        Returns:
        - åŒ…å«åˆ†ç¾¤ç»“æœçš„DataFrame
        """
        # æŒ‰å¢é‡åˆ†æ•°åˆ†ç¾¤
        df_segmented = uplift_scores_df.copy()

        # åˆ›å»ºåˆ†ç¾¤æ ‡ç­¾
        quantiles = np.linspace(0, 1, n_segments + 1)
        cutoffs = df_segmented['uplift_score'].quantile(quantiles).tolist()

        segment_labels = []
        for i in range(n_segments):
            if i == 0:
                label = f"Bottom {100//n_segments}%"
            elif i == n_segments - 1:
                label = f"Top {100//n_segments}%"
            else:
                label = f"Q{i+1}"
            segment_labels.append(label)

        # åˆ†é…åˆ†ç¾¤
        df_segmented['uplift_segment'] = pd.cut(
            df_segmented['uplift_score'],
            bins=cutoffs,
            labels=segment_labels,
            include_lowest=True
        )

        # è®¡ç®—åˆ†ç¾¤ç»Ÿè®¡
        segment_stats = df_segmented.groupby('uplift_segment').agg({
            'uplift_score': ['count', 'mean', 'std'],
            'ç”¨æˆ·ç ': 'nunique'
        }).round(4)

        segment_stats.columns = ['ç”¨æˆ·æ•°', 'å¹³å‡å¢é‡åˆ†æ•°', 'æ ‡å‡†å·®', 'ç‹¬ç«‹ç”¨æˆ·æ•°']

        print(f"âœ… ç”¨æˆ·åˆ†ç¾¤å®Œæˆ")
        for segment, stats in segment_stats.iterrows():
            print(f"   - {segment}: {stats['ç”¨æˆ·æ•°']} ç”¨æˆ·, å¹³å‡å¢é‡åˆ†æ•° {stats['å¹³å‡å¢é‡åˆ†æ•°']:.4f}")

        return df_segmented

    def save_model(self, model_name: str = 'uplift', filepath: str = None) -> str:
        """
        ä¿å­˜æ¨¡å‹

        Parameters:
        - model_name: æ¨¡å‹åç§°
        - filepath: ä¿å­˜è·¯å¾„

        Returns:
        - ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if model_name not in self.models:
            raise ValueError(f"æ¨¡å‹ {model_name} ä¸å­˜åœ¨")

        if filepath is None:
            filepath = f'uplift_model_{model_name}.pkl'

        # ä¿å­˜æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨
        model_data = {
            'model': self.models[model_name],
            'scaler': self.scalers[model_name],
            'feature_names': self.feature_names,
            'config': self.config
        }

        joblib.dump(model_data, filepath)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {filepath}")

        return filepath

    def load_model(self, filepath: str, model_name: str = 'uplift') -> Dict:
        """
        åŠ è½½æ¨¡å‹

        Parameters:
        - filepath: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        - model_name: æ¨¡å‹åç§°

        Returns:
        - åŠ è½½çš„æ¨¡å‹æ•°æ®
        """
        model_data = joblib.load(filepath)

        self.models[model_name] = model_data['model']
        self.scalers[model_name] = model_data['scaler']
        self.feature_names = model_data['feature_names']
        self.config = model_data.get('config', {})

        print(f"âœ… æ¨¡å‹å·²ä» {filepath} åŠ è½½")
        return model_data

    def plot_qini_curve(self, qini_results: Dict, title: str = "Qini Curve Analysis"):
        """
        ç»˜åˆ¶Qiniæ›²çº¿

        Parameters:
        - qini_results: Qiniæ›²çº¿åˆ†æç»“æœ
        - title: å›¾è¡¨æ ‡é¢˜
        """
        plt.figure(figsize=(10, 6))

        qini_data = qini_results['qini_data']
        fractions = qini_data['fraction']
        qini_gains = qini_data['qini_gain']
        random_qini = qini_data['random_qini']

        plt.plot(fractions, qini_gains, label='Uplift Model', linewidth=2, color='blue')
        plt.plot(fractions, random_qini, label='Random', linewidth=2, color='gray', linestyle='--')

        # å¡«å……åŒºåŸŸ
        plt.fill_between(fractions, qini_gains, random_qini, alpha=0.3, color='lightblue')

        plt.xlabel('Population Fraction', fontsize=12)
        plt.ylabel('Cumulative Uplift', fontsize=12)
        plt.title(f'{title}\nAUQC: {qini_results["auqc"]:.4f}', fontsize=14)
        plt.legend(fontsize=11)
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        return plt.gcf()

    def _evaluate_qini_performance(self, auqc: float) -> str:
        """è¯„ä¼°Qiniæ›²çº¿è¡¨ç°"""
        if auqc > 0.1:
            return "ä¼˜ç§€"
        elif auqc > 0.05:
            return "è‰¯å¥½"
        elif auqc > 0:
            return "ä¸€èˆ¬"
        else:
            return "è¾ƒå·®"

    def generate_uplift_report(self, uplift_scores_df: pd.DataFrame) -> Dict:
        """
        ç”ŸæˆUpliftåˆ†ææŠ¥å‘Š

        Parameters:
        - uplift_scores_df: åŒ…å«å¢é‡åˆ†æ•°çš„DataFrame

        Returns:
        - åˆ†ææŠ¥å‘Š
        """
        report = {
            "summary": {},
            "insights": [],
            "recommendations": []
        }

        # åŸºç¡€ç»Ÿè®¡
        report["summary"] = {
            "total_users": len(uplift_scores_df),
            "avg_uplift_score": uplift_scores_df['uplift_score'].mean(),
            "uplift_score_std": uplift_scores_df['uplift_score'].std(),
            "positive_uplift_ratio": (uplift_scores_df['uplift_score'] > 0).mean()
        }

        # ç”Ÿæˆæ´å¯Ÿ
        positive_ratio = report["summary"]["positive_uplift_ratio"]
        if positive_ratio > 0.7:
            report["insights"].append("å¤§éƒ¨åˆ†ç”¨æˆ·å¯¹ç­–ç•¥æœ‰ç§¯æå“åº”")
            report["recommendations"].append("å»ºè®®æ‰©å¤§ç­–ç•¥è¦†ç›–èŒƒå›´")
        elif positive_ratio > 0.4:
            report["insights"].append("çº¦åŠæ•°ç”¨æˆ·å¯¹ç­–ç•¥æœ‰å“åº”")
            report["recommendations"].append("å»ºè®®ä¼˜åŒ–ç›®æ ‡ç”¨æˆ·é€‰æ‹©")
        else:
            report["insights"].append("ç­–ç•¥å“åº”ç‡åä½")
            report["recommendations"].append("å»ºè®®é‡æ–°è®¾è®¡ç­–ç•¥æˆ–è°ƒæ•´ç›®æ ‡ç”¨æˆ·")

        # å¢é‡åˆ†æ•°åˆ†å¸ƒåˆ†æ
        high_uplift_threshold = uplift_scores_df['uplift_score'].quantile(0.8)
        high_uplift_users = uplift_scores_df[uplift_scores_df['uplift_score'] >= high_uplift_threshold]

        report["insights"].append(
            f"å‰20%é«˜å¢é‡ç”¨æˆ·å¹³å‡å¢é‡åˆ†æ•°: {high_uplift_users['uplift_score'].mean():.4f}"
        )
        report["recommendations"].append(
            "é‡ç‚¹é’ˆå¯¹é«˜å¢é‡åˆ†æ•°ç”¨æˆ·è¿›è¡Œè¥é”€æŠ•æ”¾"
        )

        return report